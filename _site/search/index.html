<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 5.0.0 | Copyright Dean Attali 2020 -->
<head>
	<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicon-16x16.png">
<link rel="manifest" href="/assets/img/site.webmanifest">
<link rel="mask-icon" href="/assets/img/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  

  <title>Yuanpeng&apos;s Blog</title>

  
  <meta name="author" content="Yuanpeng Zhang">
  

  <meta name="description" content="{% include search-lunr.html %}">

  

  

  <link rel="alternate" type="application/rss+xml" title="Yuanpeng's Blog" href="http://localhost:4001/feed.xml">

  

  

  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163985757-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-163985757-1');
</script>

  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  

  

  

  
  <meta property="og:site_name" content="Yuanpeng's Blog">
  <meta property="og:title" content="Yuanpeng&apos;s Blog">
  <meta property="og:description" content="{% include search-lunr.html %}">

  
  <meta property="og:image" content="http://localhost:4001/assets/img/avatar-icon.png">
  

  
  <meta property="og:type" content="website">
  <meta property="og:url" content="http://localhost:4001/search/">
  <link rel="canonical" href="http://localhost:4001/search/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  <meta property="twitter:title" content="Yuanpeng&apos;s Blog">
  <meta property="twitter:description" content="{% include search-lunr.html %}">

  
  <meta name="twitter:image" content="http://localhost:4001/assets/img/avatar-icon.png">
  

  


  

  

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script async='async' src='https://www.gstatic.com/external_hosted/clipboardjs/clipboard.min.js'></script>
<script src='https://unpkg.com/sweetalert@2.1.2/dist/sweetalert.min.js'></script>
<script language='JavaScript'>
  function copytoclipboard(containerid){
    if (document.selection) {
      var range = document.body.createTextRange();
      range.moveToElementText(document.getElementById(containerid));
      range.select().createTextRange();
      document.execCommand("copy");
    } else if (window.getSelection) {
      var range = document.createRange();
      range.selectNode(document.getElementById(containerid));
      var selection = window.getSelection() // get Selection object from currently user selected text
      selection.removeAllRanges() // unselect any user selected text (if any)
      selection.addRange(range) // add range to Selection object to select it
      document.execCommand("copy");
      //alert("Codes snippet copied to clipboard!")
      swal({
      title: "",
      text: "Codes snippet copied to clipboard!",
      icon: "success",
      });
    }
  }
</script>

<script language="Javascript">
  let constrain = 20;
  let mouseOverContainer = document.getElementById("ex1");
  let ex1Layer = document.getElementById("ex1-layer");

  function transforms(x, y, el) {
    let box = el.getBoundingClientRect();
    let calcX = -(y - box.y - (box.height / 2)) / constrain;
    let calcY = (x - box.x - (box.width / 2)) / constrain;

    return "perspective(100px) "
      + "   rotateX("+ calcX +"deg) "
      + "   rotateY("+ calcY +"deg) ";
  };

   function transformElement(el, xyEl) {
    el.style.transform  = transforms.apply(null, xyEl);
  }

  mouseOverContainer.onmousemove = function(e) {
    let xy = [e.clientX, e.clientY];
    let position = xy.concat([ex1Layer]);

    window.requestAnimationFrame(function(){
      transformElement(ex1Layer, position);
    });
  };
</script>script>
</head>

<body>

  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand navbar-brand-logo" href="http://localhost:4001/"><img alt="Yuanpeng's Blog Logo" src="/assets/img/home.png"/></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
              <a class="nav-link" href="/search">üîçSearch</a></li>
          <li class="nav-item">
              <a class="nav-link" href="/about">About</a></li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Posts</a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="/all_posts">All posts</a>
                    <a class="dropdown-item" href="/archive">Archive</a>
                    <a class="dropdown-item" href="/tags">Tags</a>
            </div>
          </li>
        
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research</a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="/nav_pages/publications">Publications</a>
                    <a class="dropdown-item" href="/nav_pages/lnotes">Learning Notes</a>
            </div>
          </li>
        
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More Links</a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown"><a target="_blank" class="dropdown-item" href="https://www.ornl.gov/staff-profile/yuanpeng-zhang">ORNL Profile</a>
								  <a target="_blank" class="dropdown-item" href="https://scholar.google.com/citations?user=NgqIgO0AAAAJ&hl=en">Google Scholar</a>
								  <a target="_blank" class="dropdown-item" href="https://orcid.org/0000-0003-4224-3361">ORCID</a>
								  <a target="_blank" class="dropdown-item" href="https://rmcprofile.pages.ornl.gov/">RMCProfile</a>
								  <a target="_blank" class="dropdown-item" href="https://github.com/Kvieta1990">GitHub Profile</a>
								  <a target="_blank" class="dropdown-item" href="https://mybinder.org/v2/gh/Kvieta1990/Jup_Notes/master">Jupyter Binder</a>
								  <a target="_blank" class="dropdown-item" href="https://github.com/Kvieta1990/Iris">More Notes</a>
								  <a target="_blank" class="dropdown-item" href="https://github.com/Kvieta1990/Kvieta1990.github.io">Blog Repo</a>
								  
            </div>
          </li>
        </ul>
  </div>

  

  
    <div class="avatar-container">
      <div class="avatar-img-border" id="others">
      </div>
    </div>
    <div class="avatar-container">
      <div class="avatar-img-border">
					<div class="avatar-adjust" id="safari">
				  </div>
      </div>
    </div>
  

<script>
function myFunction() {
		return '<a href="http://localhost:4001/"><img alt="Navigation bar avatar" class="avatar-img" src="/assets/img/avatar-icon.png" />';
}
let safariAgent = navigator.userAgent.indexOf("Safari") > -1;
let chromeAgent = navigator.userAgent.indexOf("Chrome") > -1;
if (chromeAgent) {
  document.getElementById("others").innerHTML = myFunction();
} else if (safariAgent) {
  document.getElementById("safari").innerHTML = myFunction();
} else {
  document.getElementById("others").innerHTML = myFunction();
}

</script>

</nav>


  <!-- TODO this file has become a mess, refactor it -->




<div class="intro-header"></div>





<div class="intro-header"></div>

<div role="main" class=" container-md ">
  

  </br>

<script src="/js/lunr.js"></script>

<script>

var documents = [{
    "id": 0,
    "url": "http://localhost:4001/404.html",
    "title": "404 - Page not found",
    "body": " Whoops, this page doesn‚Äôt exist.  Move along. (404 error)   "
    }, {
    "id": 1,
    "url": "http://localhost:4001/about/",
    "title": "About My Blog",
    "body": " This is my personal blog, for the purpose of recording my learning progress. For every single idea which I believe is crucial for understanding specific physics or other topics,I have been trying my best to write them down. On one hand, this can help myself refreshing my mind from time to time,and on the other, if someone else loving physics happens to meet this site,I hope either these materials can help them or they can provide important advice for me to revise some key stuff, which could help improving my understanding! We all have such moments when forgetting something we already understood before. So why not writing them down when you are sure you have got it (maybe someday, what you were sure about turns out to be wrong!)?Also, learning physics, or perhaps anything else, is a process of accumulating and we can never say what is important or not. Neither can we say with hundred percent confidence that we really understand the real meaning of some specific issues ‚Äì this makes me recall a saying by R. Feynman ‚Äì ‚Äòillusion of understanding‚Äô. So let‚Äôs write everything in mind down to paper,and have a look in the future (or show around to others). There are two cases possibly to happen ‚Äì one is ‚ÄòAh ha, what I thought at that time is absolutely correct!‚Äô and we then get a deeper impression in mind about how it works. The other case is that ‚ÄòOh no, the stuff I wrote at that time is totally wrong!!!‚Äô. That is, however, not totally a disaster since we now realize something is going wrong, which, at least, is better than pretending everything is right! At last, it is reading, writing, reviewing and effective interaction that makes everybody and also physics itself different from what it was yesterday. So, let‚Äôs write! "
    }, {
    "id": 2,
    "url": "http://localhost:4001/nav_pages/about_community/",
    "title": "RMCProfile Community",
    "body": "Two magic ways to join the RMCProfile community for discussion    [Recommended] GitHub Issues.          Go to COMMUNITY -&gt; ON GITHUB in the top-right corner of the page.           Quickly access community discussion,                Once opening the ON GITHUB link, bookmark it.                 The GitHub issues are associated with a GitHub repository. Therefore,Star the repository will give you quick access to our GitHub issuesthrough your Starred repository.                 Access to the community through this RMCProfile website is not a badoption.                    More information to be presented below.          Mailing list.      Go to COMMUNITY -&gt; MAILING LIST in the top-right corner of the page.    Brief covering for the recommended way of joining the community discussion,using GitHub issues    You need a GitHub account.      &gt; Click Me to get it if you are not already having one.       Though it is fairly straightforward to use, a demo for how-to is still worthit, as given below.        A few more links introducing GitHub issues to check out.          About issues           Mastering issues       "
    }, {
    "id": 3,
    "url": "http://localhost:4001/all_posts/",
    "title": "Yuanpeng's Posts",
    "body": ""
    }, {
    "id": 4,
    "url": "http://localhost:4001/nav_pages/change_log/",
    "title": "Change Log",
    "body": ""
    }, {
    "id": 5,
    "url": "http://localhost:4001/nav_pages/developers/",
    "title": "Developers",
    "body": ""
    }, {
    "id": 6,
    "url": "http://localhost:4001/nav_pages/disclaimer/",
    "title": "Disclaimer",
    "body": "The software and files on this site are delivered to you AS IS and for non-profit making purposes. The primary authors (Matt Tucker, Martin Dove, Andrew Goodwin, Anthony Phillips, David Keen, Helen Playford, Wojciech A. Slawinski, Igor Levin, Victor Krayzman, Maksim Eremenko and Yuanpeng Zhang) and their employing organizations (STFC, ORNL, NIST, the Universities of Oxford and Cambridge, Queen Mary, University of London) make no warranty as to their use or performance. The employing organizations and their suppliers make no warranties regarding performance, results or otherwise, express or implied, nor also regarding to non-infringement or third-party rights, merchantability, or fitness for any particular purpose. In no event will the employing organizations be liable to you for any consequential, incidental, or special damages, including any lost profits or lost savings, even if the their representatives have been advised of the possibility of such damages, or for any claim by any third party. "
    }, {
    "id": 7,
    "url": "http://localhost:4001/archive/2020/12/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 8,
    "url": "http://localhost:4001/archive/2021/05/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 9,
    "url": "http://localhost:4001/archive/2021/06/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 10,
    "url": "http://localhost:4001/archive/2021/07/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 11,
    "url": "http://localhost:4001/archive/2020/06/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 12,
    "url": "http://localhost:4001/archive/2020/10/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 13,
    "url": "http://localhost:4001/archive/2022/06/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 14,
    "url": "http://localhost:4001/archive/2022/10/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 15,
    "url": "http://localhost:4001/archive/",
    "title": "Archive",
    "body": "        2022                              October (2)                   June (1)       2021                       December (1)                    August (1)                                  July (3)                    June (1)                          May (2)       2020                                     December (3)                                  November (3)                    September (1)                                         July (4)                                  June (3)                           April (2)                                 March (3)       2019                    December (2)"
    }, {
    "id": 16,
    "url": "http://localhost:4001/archive/2019/12/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 17,
    "url": "http://localhost:4001/archive/2020/11/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 18,
    "url": "http://localhost:4001/archive/2020/04/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 19,
    "url": "http://localhost:4001/archive/2020/09/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 20,
    "url": "http://localhost:4001/archive/2021/12/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 21,
    "url": "http://localhost:4001/archive/2020/07/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 22,
    "url": "http://localhost:4001/archive/2020/03/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 23,
    "url": "http://localhost:4001/archive/2020/02/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 24,
    "url": "http://localhost:4001/archive/2021/08/",
    "title": "Archive",
    "body": ""
    }, {
    "id": 25,
    "url": "http://localhost:4001/",
    "title": "Yuanpeng's Blog",
    "body": "About Me    Working as neutron scattering scientist at ORNL, I have been actively involved in software development and scientific research activities. The software development part mainly involves the development and maintenance oftools for neutron scattering data reduction and analysis, such as ADDIE environmentfor neutron total scattering data reduction, ADDIE web interface for structuremining and online Bragg and pair distribution function refinement, RMCProfile packagefor fitting scattering data based on supercell approach. Meanwhile, I am alsointerfacing the beamline scientists team and the software development team at ORNL,actively working on the development of Mantid framework for powder diffraction data reduction.  My research interest mainly focuses on the application of neutron total scatteringto look at local structure of materials - both nucleus and magnetic. The local environmentplays an important role in determining properties in a wide range of functional materials,e. g. , the polarization behavior in ferroelectric materials, ion transportation behavior inenergy story materials, magnetic anisotropy in low dimensional magnetic systems, etc. Myresearch interest at this point is to utilize total scattering technique to reveal localstructure for energy storage (e. g. Li-ion battery, functional material (high entropy spinelmaterials) and low dimensional magnetic system (e. g. 2D vdWs magnetic materials). Forfuturistic perspective, using machine learning algorithms in phase recognition duringphase transition is one of the goals to pursue. More   Yuanpeng‚Äôs ORNL profile     Yuanpeng‚Äôs Google scholar     Yuanpeng‚Äôs ORCID     RMCProfile website     Yuanpeng‚Äôs GitHub     Binder for Jupyter notebooks     Learning notes on GitHub  "
    }, {
    "id": 26,
    "url": "http://localhost:4001/nav_pages/lnotes/",
    "title": "Collection",
    "body": " Contents:  1. Notes on Machine Learning 1. 1. Probability Theory1. 2. Machine learning in practice2. Notes on group theory1. Notes on Machine Learning: 1. 1. Probability Theory: Probability theory basicsBayesian learningGaussian process 1. 2. Machine learning in practice: Linear algebra in machine learningLinear predictionRegularization &amp; cross-validationL1 Norm and LassoCategorical, Dirichlet distribution &amp; Naive BayesOptimizationLogistic regressionNeural network 2. Notes on group theory: Lecture note-ILecture note-II "
    }, {
    "id": 27,
    "url": "http://localhost:4001/nav_pages/manual/",
    "title": "",
    "body": ""
    }, {
    "id": 28,
    "url": "http://localhost:4001/nav_pages/publications/",
    "title": "Selected Publications",
    "body": "Click here for a full list of my publication list.  2022  Qiang Zhang, Yuanpeng Zhang, Masaaki Matsuda, Vasile Ovidiu Garlea, JiaqiangYan, Michael A. McGuire, D. Alan Tennant, Satoshi Okamoto. J. Am. Chem. Soc. ,2022, 144, 14339-14350. 2021    J Marcial, Y Zhang, X Zhao, H Xu, A Mesbah, ET Nienhuis, S Szenknect, JC Neuefeind, J Lin, L Qi, AA Migdisov, RC Ewing, N Dacheux, JS McCloy and X Guo,Thermodynamic non-ideality and disorder heterogeneity in actinide silicate solid solutions, npj Mater. Degrad. , 2021, 5 (1), 1-14.     Mingyang Ou, Yuanpeng Zhang, Yongcheng Zhu, Chenyang Fan, Shixiong Sun, Jintai Feng, Xueping Sun, Peng Wei, Jia Xu, Jian Peng, Xianyong Wu, Gang Jiang, Qing Li, Chun Fang and Jiantao Han, Local Structures of Soft Carbon and Electrochemical Performance of Potassium-Ion Batteries, ACS Appl. Mater. Interf. , 2021, 13 (24), 28261-28269.     Peng Jian, Ou Mingyang, Yi Haocong, Sun Xueping, Zhang Yuanpeng, Zhang Bao, Yu Ding, Wang Feng, Gu Songqi, Lopez Carlos, Zhang Wang, Liu YI, Fang Ju, Wei Peng, Li Yuyu, Miao Ling, Jiang Jianjun, Fang Chun, Li Qing, Fernandez-Diaz Maria Teresa, Alonso Jose Antonio, Chou Shulei and Han Jiantao, Defect-free-induced Na+ disordering in electrode materials, Energy Environ. Sci. , 2021, 14, 3130-3140.     F. P. Marlton, Z. Zhao, Y. Zhang, T. E. Proffen, C. D. Ling and B. J. Kennedy, Lattice Disorder and Oxygen Migration Pathways in Pyrochlore and Defect-Fluorite Oxides, Chem. Mater. , 2021, 33 (4) 1407-1415.     Santanu Roy, Shobha Sharma, Waruni V Karunaratne, Fei Wu, Ruchi Gakhar, Dmitry S Maltsev, Phillip Halstenberg, Milinda Abeykoon, Simerjeet K Gill, Yuanpeng Zhang, Shannon M Mahurin, Sheng Dai, Vyacheslav S Bryantsev, Claudio J Margulis and Alexander S Ivanov, X-ray scattering reveals ion clustering of dilute chromium species in molten chloride medium, Chem. Sci. , 2021, 12, 8026-8035.  2020    C. Li, Y. P. Zhang, J. Liu and H. A. Graetsch. Long-Range and Local Structure of SrxBa1‚ÄìxNb2O6 (x = 0. 33 and 0. 67) across the Ferroelectric‚ÄìRelaxor Transition, Chem. Mater. , 2020, 32 (5), 1844-1853.     Yuanpeng Zhang, Maksim Eremenko, Victor Krayzman, Matthew G. Tucker, Igor Levin, New capabilities for enhancement of RMCProfile: instrumental profiles with arbitrary peak shapes for structural refinements using the reverse Monte Carlo method, J. appl. Crystallogr. , 2020, 53 (6) 1-10.     Bo Jiang, Craig A Bridges, Raymond R Unocic, Krishna Chaitanya Pitike, Valentino R Cooper, Yuanpeng Zhang, De-Ye Lin and Katharine Page, Probing the Local Site Disorder and Distortion in Pyrochlore High-Entropy Oxides, J. Am. Chem. Soc. , 2020, 143 (11), 4193-4204.     Zhi Deng, Mingyang Ou, Jing Wan, Shuai Li, Yuyu Li, Yuanpeng Zhang, Zhe Deng, Jia Xu, Yuegang Qiu, Yi Liu, Chun Fang, Qing Li, Li Huang, Jinlong Zhu, Songbai Han, Jiantao Han and Yusheng Zhao, Local Structural Changes and Inductive Effects on Ion Conduction in Antiperovskite Solid Electrolytes, Chem. Mater. , 2020, 32 (20), 8827-8835.  2019    Y. P. Zhang, M. McDonnell, W. Liu and M. G. Tucker. Reverse Monte Carlo modeling for low-dimensional systems, *J. Appl. Cryst. , 2019, 52, 1035-1042.     Y. P. Zhang, M. McDonnell, S. A. Calder and M. G. Tucker. Mechanistic Insights into the SuperexchangeInteraction-Driven Negative Thermal Expansion in CuO, *J. Am. Chem. Soc. , 2019, 141, 6310-6317.     Y. P. Zhang, T. Scholz, R. Dronskowski, M. McDonnell and M. G. Tucker. Local magnetic cluster size identified by neutron total scattering in the site-diluted spin glass SnxFe4-xN (x=0. 88). Phys. Rev. B, 2019, 100, 014419.  -2019    N. R. C. Corsini, Y. P. Zhang, W. R. Little, A. Karatutlu, O. Ersoy, P. D. Haynes, C. Molteni, N. D. M. Hine, I. Hernandez, J. Gonzalez, F. Rodriguez, V. V. Brazhkin and A. Sapelkin. Pressure-induced amorphization and a new high density amorphous metallic phase in matrix-free Ge nanoparticles, *Nano Lett. , 2015, 15, 7334-7340.     A. Karatutlu, M. Song, A. P. Wheeler, O. Ersoy, W. R. Little, Y. P. Zhang, P. Puech, F. S. Boi, Z. Luklinska and A. V. Sapelkin. Synthesis and structure of free-standing germanium quantum dots and their application in live cell imaging, RSC Adv. , 2015, 5, 20566-20573.     Y. P. Zhang, W. Liu and R. Wang. From ZnS nanoparticles, nanobelts to nanotetrapods: the ethelenediamine modulated anisotropic growth of ZnS nanostructures, *Nanoscale, 2012, 4, 2394-2399.  "
    }, {
    "id": 29,
    "url": "http://localhost:4001/post_templates/sample_1/",
    "title": "Welcome to RMCprofile community",
    "body": "This is a demo post to show you how to write blog posts with markdown.  I strongly encourage you to take 5 minutes to learn how to write in markdown - it‚Äôll teach you how to transform regular text into bold/italics/headings/tables/etc. Here is some bold text Here is a secondary heading: Here‚Äôs a useless table:       Number   Next number   Previous number         Five   Six   Four       Ten   Eleven   Nine       Seven   Eight   Six       Two   Three   One   How about a yummy crepe? It can also be centered! Here‚Äôs a code chunk:    var foo = function(x) { return(x + 5);}foo(3) And here is the same code with syntax highlighting:    var foo = function(x) { return(x + 5);}foo(3) And here is the same code yet again but with line numbers:  1234var foo = function(x) { return(x + 5);}foo(3)Boxes: You can add notification, warning and error boxes like this: Notification: Note: This is a notification box. Warning: Warning: This is a warning box. Error: Error: This is an error box. "
    }, {
    "id": 30,
    "url": "http://localhost:4001/search/",
    "title": "",
    "body": "&lt;/br&gt; {% include search-lunr. html %} "
    }, {
    "id": 31,
    "url": "http://localhost:4001/tags/",
    "title": "Tag Index",
    "body": "      {% assign date_format = site. date_format   default: ‚Äú%B %-d, %Y‚Äù %}   {%- capture site_tags -%}  {%- for tag in site. tags -%}    {{- tag | first -}}{%- unless forloop. last -%},{%- endunless -%}  {%- endfor -%}{%- endcapture -%}{%- assign tags_list = site_tags | split:‚Äô,‚Äô | sort -%} {%- for tag in tags_list -%}  ¬†{{- tag -}}¬†({{site. tags[tag]. size}}){%- endfor -%}  {%- for tag in tags_list -%}  &lt;h2 id= {{- tag -}}  class= linked-section &gt;        ¬†{{- tag -}}¬†({{site. tags[tag]. size}})  &lt;/h2&gt;  &lt;div class= post-list &gt;    {%- for post in site. tags[tag] -%}      &lt;div class= tag-entry &gt;        {{- post. title -}}        &lt;div class= entry-date &gt;										{{- post. date | date: date_format -}}, by {{ post. author }}        &lt;/div&gt;      &lt;/div&gt;    {%- endfor -%}  &lt;/div&gt;{%- endfor -%} "
    }, {
    "id": 32,
    "url": "http://localhost:4001/nav_pages/tools/",
    "title": "Tools",
    "body": "   SofQ_Calib      A tool for calibrating \(S(Q)\) against Bragg pattern.            Installation     This requires users to have conda installed on their machines, so that one can easily install this tool using the following command:      conda install -c apw247 sofq_calib             Topas4RMC      A tool for preparing Topas profiles to be used in Bragg pattern fitting in RMCProfile.            Installation     This requires users to have conda installed on their machines, so that one can easily install this tool using the following command:      conda install -c apw247 topas4rmc          "
    }, {
    "id": 33,
    "url": "http://localhost:4001/nav_pages/tutorial/",
    "title": "Tutorials",
    "body": "Videos for each of the exercises included in RMCProfile release package. Exercise-1 {% include streamablePlayer. html id=page. streamableId1 %} Exercise-2 {% include streamablePlayer. html id=page. streamableId2 %} "
    }, {
    "id": 34,
    "url": "http://localhost:4001/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ ‚Äúsitemap. xml‚Äù   absolute_url }}   "
    }, {
    "id": 35,
    "url": "http://localhost:4001/2022-10-09-jekyll_maths/",
    "title": "Math equation in Jekyll",
    "body": "2022/10/09 -  To enable the display of math equations in GitHub pages, we need to include the corresponding Javascript in our page header. Taking my current blog as an example (one can go to MORE LINKS (\rightarrow) BLOG REPO to visit the GitHub repo for current blog), in the header part of each post, it is specified the layout is post. We then can find post. html in the _layouts directory which includes the definition for the outlook of a post. There, in the header part, one can find it is further pointing to the base layout which then refers to the base. html file under _layouts. Opening the base. html file, we can find that it includes the head. html file (which fundamentally defines the &lt;header&gt; section in the rendered HTML file). The head. html file can be found under _includes directory. We then need to include the following codes in the head. html file,    &lt;script type= text/javascript  async src= https://cdn. mathjax. org/mathjax/latest/MathJax. js?config=TeX-MML-AM_CHTML &gt;&lt;/script&gt; Then for both inline and display equation, we can just use ‚Äò$$‚Äô symbol to claim an equation environment to write out equations. "
    }, {
    "id": 36,
    "url": "http://localhost:4001/2022-10-09-jekyll_code_snippet_copy/",
    "title": "Copy of code snippet in Jekyll",
    "body": "2022/10/09 -  Trying to follow several resources [1, 2] for setting up the code snippet copy capability in Jekyll site, but for some reason, I could not get it working. I suppose this may be something to do with theme I am using (the beautiful-jekyll theme), and I am not what to tune to make it working with the code snippet copy function posted by others (see Ref. [1, 2]). Instead of struggling with those minor tunes, I am using a separate routine for such a purpose, without any involvement with CSS styling, etc. To enable the code snippet copy in GitHub pages using my current way, we need to include the corresponding Javascript in our page header. Taking my current blog as an example (one can go to MORE LINKS (\rightarrow) BLOG REPO to visit the GitHub repo for current blog), in the header part of each post, it is specified the layout is post. We then can find post. html in the _layouts directory which includes the definition for the outlook of a post. There, in the header part, one can find it is further pointing to the base layout which then refers to the base. html file under _layouts. Opening the base. html file, we can find that it includes the head. html file (which fundamentally defines the &lt;header&gt; section in the rendered HTML file). The head. html file can be found under _includes directory. First, we need to put the following Javascript codes into the &lt;header&gt; section of the head. html file,  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 910111213141516171819202122232425&lt;script async=&#39;async&#39; src=&#39;https://www. gstatic. com/external_hosted/clipboardjs/clipboard. min. js&#39;&gt;&lt;/script&gt;&lt;script src=&#39;https://unpkg. com/sweetalert@2. 1. 2/dist/sweetalert. min. js&#39;&gt;&lt;/script&gt;&lt;script language=&#39;JavaScript&#39;&gt; function copytoclipboard(containerid){  if (document. selection) {   var range = document. body. createTextRange();   range. moveToElementText(document. getElementById(containerid));   range. select(). createTextRange();   document. execCommand(&quot;copy&quot;);  } else if (window. getSelection) {   var range = document. createRange();   range. selectNode(document. getElementById(containerid));   var selection = window. getSelection() // get Selection object from currently user selected text   selection. removeAllRanges() // unselect any user selected text (if any)   selection. addRange(range) // add range to Selection object to select it   document. execCommand(&quot;copy&quot;);   //alert(&quot;Codes snippet copied to clipboard!&quot;)   swal({   title: &quot;&quot;,   text: &quot;Codes snippet copied to clipboard!&quot;,   icon: &quot;success&quot;,   });  } }&lt;/script&gt;Here is where I put those lines in the head. html file, Click Me. Then, as what I have above in current blog, we need to put down a button to link to the copytoclipboard function defined in the Javascript we just included. Here follows is the code for the button, which we can directly grab and put into our blog post (see here for the implementation in current blog)  Copy snippet to clipboard!  123&lt;div align=&quot;right&quot;&gt;&lt;button onclick=&quot;javascript:copytoclipboard(&#39;csp2&#39;)&quot; style=&quot;border: none&quot;&gt;Copy snippet to clipboard!&lt;/button&gt;&lt;/div&gt;Then, we need to go to the hilite. me website, where we can paste in our code snippet and the website will help us turning that into HTML codes with language specific grammar highlighting. From there, we can then copy those HTML codes and directly paste them into our blog post, like what I have here for the current blog (the first Javascript code snippet above). Finally, to link the copytoclipboard function associated with a certain button to copy a specific block of codes, we need to add in a unique ID into the pasted HTML codes from hilite. me, like what I have here for the current blog (again, the first Javascript code snippet above). Then the function parameter for copytoclipboard needs to be consistent with the code block that we want to copy by clicking on the button - see here, again, for the the first Javascript code snippet above.  N. B. The ID for the pasted code from hilite. me should go to EXACTLY the &lt;td&gt; section as presented in the link here.  N. B. Those pasted HTML from hilite. me was changed a bit across all posts in my blog to remove the padding space of the code block - specifically it is this bit padding:. 0em . 0em; in here. "
    }, {
    "id": 37,
    "url": "http://localhost:4001/2022-06-20-iso_subg/",
    "title": "Notes On Isotropy Subgroup",
    "body": "2022/06/20 - Figure. 1. Isotropy subgroup [1].  This blog contains some key notes for reading the lecture notes by H. Stokes, et al. [1] on isotropy subgroup. Details about the lecture notes will not be reproduced here and instead we will just put down some key understanding as below, Two subspaces are equivalent if the basis vectors for each can be set up in such a way that they are associated with the same representation. The reason why the two subspaces are equivalent is that it is actually the linear combination coefficients that appear in front of the basis vectors that determines how the symmetry is lowered. Even though the basis vectors of the two subspaces may be very different, the same linear combination of basis vectors still lead to the same variation of symmetry, e. g. , lowering the space group from (G) to its subgroup (G‚Äô). This might be the reason why subgroups associated with vectors in parameter space are called isotropy subgroup ‚Äì atomic distortions in the two equivalent subspaces could be very different in 3D space (i. e. , isotropic) but they both lead to the same symmetry lowering from (G) to (G‚Äô). In group theory, there are many ways of separating out group elements into different parts, like cosets. One of the ways is that the separated-out parts themselves can be regarded as a single group element, in which case we say the original group is mapped onto another group the elements of which is actually a group of elements instead of single operations. In such a situation, for sure there should be a certain group of elements that are mapped to the identify element in the new group i. e. , all the group elements involved are mapped to the identity element (of the new group). Representation is a certain type of mapping ‚Äì it maps group elements in the original group to certain matrices in the new group (of matrices which are now the specific form of operations). Then in the context of isotropy subgroup, if a certain isotropy subgroup is mapped to the identity matrix by a certain irreducible representation (IR), that isotropy subgroup is called the kernel of the IR. This further means all vectors in the representation space is invariant under the operation of any elements in that isotropy subgroup (the kernel of the IR).  References [1] https://1drv. ms/b/s!AlZpbyasn9jtkNAL8RAzOHFoeYj2iQ "
    }, {
    "id": 38,
    "url": "http://localhost:4001/2021-12-21-owncloud_setup/",
    "title": "OwnCloud Server Setup",
    "body": "2021/12/21 -  üëâ Ports configuration Refer to the following links to gist for configuration files concerning the ports configuration, /etc/apache2/ports. conf /etc/apache2/sites-enabled/000-default. conf üëâ Connection to WSL Apache server from outside (i. e. , beyond localhost) This link provide detailed explanation about the IP address assignment scheme for WSL 2 and we need to follow the instruction there to establish the connection from outside to WSL Apache server. Also, since each time when we launch the WSL, new IP address will be assigned to the virtual system and we have no way to make the IP address static. In this case, we can follow this link to grab the IP address of the virtual WSL system automatically and connect it to our Windows host. The following function can be put in powershell profile file so that we can do the configurations all-in-once,    Function own {  wsl sudo /etc/init. d/mysql start  wsl sudo service apache2 restart  $wsl_ip = (wsl hostname -I). trim()  netsh interface portproxy add v4tov4 listenport=5051 listenaddress=0. 0. 0. 0 connectport=5051 connectaddress=$wsl_ip}  üëâ Port confliction &amp; Firewall issues Sometimes, if the connection cannot be established via public IP address (or domain name if configured), there could be multiple reasons. First, we may want to change the Apache configuration to let it listen to another alternative port, since sometimes other services (e. g. , Jupyterlab) will take over the port used by Apache. Second, we want to make sure the rule for a specific port is added in Windows Firewall exception (inbound traffic).  üëâ Configure external drive By default, onwCloud will use ‚Äò/var/www/owncloud/data‚Äô as the data directory, where all files would be stored. Also, by default, using external local drive as storage is disabled (for safety reason). To enable this, we can refer to Ref. [3].  References [1] https://www. how2shout. com/how-to/how-to-install-owncloud-server-on-windows-10-wsl. html [2] https://lucidar. me/en/owncloud/install-owncloud-server-on-ubuntu-20-04/ [3] https://github. com/owncloud/core/pull/27590 "
    }, {
    "id": 39,
    "url": "http://localhost:4001/2021-08-25-nano_rmc/",
    "title": "Size effect in RMCProfile",
    "body": "2021/08/25 - Figure. 1. Simulation box for bulk (left) and nano (right) systems.  In Ref. [1], we discussed the theoretical principles for correcting the nano-size effect when modeling the pair distribution function (PDF). The fundamental idea is to bring back the uncorrelated pairings in between atoms belong to different nanoparticles, based on the assumption of random distribution of nanoparticles in system. Such uncorrelated pairings will then be added to the partial PDF‚Äôs calculated explicitly from the structural model in simulation box, as presented in the right of the picture shown above. The kernel mathematical expression in Ref. [1] is reproduced as follows, [G(r) = \sum_{i,j}c_ic_jf_if_j[\frac{\rho^{RMC}}{\rho}g_{ij}^{RMC}(r) + U(r) - 1]] where the meaning of all symbols can be found in Ref. [1] and we won‚Äôt reproduce them all here. Instead, we are going to focus on the term (g_{ij}^{RMC}(r)) which represents the partial PDF‚Äôs calculated explicitly from the simulation box and (U(r)) which represents the uncorrelated correlation term. What we are going to discuss here is how to bring these two terms together so that they can be calculated in a compact manner when coded in, e. g. , RMCProfile package. First, (g_{ij}^{RMC}(r)) can be further written as, [g_{ij}^{RMC}(r) = \frac{n_{ij}}{4\pi r^2dr\rho_j} = \frac{\frac{hist_{ij}}{n_i}}{4\pi r^2dr\frac{n_j}{Vol}} = \frac{hist_{ij}}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}] where (hist_{ij}) represents the histogram of pairings between atoms of type (i) and (j) in system. Basically, it is just the number of pairs between atoms of type (i) and (j) that fall into specific distance bins. (Vol) represents the ‚Äòoverall‚Äô volume for calculating the partial number density (\rho_j). However, if (Vol) in the equation represents the overall volume of the simulation box (where we have void space, to get rid of periodic boundary condition), we then have to bring in an extra correction factor so that the partial number density can be calculated properly. To this point, the factor (\rho^{RMC}/\rho) can be introduced, where (\rho^{RMC}) and (\rho) refers to the overall number density calculated with and without void space in the simulation box, respectively. If we multiple this factor the $Vol$, the effective volume then can be obtained, in which case the equation above just becomes, [g_{ij}^{RMC}(r) = \frac{hist_{ij}}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol^{eff}}} = \frac{\rho^{RMC}}{\rho}\frac{hist_{ij}}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}] Next, we focus on the (U(r)) term ‚Äì when coding in such a correction term, we want to do it in a clean way and thus will try to calculate the ‚Äòhistogram‚Äô corresponding to the correction term, so that the correction can be applied at the initialization stage and we don‚Äôt need to worry about it anymore when calculating the overall PDF and all the other relevant quantities in the program. To do this, we first write, [\frac{\rho^{RMC}}{\rho}g_{ij}^{RMC}(r) + U(r) = \frac{\rho^{RMC}}{\rho}\frac{hist_{ij}}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}} + \frac{U(r)4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}] Pulling all the factors out, we will arrive at, [\begin{equation}\begin{aligned}\frac{\rho^{RMC}}{\rho}g_{ij}^{RMC}(r) + U(r) &amp; = \frac{\rho^{RMC}}{\rho}\frac{1}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}[hist_{ij} + \frac{\rho}{\rho^{RMC}}U(r)4\pi r^2dr\frac{n_i\cdot n_j}{Vol}]\ &amp; = \frac{\rho^{RMC}}{\rho}\frac{1}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}[hist_{ij} + \frac{\rho}{n_{all}/Vol}U(r)4\pi r^2dr\frac{n_i\cdot n_j}{Vol}]\ &amp; = \frac{\rho^{RMC}}{\rho}\frac{1}{4\pi r^2dr\frac{n_i\cdot n_j}{Vol}}[hist_{ij} + \rho U(r)4\pi r^2dr\frac{n_i\cdot n_j}{n_{all}}]\end{aligned}\nonumber\end{equation}] where the second term in the square bracket is the effective histogram corresponding to the uncorrelated pairings, which then can be added to the partial PDF‚Äôs at the initialization stage.  References [1] Y. Zhang, et al. , J. Appl. Cryst. (2019). 52, 1035-1042. "
    }, {
    "id": 40,
    "url": "http://localhost:4001/2021-07-09-coh_incoh_sl/",
    "title": "Derivation of neutron incoherent scattering length",
    "body": "2021/07/09 - Figure. 1. Neutron scattering length table by NIST [1]. When we do calculations relevant to neutron scattering, it is unavoidable that we will come across either coherent, incoherent or total scattering length of elements, which describes the strength of scattering neutrons by different elements, either coherently, incoherently or both. In this article, I will try to uncover the three different types of neutron scattering length, by going through the derivation in details. First, the differential cross section for neutron scattering by a certain structure is given as below ‚Äì here we do the derivation for a single-species system so we can derive the relevant scattering length conveniently. [\frac{d\sigma}{d\Omega} = \sum_{i,j}b_ib_je^{-i\vec{Q}\cdot (\vec{R}_i - \vec{R}_j)}] where (i), (j) refers to atoms located at different locations in the structure under beam. In practice, every single (b_i), (b_j) depends on the corresponding nuclear isotope, spin orientation relative to neutron, nuclear eigenstate, etc. What we are interested in and what is meaningful in practical calculation is the average (\langle b_ib_j\rangle) across all pairs in system, which then can be used as an effective representative of system. To obtain (\langle b_ib_j\rangle), we first write, [b_i = \langle b\rangle + \delta b_i] where we should have (\langle\delta b_i\rangle = 0), if assuming random variation of (b_i) around (\langle b\rangle) for an arbitrary (i). Further, [\begin{equation}\begin{aligned}\langle b_ib_j\rangle &amp; = \Big\langle\langle b\rangle^2 + \langle b\rangle(\delta b_i + \delta b_j) + \delta b_i\delta b_j\Big\rangle\ &amp; = \Big\langle\langle b\rangle^2\Big\rangle + \big\langle\langle b\rangle(\delta b_i + \delta b_j)\big\rangle + \langle\delta b_i\delta b_j\rangle\ &amp; = \langle b\rangle^2 + 0 + \langle\delta b_i \delta b_j\rangle\end{aligned}\nonumber\end{equation}] (\langle\delta b_i\delta b_j\rangle) is then the quantity we want to calculate. The good news is, it is only non-zero when (i = j), assuming atom (i) and (j) is irrelevant to each other. For (i = j), we have, [\langle b^2\rangle = \langle b\rangle^2 + \langle\delta b_i^2\rangle \Rightarrow \langle\delta b_i^2\rangle = \langle b^2\rangle - \langle b\rangle^2] For (i \neq j), we simply have, [\langle b_ib_j\rangle = \langle b\rangle^2] Going back to the equation for calculating differential cross section and putting in the expression for (\langle b_ib_j\rangle), we have, [\begin{equation}\begin{aligned}\frac{d\sigma}{d\Omega} &amp; = \sum_{i,j}^N\langle b_ib_j\rangle e^{i\vec{Q}\cdot(\vec{R}i - \vec{R}_j)}\ &amp; = \sum{i\neq j}^N\Big[\langle b\rangle^2e^{i\vec{Q}\cdot(\vec{R}i - \vec{R}_j)} + \langle\delta b_i\delta b_j\rangle e^{i\vec{Q}\cdot(\vec{R}_i - \vec{R}_j)}\Big] + \ &amp; \hspace{0. 75cm} \sum{i=j}^N\Big[\langle b\rangle^2e^{i\vec{Q}\cdot(\vec{R}i - \vec{R}_j)} + \langle\delta b_i\delta b_j\rangle e^{i\vec{Q}\cdot(\vec{R}_i - \vec{R}_j)}\Big]\ &amp; = \sum{i\neq j}^N\Big[\langle b\rangle^2e^{i\vec{Q}\cdot(\vec{R}i - \vec{R}_j)} + 0\Big] + \sum{i=j}^N\Big[\langle b\rangle^2e^{i\vec{Q}\cdot(\vec{R}i - \vec{R}_j)} + (\langle b^2\rangle - \langle b\rangle^2)\Big]\ &amp; = \sum{i,j}^N\langle b\rangle^2e^{i\vec{Q}\cdot(\vec{R}_i - \vec{R}_j)} + N(\langle b^2\rangle - \langle b\rangle^2)\end{aligned}\nonumber\end{equation}] where (N) is the total number of atoms in system. Here we see the first term is relevant to atomic positions and therefore is the coherent scattering term. Accordingly, (\langle b\rangle^2) is the coherent scattering length (squared). The second term is nothing to do with structure and therefore is the incoherent scattering term. Accordingly, [\langle b^2\rangle - \langle b\rangle^2] is the incoherent scattering length (squared).  References [1] https://www. ncnr. nist. gov/resources/n-lengths/ "
    }, {
    "id": 41,
    "url": "http://localhost:4001/2021-07-08-top_physics/",
    "title": "Notes on topological physics",
    "body": "2021/07/08 - Image reproduced from Ref. [5]. In this blog, I will put down my learning notes as reading through the article on topological electrons by A. P. Ramirez and B. Skinner [1]. Basically, I will follow the story flow in Ref. [1] and therefore, first, I will note down the main flow that one can follow to arrive at the notion of topological electrons. Then I will cover the implications of topology and its connection to quantum Hall effect and quantum spin Hall effect. Finally, Weyl semimetal will be covered. It should be pointed that I will not reproduce all the nice discussions presented in Ref. [1]. Rather instead, I will just try to note down those key points or questions that I came across during reading Ref. [1]. First, the topological structure of an geometric object is defined by the Gauss-Bonnet integral, [\frac{1}{2\pi}\int_S K dA = n] where (K) refers to the curvature at points on surface (A). The integral will give us a constant (n) which corresponds to the genus (number of holes) of a certain geometric object in the following manner, [n = 2(1 - g)] When defining topological electrons, we are trying to look for similar definition as for the Gauss-Bonnet integral presented above. We can summarize the discussion in Ref. [1] as the following flow, Berry connection (\rightarrow) Berry curvature (\rightarrow) Berry phase. Considering then the integral of Berry curvature on the boundary of a 2D Brillouin zone, we then arrive the topological invariant - the Berry phase, [\frac{1}{2\pi\hbar^2}\int_{BZ}\Omega d^2p = C] where the topological invariant (C) in this case is called the Chern number. (\Omega = \nabla \times \mathbf{X}) is defined as Berry curvature, where (\mathbf{X}) is the Berry connection. The general definition for Berry connection and Berry phase can be found on Wikipedia [2] and won‚Äôt be reproduced here. Though, it should be pointed out that the general variable (R) in the formulation presented in Ref. [2] becomes (p) (i. e. momentum of electron) in the specific context of discussing topological electrons. Accordingly, the Berry connection in the context of topological electrons has its physical meaning - the average position of electron as the function of momentum. To understand this, we can refer to Eqn. (5. 34)-(5. 39) in Ref. [3]. Next, I will talk about the implication of topological invariant for magnetic field. First, to have non-zero Chern number, we will have a self-rotation in momentum space, as presented in Fig. 3 in Ref. [1]. Moreover, from the discussion above, we know that the mean value of atomic center position in unit cell is a function of momentum (\mathbf{p}). This indicates that the changing in momenta (i. e. , rotation - attention to the difference between rotation in momentum and real space) accompanies the changing of position and therefore indicates that the angular momentum is associated with the local Berry curvature (which infers the rotation of momenta). Therefore, we can see the analogous relation between Berry curvature and magnetic field - they both break symmetry (Berry curvature breaks the inversion symmetry when we have non-zero Chern number); they both bring in orbital angular momentum. Another implication for magnetic field from Berry curvature is that non-zero curl of (\mathbf{X}) will introduce movement in the transverse direction as, e. g. , electrons are accelerated in electric field - refer to Wikipage for curl [4] (see the two examples given there).  If inversion symmetry is not broken, the path integral along the boundary ofBrillouin zone will always Chern number of 0 ‚Äì for any (\mathbf{p}),we have a corresponding (-\mathbf{p}) with identical Berry connection,which will make the integration always 0. The implication for magnetic field as originated from topological invariant brings us to the connection with quantum Hall effect. When certain 2D materials are immersed in strong magnetic field and low temperature environment, they show quantized Hall conductance behavior. The physics picture for such a behavior is, electrons are circulating interior the bulk and rolling along the surface. Such circulating and rolling orbitals are quantized according to Landau levels which gives the quantization of cyclotron orbitals of charged particles in a uniform magnetic field. The quantization of Hall conductance can be explained purely by Landau‚Äôs quantization theory for magnetic field [6], and also it can be deduced based on topological consideration [7, 8]. The topological paradigm also explains the robustness of quantum Hall effect, i. e. the quantized Hall conductance is protected by topological invariant [7, 8]. According to Ref. [7, 8], the topological invariant is defined in parameter space, which is different from the version as presented in current summary based on Ref. [1] where the topological invariant is given in momentum space. Going back to the discussion about topological invariant as defined in momentum space, the implication for magnetic field gives rise to edge states much like those in the quantum Hall effect. There are two things to note down at this point, 1) as pointed out just above, the topological protection mechanism of quantum Hall effect systems and the topological system defined in momentum space is different. 2) though the topological invariant (again, defined in momentum space) implies magnetic field (which seems to suggest that the edge states can stably exists without external magnetic field), the breaking of time reversal symmetry in such topological systems makes it impossible to hold stable edge currents as what we can have in quantum Hall effect systems. However, in certain systems with strong spin-orbital coupling [1, 9], electrons with spin up and spin down can break down the time reversal symmetry separately to give opposite non-zero Chern number. In another word, spin up electrons flow, e. g. , to the right on surface whereas spin down electrons to the left. In such systems. the overall time-reversal symmetry is kept and on surface, we won‚Äôt have net current of electrons but we do have net flux of spins - either up or down. Such an effect is called quantum spin Hall effect [1, 10, 11]. The topological notion discussed here can apply to both 2D and 3D systems ‚Äì in 3D systems, it can be used to understand Weyl semimetal. What is semimetal? It shows continuous band structure as what we have for metal but the connection part (somewhat like the neck) is quite narrow ‚Äì that is typical band structure of semimetals. Specifically for Weyl semimetals, two bands touch each other in momentum space at Weyl points where we have the abrupt change in the orbital character of the wavefunction ‚Äì the momentum of electrons does not change smoothly crossing Weyl points. The picture shown at the top of current blog gives a typical picture of the corresponding band structure in 3D space. Usually, electronic band cannot coincide in energy since anytime two bands meet each other, there will be hybridization happening which will splits the degeneracy and therefore the two bands are bounced away from each other. In early age, the touching of two bands was explained to be accidental in which case hybridization is avoided. However, such an accidental touching could be easily destroyed by perturbation and therefore does not stand. In the context of topological paradigm, we see that such a type of band structure for Weyl semimetal systems is protected by the topological invariant. The value of topological invariant is relevant to the inclusion of Weyl points in the integration area when evaluating the Chern number integral. Weyl points are topological analogues to electric charges ‚Äì they are monopoles of Berry flux [1]. Also the Weyl points always come in pairs with opposite topological charges and the two Weyl points in the pair are with different chirality. Therefore, in Weyl semimetal systems, half of electrons are Weyl fermions with one chirality (see Ref. [12] for definition of electron chirality ‚Äì basically, it means whether electron spin is in the same or opposite direction flowing direction), the other half being Weyl fermions (electrons without explicit chirality are Dirac [fermions) with opposite chirality.  References [1] A. P. Ramirez and B. Skinner.  Physics Today 73, 9, 30 (2020). [2] https://en. wikipedia. org/wiki/Berry_connection_and_curvature [3] https://1drv. ms/b/s!AlZpbyasn9jtoqUZCYW069akHDG2rQ?e=gCynHc [4] https://en. wikipedia. org/wiki/Curl_(mathematics) [5] https://www. bnl. gov/newsroom/news. php?a=117401 [6] https://1drv. ms/b/s!AlZpbyasn9jtoqUlsQ_9KB7CG2g-og?e=kSOfZu [7] https://1drv. ms/b/s!AlZpbyasn9jtoqUkYCO6KG6h8JZFFA?e=gdOCXB [8] https://1drv. ms/b/s!AlZpbyasn9jtoqUj2N8fMFbK-0_cNQ?e=oe58FK [9] https://jqi. umd. edu/glossary/quantum-hall-effect-and-topological-insulators [10] https://scienceblogs. com/principles/2010/07/20/whats-a-topological-insulator [11] https://www. evernote. com/shard/s266/sh/2a935515-dfaa-4312-bb66-1d5dd5086339/dcdb9fe33e21b49f7c10168fd8980861 [12] https://en. wikipedia. org/wiki/Chirality_(physics) "
    }, {
    "id": 42,
    "url": "http://localhost:4001/2021-07-07-ising_sol/",
    "title": "Notes on Ising model",
    "body": "2021/07/07 - Ernst Ising (Left) and Wilhelm Lenz (Right) - Ising was Lenz‚Äôs student and the Ising model was claimed (by Ising himself) to be originated by Lenz but named after Ising. Ising model was originally proposed for ferromagnetism and owing to its simplicity in describing the system interaction, it has been widely used in not only describing magnetic systems in theoretical physics area but also in other areas involving similar interaction mechanism. In fact, Ising model can potentially find its position in describing systems involving binary states whereby we have active influence upon each other between neighbors. Here in this blog, I will not try to reproduce those already available beautiful introduction to Ising model - see e. g. , Ref. [1-4] and a whole bunch of others one can easily find on Internet. Instead, I will just write down the outline of the problem we are facing once we have the simple Ising model set up for describing the system energy. For example, we always hear people talking about the exact solution for Ising model. But, what actually are we trying to solve? What about those non-exact ways for ‚Äòsolving‚Äô the Ising model?First, it is worthwhile to write down the Hamiltonian for Ising model, [E_I{S_i} = -\sum_{\langle i,j\rangle}J_{ij}S_iS_j - \sum_{i=1}^NB_iSi] where the subscript (I) represents the Ising model. The first term corresponds to the interaction energy between neighboring spins and the second term is the interaction energy with externally applied magnetic field. ({S_i}) is a shortcut for the spin configuration of the system where each spin on its lattice site has its own orientation - either up (+1) or down (-1). (i) and (j) refers to lattice site and (J_{ij}) is the exchange constant describing the interaction strength between neighboring spins. Given the Hamiltonian of system, we are trying to calculate a crucial quantity - the partition function, which is a defined as the function of system state variables such as temperature, volume, etc. Starting from partition function, we can derive most of other thermodynamic variables, e. g. , system total energy, free energy, entropy, pressure, etc. Then naturally we can look into the phase transition problem, e. g. , for magnetic system, using those quantities derived from partition function. Therefore, for Ising model, when we say we want the exact solution, we mean to obtain the exact analytical solution for the partition function, the general expression of which is given as below, [Z = \sum_{s_1=-1}^{+1}\sum_{s_2=-1}^{+1}\cdots\sum_{s_N=-1}^{+1}e^{-\beta E_I{S_i}}] The solution for 1D Ising model can be found in Ref. [3], which is based on the original publication by Kramers and Wannier [5]. The exact solution for 2D model was originally proposed by Onsager [6-8] and the whole derivation procedure is reproduced in details as presented in Ref. [6]. The exact solution for 3D situation has been a challenging question to the physics community. In 2007, Prof. Z. Zhang proposed his exact solution based on two conjectures [9] and currently it is still under active debate and development [10, 11]. About this debate, Prof. Z. Zhang has three series of blogs introducing the history and current development of this theory - one can refer to Ref. [12-14] for details. Apart from exact solution, there are other ways to explore the phase transition behavior using Ising model, mainly based on numerical or simulation (e. g. , Monte Carlo) approach. An approach based on iterative numerical technique can be found in Ref. [3] and typical examples for those based on Monte Carlo simulation can be found in Ref. [15, 16].  References [1] http://blog. sciencenet. cn/blog-2344-3193. html [2] http://blog. sciencenet. cn/blog-2344-3194. html [3] https://1drv. ms/b/s!AlZpbyasn9jtoqUSanNV39-L40X42g?e=pOxR7u [4] https://1drv. ms/b/s!AlZpbyasn9jtoqUTtwM3cceW31_s5Q?e=d8RZv4 [5] H. A. Kramers and G. H. Wannier, Phys. Rev. 60, 263, 1941. [6] https://1drv. ms/b/s!AlZpbyasn9jtoqUUAfC4omrmXx1SSg?e=BX4WtI [7] https://1drv. ms/b/s!AlZpbyasn9jtoqUVcBIXJkaygOTFXw?e=3V0JK0 [8] L. Onsager. Phys. Rev. 65, 117, 1944. [9] Z-D. Zhang, Philos. Mag. Lett. 87 (34), 5309-5419, 2007. [10] Zhi-Dong Zhang, Chinese Phys. B. 22, 030513, 2013. [11] Zhidong Zhang, Osamu Suzuki and Norman H. March, Adv. Appl. Chifford Al. 29, 12, 2019. [12] http://blog. sciencenet. cn/blog-2344-3476. html [13] http://blog. sciencenet. cn/blog-2344-49176. html [14] http://blog. sciencenet. cn/blog-2344-1173989. html [15] https://rajeshrinet. github. io/blog/2014/ising-model/ [16] https://towardsdatascience. com/monte-carlo-method-applied-on-a-2d-binary-alloy-using-an-ising-model-on-python-70afa03b172b "
    }, {
    "id": 43,
    "url": "http://localhost:4001/2021-06-24-man_jupyter_kernel/",
    "title": "Management of Jupyter kernels",
    "body": "2021/06/24 -  Having multiple kernels available for Jupyter service, we may need to manage them at some point, e. g. , rename kernel names and remove kernels. First, to show all available kernels, run the following command,  jupyter kernelspec list we will then see output like this,  Available kernels:  python3  /opt/jupyterhub/lib64/python3. 6/site-packages/ipykernel/resources  diffpy   /usr/local/share/jupyter/kernels/diffpy  py37    /usr/local/share/jupyter/kernels/py37  python   /usr/local/share/jupyter/kernels/python This is the full list of all available kernels on our machine and the directory specifies where the configuration file for each kernel is located. To change kernel name, we then need to go into the corresponding directory for a specific kernel and open the ‚Äòkernel. json‚Äô file to change the ‚Äòdisplay_name‚Äô entry to whatever we want. To remove a kernel, we want to use the following command,  jupyter kernelspec remove KERNEL_NAME For example, if we want to remove the ‚Äòdiffpy‚Äô kernel above, we want to execute,  jupyter kernelspec remove diffpy Among all the available kernels, there is a special one - the ‚Äòbase‚Äô JupyterHub kernel from kernelspec. The ‚Äòpython3‚Äô kernel shown above is just the ‚Äòbase‚Äô JupyterHub kernel. If we try to remove this kernel, it will complain that the kernel cannot be found. Here in Ref. [1] is given detailed description and solution to this issue. To remove this base kernel, as posted in Ref. [1], there are two main things to do, 1) rename one of the other kernels to the base kernel name [2] and 2) disable native kernel by changing Jupyter configuration file [3]. Concerning the second part, we may need to create Jupyter configuration file first if it is not already existing, as instructed in Ref. [4].  References [1] https://github. com/jupyterhub/jupyterhub/issues/2759 [2] https://github. com/jupyterhub/jupyterhub/issues/2759#issuecomment-538139098 [3] https://github. com/jupyterhub/jupyterhub/issues/2759#issuecomment-770025308 [4] https://testnb. readthedocs. io/en/latest/config. html "
    }, {
    "id": 44,
    "url": "http://localhost:4001/2021-05-17-sphinx/",
    "title": "Intro to Sphinx",
    "body": "2021/05/17 -  Docstring is part of Python script which will keep record of documentation and description of the relevant section in the script. It won‚Äôt make any effect upon the execution of the script but whenever needed, the docstring could be pulled out and displayed for users‚Äô reference. Based on that, we can go further to generate dedicated documentation pages/docs for general purpose. At this point, Sphinx is a commonly used package to transform the docstrings in Python script into either HTML, LaTeX or some other suitable formats. Here in this blog, I am going to write down some notes in using Sphinx for building documentation based on the docstring in Python scripts. The steps below could be used as sort of general guidance to set things up with Sphinx.  1. Installation The official link to Sphinx gives rather detailed instructions about the installation and here I am not going to reproduce those details - refer to Ref. [1].  2. Initial setup Once Sphinx is installed, we may want to set up the building system initially, following the instruction provided with Sphinx official site - refer to Ref. [2] at this point. It is a common practice to put everything about the documentation building into a single dedicated directory, alongside the Python files containing our docstrings. For example, here following is presented the tree structure for one of my projects, . ‚îú‚îÄ‚îÄ LICENSE. txt ‚îú‚îÄ‚îÄ ‚Ä¶ ‚îú‚îÄ‚îÄ docs ‚îú‚îÄ‚îÄ requirements. txt ‚îú‚îÄ‚îÄ rmc_tools ‚îú‚îÄ‚îÄ ‚Ä¶ whereby rmc_tools is a folder containing a whole bunch of Python scripts containing docstrings in each of them and docs is the folder where I put the documentation building system.  3. Documentation tree After initial setup, we can start to put together the documentation tree so that we can further use Sphinx to build our documentation. Here in my example, the whole documentation tree (in which each file is following the reStructuredText format) is stored in the source directory. The following is presented the overall tree structure for the documentation (i. e. stuff put under docs directory), . ‚îú‚îÄ‚îÄ Makefile‚îú‚îÄ‚îÄ make. bat‚îî‚îÄ‚îÄ source  ‚îú‚îÄ‚îÄ _static  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ init. py  ‚îú‚îÄ‚îÄ conf. py  ‚îú‚îÄ‚îÄ ext_links. rst  ‚îú‚îÄ‚îÄ index. rst  ‚îú‚îÄ‚îÄ install. rst  ‚îú‚îÄ‚îÄ installation  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ rmc_modules_install. rst  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ rmc_tools_install. rst  ‚îú‚îÄ‚îÄ rmc_modules  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bulk_stuff. rst  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ nano_stuff. rst  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ rmc6f_stuff. rst  ‚îú‚îÄ‚îÄ rmc_modules. rst  ‚îú‚îÄ‚îÄ rmc_tools  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bulk_shells. rst  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ np_gen. rst  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ np_lin_analyzer. rst  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ np_shells. rst  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ rmc_strain. rst  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sofq_calib. rst  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ topas4rmc. rst  ‚îî‚îÄ‚îÄ rmc_tools. rst Then located in docs directory on terminal, we can simply execute make html to build up the documentation HTML pages. Things should start to roll like a charm at this point and following I note down several aspects we may want to pay attention to as we follow the procedures,  rst files could be grouped into dedicated folders and referred to in a separate rst file - like what we have above for the rmc_tools. rst file which contains references to those rst files in rmc_tools folder.    The rst file at the fundamental level should then contain reference to the docstring in Python file. For example in the rmc_tools/bulk_shells. rst file, it refers to the NP_Shells/bulk_shells. py file located in the main project directory. To let the building system find the Python file, we need to tell the building engine where those scripts are located. This can be done through the conf. py file located under source directory. Sometimes, we may think that if we have an entry in a rst file like . . automodule:: RMC_Strain_Analyzer. rmc_strain, it is enough to specify the parent directory where RMC_Strain_Analyzer is located. However, this turns out to be not the case - we need to include the full path to RMC_Strain_Analyzer in the system path as well. &lt;/li&gt; 4. Go online Upload documentation to online service so that it can be accessed by public. To do this, we can use the service provided by readthedocs. Here I will take the combination of readthedocs with GitHub as the example. If we have suitable directory setup as discussed above, e. g. everything concerning the documentation setup is contained in docs directory, and we have the whole project available in GitHub repository, we can set up a readthedocs account using our GitHub account, after which we can then import our GitHub repository holding the documentation project without problem. Once we are done the link between GitHub and readthedocs, any time we push something to our GitHub repository, the documentation will be built automatically and will be made available through readthedocs service.  Sometimes, certain Python scripts involved in the documentation building will try to import external modules, e. g. numpy or whatever - in this case, we need to tell readthedocs service explicitly what external modules we need. Otherwise, readthedocs won‚Äôt be able to find those necessary modules on its building server and therefore will fail the corresponding part of documentation building. As a comprehensive example, the GitHub repository given in Ref. [3] could be used as the template for documentation building with Sphinx.  References [1] https://www. sphinx-doc. org/en/master/usage/installation. html [2] https://www. sphinx-doc. org/en/master/usage/quickstart. html [3] https://github. com/Kvieta1990/rmc_adv_tools "
    }, {
    "id": 45,
    "url": "http://localhost:4001/2021-05-17-jup_kernel/",
    "title": "Jupyterlab kernel setup",
    "body": "2021/05/17 -  When trying to set up our own Jupyterlab server where general users can visit and use, the link in Ref. [1] could be followed. Once we follow literally the step-1 specified in the link, the server should be running without problem and we can just start using our own online Jupyterlab service. However, since the Jupyterlab service we just set up is a system-wise available service and therefore when we want to add kernels to the Jupyterlab service, we cannot use those kernels belonging to a specific user. Instead, we should set up system-wise available environment which then can be used as system-wise available kernels. The step-2 in Ref. [1] provides us with a generic way to set up the system-wise available environment using conda. Definitely we can follow the instructions there to set up conda in such way that conda itself is also system-wise available. As an alternative, we can be a bit flexible - we can use general users‚Äô local conda environment to do this as well, as long as the general user has the sudo privilege. For example, the following commands could be executed to set up the system-wise available Python environment,  sudo ~/miniconda3/condabin/conda create ‚Äìprefix /opt/conda/envs/py37 python=3. 7sudo /opt/conda/envs/py37/bin/python -m pip install ipykernelsudo /opt/conda/envs/py37/bin/python -m ipykernel install ‚Äìname py37 ‚Äìdisplay-name ‚ÄúPython (py37)‚Äù ‚Äìprefix=/usr/local/ In this way, the py37 environment could also be accessed across the system by all logged in users.  References [1] https://jupyterhub. readthedocs. io/en/1. 2. 0/installation-guide-hard. html "
    }, {
    "id": 46,
    "url": "http://localhost:4001/2020-12-21-notes_mag_III/",
    "title": "Notes on magnetism - III",
    "body": "2020/12/21 -  Talking about magnetic field, we have three relevant physical quantities - magnetic field (\vec{H}), magnetic induction field (\vec{B}) and magnetization field (\vec{M}). It is straightforward to understand (\vec{M}) - when applying magnetic field (here, by ‚Äòmagnetic field‚Äô, we mean something in general, but not specifically refer to (\vec{H})), we use (\vec{M}) to characterize how much the matter in question is magnetized. However, concerning (\vec{H}) and (\vec{B}), it seems that both are describing some sort of ‚Äòstrength‚Äô of magnetic field (again, we mean ‚Äòmagnetic field‚Äô in general. The same applies below until we become specific about what we mean by ‚Äòmagnetic field‚Äô). But why do we have two quantities here to describe the ‚Äòsame‚Äô thing? The answer is - they are not the same thing, as described by (\vec{H}) and (\vec{B}), respectively. Fundamentally, this goes back to the foundation of the electromagnetic theory - specifically, we mean the two historical discoveries. One is the finding that an electric current creates a magnetic field, by Oersted. The other is the discovery by Faraday that, in brief, a changing magnetic field will create electromotive force across an electrical conductor. The first one describes how a magnetic field can be generated from a current. Starting from such a discovery, if we are going to define a quantity to describe magnetic field, such a quantity will be bounded to electrical current, i. e. such a defined quantity for describing magnetic field can be purely derived from electrical current - this is the quantity (\vec{H}), to which we give the name of magnetic filed (we now become specific about what we mean by ‚Äòmagnetic field‚Äô). Concerning the second discovery, we also have a correspondingly defined quantity to describe the associated magnetic field (here, we go back to the general meaning of saying ‚Äòmagnetic field‚Äô, temporarily) ‚Äì the quantity we define as (\vec{B}), to which we give the name of magnetic induction field. Different from (\vec{H}), the quantity (\vec{B}) serves as the ‚Äòsource‚Äô of electric field, i. e. (\vec{B}) is considered to induce electric field (thus given the name magnetic induction field) and therefore (\vec{B}) does not have to originate itself purely from electrical current. In another word, when we talk about the induction of electric field from magnetic ‚Äòstuff‚Äô, we mean every aspect of the magnetic ‚Äòstuff‚Äô, including both that generated from electrical current (i. e. the magnetic field (\vec{H})) and the magnetization effect of matter (i. e. , the magnetization field (\vec{M})). After all, the following relation summarizes the discussion above, [\vec{B} = \mu_0\vec{H} + \vec{M}] The two discoveries mentioned above were further summarized into Maxwell‚Äôs equation in matter (i. e. , non-vacuum), respectively, [\nabla \times \vec{E} = -\frac{1}{c}\frac{\partial \vec{B}}{\partial t}] [\nabla \times \vec{H} = \frac{1}{c}(4\pi \vec{J}_f + \frac{\partial \vec{D}}{\partial t})] In summary, (\vec{H}) can be thought of as being purely coming from electrical current, whereas (\vec{B}) covers both the part originating from electrical field and that from matter magnetization (i. e. , a comprehensive ‚Äòmagnetic field‚Äô) ‚Äì that‚Äôs why the Gauss‚Äôs law for magnetism is summarized as (\nabla \cdot \vec{B} = 0), where the comprehensive quantity (\vec{B}) is used instead of (\vec{H}). "
    }, {
    "id": 47,
    "url": "http://localhost:4001/2020-12-18-spin/",
    "title": "About electron spin",
    "body": "2020/12/18 - Illustration for Stern-Glach experiment [1].  Angular moment means rotation - this applies to electron as well. For electrons, any movement is associated with current and therefore angular moment naturally is tightly linked to current as well. Furthermore, current means magnetic field, as originated by Orsted. Mathematically, starting from expressing the current with the angular moment of rotating electrons, followed by detailed mathematics based on Biot-Savart law (induction (\vec{B}) as the function of current), one can arrive at the expression of magnetic induction in terms of magnetic (dipole) moment (\vec{m}_l). In another word, it can be shown that the magnetic field generated by electron rotation current is equivalent to that generated by magnetic dipole, with the equivalent dipole moment defined as (see Ref. [2] for detailed derivation), [\vec{m}_l = -\frac{1}{2}eR^2\vec{\omega}] Given that the angular moment can be written as (\vec{l} = m_eR^2\vec{\omega}), we can obtain the following relation, [\vec{m}_l = -\frac{e}{2m_e}\vec{l}] Defining the Bohr magneton as, [\mu_B := \frac{e\hbar}{2m_e}] we arrive at the more familiar expression for the magnetic dipole moment, [\vec{m}_l = -\mu_B\frac{1}{\hbar}] This is what we mean by angular moment quantum number (l) in quantum mechanics. When we say the electron angular moment quantum number is 1, we mean, actually, (l = \hbar), as in the equation given above. Everything now does not seem to be so strange yet - at least we can somehow start from classic mechanics to arrive at expression for quantum mechanics. However, things change a bit as we start to think about electron spin. Following the idea presented above, we know that electron spin should have similar expression as above for its corresponding effective magnetic dipole moment, i. e. [\vec{m}_s = -\mu_B\frac{\vec{s}}{\hbar}] since anyways electron spin is indeed a sort of rotation, if we consider electron spin purely as classic phenomenon. However, in fact what we have is, [\vec{m}_s = -g\mu_B\frac{\vec{s}}{\hbar}] where, if ignoring other effect (e. g. spin-orbital coupling), we would have (g = 2). But, where does the extra factor (g) comes from? Why do we need it? The reason is, if following the same format of the magnetic dipole moment expression, as for the orbital angular moment, we just have to have (g = 2) to have such a correspondence that (g\vec{s} \sim \vec{l}), since simply we have the spin quantum number for electron to be (\frac{1}{2}). But why do we have electron spin as one half? Why cannot we have electron spin quantum number as 1 so that we do not need to worry about the extra factor (g) at all? The reason goes way back to the Stern-Gerlach experiment, in which it was shown that the split of electron spin in magnetic filed is 2. In another word, we have two possible projections of spin onto the (z)-axis (the direction along the magnetic field). From the basic principle of quantum mechanics, we know that we have to have the electron spin quantum number to be (\frac{1}{2}) for such a splitting behavior of electron spin in magnetic field. More notes about this can be found in Ref. [3] - basically, the principle is the number of projections along the direction of magnetic field (our (z)-axis) should be (2l + 1), where we use (l) to represent angular moment in general.  N. B. (l) in quantum mechanics is usually used to represent orbital angular moment, but here we are using (l) to represent angular moment in general, i. e. it can refer to either orbital angular moment or electron spin angular moment. References [1] http://hyperphysics. phy-astr. gsu. edu/hbase/spin. html [2] http://u. pc. cd/ydWrtalK [4] https://www. iris2020. net/2020/03/notes-on-magnetism-i-magnetism-of-free. html "
    }, {
    "id": 48,
    "url": "http://localhost:4001/2020-12-01-rmc_configure/",
    "title": "Configure RMCProfile",
    "body": "2020/12/01 -    Configuration on Linux system          rmcprofile on cluster      To run rmcprofile on cluster, the following bash script may be helpful,       #!/bin/bash ulimit -s unlimited export OMP_NUM_THREADS=12 RMCProfile_PATH=WHEREVER_RMCProfile_FOLDER_IS_LOCATED export PGPLOT_DIR=$RMCProfile_PATH/exe/libs export LD_LIBRARY_PATH=$RMCProfile_PATH/exe/libs export LIBRARY_PATH=$RMCProfile_PATH/exe/libs export PATH=$PATH:$RMCProfile_PATH/exe $RMCProfile_PATH/exe/rmcprofile stem_name        where WHEREVER_RMCProfile_FOLDER_IS_LOCATED refers to the main  RMCProfile directory within which the exe and tutorial  sub-directories are usually located. stem_name refers to whatever the stem name is for our RMC fitting. Put this script within RMC  fitting directory and run it from there should not be a bad idea.           Speeding up rmcprofile     No matter running on clusters or a PC, running the following two  commands just before kicking off RMC fitting should help speeding up the fitting.      ulimit -s unlimited export OMP_NUM_THREADS=12             Configuration on MacOS          Speeding up rmcprofile     Running the following two commands just before kicking off RMC fitting should help speeding up the fitting.      ulimit -s unlimited export OMP_NUM_THREADS=12          "
    }, {
    "id": 49,
    "url": "http://localhost:4001/2020-11-28-notes_jekyll/",
    "title": "Notes on Jekyll",
    "body": "2020/11/28 -  One can follow Ref. [1] to build up site with Jekyll - it contains quite a few steps concerning the set-up of sites through GitHub pages. However, this is not necessary if one just wants to set up site locally and test. Therefore, after installing Ruby and Bundle, one can directly create a local folder and go into it. From there, one needs to follow the steps given below,1. Run bundle init - this will create the Gemfile. 2. According to Ref. [1], GitHub pages depends on certain version of packages (a link can be found there in Ref. [1] about details) and therefore one may need to install certain version of Jekyll with Bundle (though, again this may not be necessary if one only wants to do it locally). To install a certain version of Jekyll with Bundle, one need to put in the following line into Gemfile,  gem ‚Äòjekyll‚Äô, ‚Äò3. 9. 0‚Äô 3. Then one needs to execute bundle install to install the required version of Jekyll. 4. At this stage if one continues, as instructed in Ref. [1], to execute bundle exec jekyll new . , most likely error will occur, complaining that the directory is not empty (since we created the Gemfile in previous step for installing the right version of Jekyll). In this case, one just executes the following command, bundle exec jekyll new ‚Äìforce . , which will by force overwrite the already existing Gemfile. 5. To test locally, one simply executes the following command, bundle exec jekyll serve to start the service, where one should be able to see the localhost that we need to open in browser to check our template site!More reference materials can be found in Refs. [2-4].  Typical issues - 1    Load error: cannot load such file ‚Äì webrick Solution Run the command, bundle add webrick.  References [1] https://docs. github. com/en/free-pro-team@latest/github/working-with-github-pages/creating-a-github-pages-site-with-jekyll [2] https://docs. github. com/en/free-pro-team@latest/github/working-with-github-pages/testing-your-github-pages-site-locally-with-jekyll [3] https://pages. github. com/versions/ [4] https://bundler. io/gemfile. html "
    }, {
    "id": 50,
    "url": "http://localhost:4001/2020-11-22-kde/",
    "title": "Notes on kernel density estimation",
    "body": "2020/11/22 - With a collection of data, we may want to extract or estimate the underlying distribution model. For example, we have the collection of house price in a certain area, we want to have an idea about how the house price in that area is distributed. However, without a priori knowledge about what the model that distribution should follow, we cannot follow the so-called parameterized way for estimating the distribution. In that way, we know beforehand about what the distribution model should be and it‚Äôs just some parameters yet need to be determined. Then we can do the commonly used least-square fitting to obtain those unknown parameters. However, it is usually the case where we have no knowledge about what the distribution model should look like, in which case we need a non-parameterized approach to estimate the underlying distribution, e. g. the histogram method and the one we are going to focus here: kernel density estimation (KDE). Here is the formulation of KDE, [\hat{f}(x_0) = \frac{1}{Nh}\sum_{i=1}^N K(\frac{x_i - x_0}{h})] where (h) is called the bandwidth which plays an important role in determining our estimation for the distribution density. (K) is just our kernel function, for which we may have several alternative choices - a Gaussian kernel is usually used. Detailed introduction about mathematics of KDE can be found in Ref. [1] and we are not going to reproduce them here. Instead I put several key points as follows, which I think is quite important for better understanding the KDE method,  Wherever we have an observed data, we should put a corresponding kernel there.  The kernel function we put at each observed data point is a normalized distribution function, for which the probability density is the highest at each corresponding observed data point.  The fundamental idea behind the kernel approach is that around each observed data point, the further we go away from the observed data point, the less our probability density should be.  The overall sum of all the kernels should be normalized to 1, i. e. the overall probability should obviously be 1. There are more technical details about KDE, for which one can refer to the introduction given by Ref. [1]. Here we use two simple animations to demonstrate the idea about KDE, as presented below,  The left-hand side figure gives the situation where all five data points fall onto the same position and the KDE distribution stays all the same as we have more data coming. The right-hand side figure gives more general situation where all five data points fall onto different positions, from which one can clearly see how the estimation of KDE distribution varies as we collect more and more data points.  ========================I AM A SEPARATOR======================== ‚òùAbout the influence of norm choice upon KDE for higher dimension The idea of KDE can be easily extended to higher dimensions and the idea is still the same - the further we go away from the center of a specific kernel, the less distribution probability we will have. However, for high dimensions, it is not as straightforward as it is for 1D case, in terms of how we define the distance from the kernel center. Mathematically, the distance we mean here is actually a norm of a certain type, e. g. L0 norm, L1 norm or L2 norm, ‚Ä¶ According to the definition of norm,       [   ¬†   \vec{x}   ¬†   _p = \sqrt[\leftroot{-1}\uproot{5}p]{\sum_i   x_i   ^p}]   where (p\in{\rm I!R}). For 1D situation, the value of various different L norms is the same (except L0 norm, which is kind of special - see note below), since simply we have only one entry in the vector. But going to higher dimensions, we have more entries in the vector and therefore different L norms do give different distances. Therefore, choosing different L norms for the KDE analysis will influence the results, especially when we have limited number of input data points. Detailed discussion about the influence of different L norm choices can be found in Ref. [1]. N. B. There are two special L norms - L0 norm and L-Infinity norm - among which L0 norm is even more problematic since we don‚Äôt have rigorous definition for what (\sqrt[0]{n}), where (n\neq 0). Therefore, in practice, the L0 norm is actually defined as,       [   ¬†   \vec{x}   ¬†   _0 = #(i   x_i\neq 0)]   where (#) means ‚Äòthe number of‚Äô. As for the L-Infinity norm, it means the maximum entry in the vector component. This is relatively straightforward to follow - given the mathematical definition of L norm above, the maximum entry will be the only one dominating as compared to all the other entries, considering the infinity power. Refer to Ref. [2, 3] for more detailed discussion about L norms.  References [1] https://www. youtube. com/watch?v=x5zLaWT5KPs&amp;list=PLAYk0l7EXZVumN_Uil7ou8WUBkrFkVE91 [2] https://rorasa. wordpress. com/2012/05/13/l0-norm-l1-norm-l2-norm-l-infinity-norm/ [4] https://www. evernote. com/l/AQpVf7ClpwZJp7qhPTXWRPHUZL2MAIUC40E "
    }, {
    "id": 51,
    "url": "http://localhost:4001/2020-11-20-flask/",
    "title": "Notes on Flask",
    "body": "2020/11/20 -  We follow the tutorial given in Ref. [1, 2] for setting up the web host using Python Flask module. Details will not be reproduced in current blog step by step. Instead, we will focus on 1) some key aspects to make step description clearer and 2) steps where error can easily occur. First, we give all the necessary recipes, as follows,  Flask - Python web server  uWSGI - Sitting in the middle between Flask and Nginx for connection purpose.  Nginx - Facing outwards to receive request. and we will configure the web host on CentOS 7.  Traditionally, we have the web server hosts files in specific location on the server (e. g. /var/www) and then we will have, e. g. the Apache HTTP server to listen to user request (through a certain port, e. g. 80) and fetch certain files stored in specific location on the server and then send back to users‚Äô browser. When using Python to set up web host, we have one more layer for the connection between files on the server to be visited and users. The idea is that Python is responsible for creating contents, uWSGI is responsible for ‚Äòtranslating‚Äô and Nginx is responsible for receiving from users for request and sending back to users the ‚Äòtranslated‚Äô contents. ‚òùPreparation On CentOS 7, Nginx can be installed with yum,sudo yum install nginxSometimes, it may also be necessary to install pip and python-devel if they are not already [3, 4],sudo yum install python-pip python-develWith Python 3, we may need to change the command to [5, 6, 13, 14],sudo yum install python3-pip python37-devel(here we take Python 3. 7 as an example). It is always recommended that we should create dedicated environment when setting up the web host with Python. Therefore, either we can follow the instruction given in Ref. [1, 2] to install and set up virtual Python environment using virtualenv using pip. Or we can use conda to set up the dedicated Python environment. Within the created environment, we can either use pip or conda to install necessary packages, namely uwsgi and flask. In some cases, using pip to install uwsgi may return error, where one has to use conda to install it. N. B. Though the packages are installed within certain environment (which seems not accessible from outside the environment), they can still be accessed from outside - the reason simply is that when a specific version of Python is used in question (e. g. that within a certain environment), all the packages installed within the corresponding environment will become available.  ‚òùA simple start With just Flask installed (no Nginx, no uWSGI), one can already host a web - that‚Äôs why we call Flask a Python web server, since simply with it we can just host a web server! Refer to Ref. [1, 2] for a Hello World demo with a simple Python script.  ‚òùCreate the WSGI entry point Now we go a bit further to start the web host through WSGI entry point. According to Ref. [1, 2], the entry point here is just a simple Python script which first imports the Python method (containing the Flask app) and then run it. In Ref. [1, 2], the entry point script and the main Python app script are put together under the same directory. But in practice, we don‚Äôt have to do that - the import command in the entry point script should specify where to find the main app script. N. B. By default, uwsgi expects application as our app name. If we want to use another name for the app (specified in the main app Python script), we should specify the callable app name [7, 8]. When starting the uWSGI service directly from command line, we should have,uwsgi --socket 0. 0. 0. 0:8000 --protocol=http --callable myapp -w runwhere myapp is our app name and run is the entry point script stem name. N. B. We should not use port 80 in the entry point script [9].  ‚òùConfiguring Nginx The last step is to configure Nginx - to establish the connection between outside world and our Python app (through uWSGI as the interface as discussed above). To do this, again we should follow steps in Ref. [1, 2] and details won‚Äôt be reproduced here. One critical parameter to mention is the location of the socket file - this file is like a junction between Nginx and uWSGI and therefore in the configuration files of both, the socket file should be with exactly the same name. Another potential issue to mention here is that, though Ref. [1, 2] mentions some file/folder permission configuration concerning setting up Nginx, in practice we may still have issues establishing the connection. The common problem is 502 bad gateway issue. Once this occurs, we can consider the following potential solutions,  Open port in firewall configuration. In CentOS 7, this may require the installation of `firewalld` package and following the instruction given in Ref. [11] for how-to.  If web server is within a certain organization network, we may need to check the firewall restriction of the organization network as well. Specifically for CADES service at ORNL, we need to follow the instruction in Ref. [12] for how-to.  We may want to disable SELinux, according to the comments in Ref. [1, 2]. plus those mentioned in Ref. [1, 2].  ========================I AM A SEPARATOR======================== ‚òùNotes on setting up pdfitc on CADES hosted at ORNL    We want to follow Long‚Äôs instruction in Ref. [15] for step-by-step procedures (see the ‚ÄòHow to install‚Äô section). We want to skip step-#5 and also for step-#7, the file we want to configure for implementing GSAS II is ‚Äòrun_gsas2_calc. py‚Äô under ‚Äòpdfitc‚Äô folder. The line we want to change is the one containing ‚Äòsys. path. insert‚Äô.     The folder cloned from Long‚Äôs ‚Äòtsitc‚Äô repository is not complete - some files and folders are missing which will cause the app not starting. We need to back up Long‚Äôs working version to a separate repository and develop from there (need to post the new repository here once it‚Äôs done).     For running the pdfitc service (edit ‚Äò/etc/systemd/system/pdfitc. service‚Äô file if changes to the service are needed) for the first time, we may encounter problems about modules not found. Usually, the missing modules (e. g. dash) should be straightforward to install with, e. g. conda.     The ‚Äòcelery. task‚Äô method has been deprecated and therefore is no longer available with celery. Accordingly in the main ‚Äòapp. py‚Äô file, we want to comment out the import line for ‚Äòcelery. task‚Äô and change ‚Äòrevoke‚Äô to ‚Äòapp. control. revoke‚Äô [16, 17].  References [1] https://www. digitalocean. com/community/tutorials/how-to-serve-flask-applications-with-uwsgi-and-nginx-on-centos-7 [2] https://www. evernote. com/l/AQrJngSLeBxB0okR7mOoGaUV072RVCnFd2M [3] https://stackoverflow. com/questions/44037637/error-installing-uwsgi-in-virtualenv [4] https://www. evernote. com/l/AQpLAsPHMUdGBp-p5Y-y7Zvfe7Bvip53n84 [5] https://stackoverflow. com/questions/23541205/cant-install-python-dev-on-centos-6-5 [6] https://www. evernote. com/l/AQptvLJl0n9OzIm13ajH6X1VrYTsq9DxidE [7] https://stackoverflow. com/questions/12030809/flask-and-uwsgi-unable-to-load-app-0-mountpoint-callable-not-found-or-im [8] https://www. evernote. com/l/AQrMIOSck-VJQ6E5qeo_tsWxMVAJBwiRhoQ [9] https://stackoverflow. com/questions/51396047/running-flask-on-port-80-in-linux [10] https://www. evernote. com/l/AQqJG6XKtOxDtbIggIY2RwH1Mn2U3lcgbdM [11] https://www. tecmint. com/fix-firewall-cmd-command-not-found-error/ [12] https://docs. cades. ornl. gov/#openstack/manage-vm/create-new-security-group/ [13] https://phoenixnap. com/kb/how-to-install-pip-on-centos-8 [14] https://www. evernote. com/l/AQqEzk-6MpBOT5lTrj1N-Viu5MZOEXuT9y4 [15] https://code. ornl. gov/ly0/tsitc/-/tree/master/ [16] https://github. com/celery/celery/issues/6406 [17] https://docs. celeryproject. org/en/latest/userguide/workers. html#revoke-revoking-tasks "
    }, {
    "id": 52,
    "url": "http://localhost:4001/2020-09-25-rsa/",
    "title": "Notes on RSA algorithm",
    "body": "2020/09/25 - Image reproduced from Ref. [9]. In this post, i will note down my learning and understanding for the RSA algorithm. This will not go into deep details about RSA. Instead, only basics will be covered. In fact, most of the discussion presented here has already been covered in the relevant Wiki page: Click Me! Basically, I will just follow the Wiki page and put in my understanding along the way. Specially, when we go into the working example of RSA algorithm, detailed explanation about how the algorithm is realized in practice will be presented, with reference to some outstanding external resources. Finally, a bit understanding will be presented for why encryption and decryption through RSA algorithm is difficult or even impossible to decipher in practice and thus considered to be secure enough nowadays. ‚òùKeys generation1. Select two prime numbers (p) and (q). 2. Calculate (n = pq). 3. Calculate (\phi(n) = (p-1)(q-1)). 4. Select an integer (e) satisfying 1) (1 &lt; e &lt; \phi(n)) and 2) (e) is co-prime to (\phi(n)). 5. Calculate (d) to satisfy the congruence relation (de \equiv 1 (mod(\phi(n)))).  The congruence relation here reads, (de) and (1) are equivalent in terms of the remainder when divided by (\phi(n)). In this sense, it does not matter that much whether (de) or (1) sits on the left-hand side. (n) and (e) here are the public key that can be shared. (d) is the private key which should be kept securely. There is a question here: what we are generating is actually numbers, but that‚Äôs not what we usually see in public or private key file. For example, the example shows a demo for public key, where we actually do not see numbers but rather text. What is the trick here?    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC+Z2085MxeBuiQ77giIgwAjYWID4ze7pUk+Z+ANcWgX479KJPHROjuY7fH6bJ9KoRGqyc3vu72nC6WdLMD6i/p+dTUmAuXyFVlgJNFUeejyRZTWnglNnGxAvB9y5F0LsNHj+fumhKSk8zY+cs8/5JkKyNSCp6VzI7DNjPOQmuMdja9Km2CeLk963aUEvx+bfYB0sPvuQnhOwCmw0bAp68QW048IjKWfZPDZC6gKZBE6udeu+rGLVVsMVCjmMyllfVIajrwAVvevIhSaUVcr02j7Rq9jRDAxbqI6BWXxD7D2oi+eYXic6yE67qbxoYflC2eBHGVgvZRcctDe682aioYBHDXl22f+160KSm6gawYBJmymM7WotOsKpBCyM9d9ghw+U+pkAJXOSqqtuGypGMG3DXJQfO44DyETiL99OgC9g4+cioPxVbXsK/txUoXim1QOG+e91V31TxisSVcZL6JfD2KGAhz5Nuhrgw9fiw37VB8r1fRrwAIh7ztOa/Sakk= y8z@mac117849 In fact, the number generated from the RSA algorithm is stored in the so-called PEM file format, which involves obviously some encoding scheme turning those generated numbers into text for storage. In this following post, there is introduced some other available format for storing public key: Click Me!‚òùEncryptionFirst, the sender Bob needs to turn message M into a number m using some pre-agreed-upon protocol. Then Bob calculate the ciphered message c to send to the receiver following, [c = m^e\ \ mod\ n] ‚òùDecryptionWhen the receiver Alice receives the ciphered message c from Bob, she then needs to decode the original message m from c following, [m = c^d\ \ mod\ n] ‚òùDerivationGiven the way a certain message is encrypted and decrypted mentioned above, we only need to show, [c^d \equiv (m^e)^d \equiv m^{ed} \equiv m\ (mod\ n)]  Here, we need to remind ourselves again about the meaning of the congruence relation - see introduction above. Back to the step of key generation, the values of (e) and (d) were chosen so that, [ed \equiv 1\ (mod\ \phi(n))] Therefore, there exists some integer (k) so that, [ed = k\times\phi(n) + 1] Following that, we have, [\begin{equation}\begin{aligned}m^{ed} &amp; \equiv m^{k\phi(n) + 1}\ &amp; \equiv m\times m^{k\phi(n)}\ &amp; \equiv m\times(m^{\phi(n)})^k\ (mod\ n)\end{aligned}\nonumber\end{equation}] According to Wiki page, we can apply Euler‚Äôs theorem here, [m^{\phi(n)}\equiv 1\ (mod\ n)] to arrive at, [m\times (1)^k\equiv m\ (mod\ n)] However, Euler‚Äôs theorem actually applies to the situation where we have (m) and (n) involved here should be coprime. But in fact, it seems that (m) and (n) here may not be coprime - since (m) is generated from the message to be sent, which can be arbitrary. Concerning this confusion, here is a good reference for explanation: https://math. stackexchange. com/a/87720. ‚òùA Working ExampleA working example demonstrating the RSA algorithm is practice is presented in the PDF doc below,  When trying to decrypt the original message (m) from the encrypted message (c), the calculation we need to conduct, as shown in the PDF doc above, (c^{d}\ mod\ n) is usually quite computationally expensive, since the numbers involved in the calculation could be very large in practice. To speed up the calculation speed, the Chinese remainder theorem can be used here. The theorem says,  Suppose (p) and (q) are relatively prime, then (x \equiv a\ (mod\ pq)) if and only if (x\equiv a\ (mod\ p)) and (x\equiv a\ (mod\ q)). To demonstrate how the theorem can be used for message decryption, it is better to go with an example. We take the one given in Ref. [1] - (c = 17639), (d = 11613) and (n = 21829). We are going to calculate (m \equiv 17639^{11613}\ mod\ 21819). If we hold private key, then we know exactly (21829 = 83 \times 263). Therefore, according to the theorem, [m\equiv 17639^{11613}\ mod\ 83,\ \ m\equiv 17639^{11613}\ mod\ 263] Simplifying the first congruence, [\begin{equation}\begin{aligned}m &amp; \equiv 17639^{11613}\ mod\ 83\ &amp; \equiv 43^{11613}\ mod\ 83\end{aligned}\nonumber\end{equation}] where the second line of the simplification comes from the fact that (17639\equiv 43\ mod\ 83). Furthermore, according to Euler‚Äôs theorem mentioned above, the calculation can be further simplified, [\begin{equation}\begin{aligned}m &amp; \equiv 43^{51}\ mod\ 83\ &amp; \equiv 58\ mod\ 83\end{aligned}\nonumber\end{equation}] Just to remind ourselves with Euler‚Äôs theorem, ‚Äô‚Äô‚ÄôFor (a), (N) coprime, (a^{\phi(N)}\equiv 1\ mod\ N). ‚Äò‚Äô‚Äô Here we have (N = 83) itself is just a prime, and therefore (\phi(83) = 82), where (\phi(N)) is the number of positive integers smaller than (N) and coprime to (N). Therefore, if (N) is a prime, we know for sure [\phi(N) = N - 1] Then we have, [43^{11613}\ mod\ 83 = (43^{82})^{141}\times43^{51}\ mod\ 83 \equiv 1^{141}\times 43^{51}\ mod\ 83] As for how we go from the first line to the second one in the calculation presented above, refer to Ref. [2] for a YouTube demo for a general method. Following the same procedure, we can arrive at the following equation from the other congruent equation mentioned above, [m \equiv 44\ mod\ 263] Assuming (m) can be written as (m = 263x + 44), then we want to find (x) to satisfy, [263x + 44 \equiv 58\ mod\ 83] which can be further simplified to (14x \equiv 14\ mod\ 83). Then we can easily inspect the solution as (x = 1). For general situation of solving the congruent equations, refer to Ref. [3, 4]. ‚òùRSA for SSH connectionIntroduction about the application of RSA in SSH connection (the so-called ‚Äòasymmetric encryption‚Äô) is beyond the topic of current blog. Detailed explanation/introduction can be found in Refs. [5-8]. ‚òùIn brief, why RSA is difficult to hack?From the calculation presented above, we can see that to decrypt the encrypted message by the public key ((n) and (e)), one needs to know (d). To obtain (d), we actually start from (n) - however, knowing (n) is not enough, since it is beyond the capability of modern computer to calculate the two prime factors (p) and (q) from (n). This is the fundamental reason for why RSA algorithm is regarded as being safe enough for encryption and communication between client and server.  References [1] https://www. youtube. com/watch?v=NcPdiPrY_g8 [2] https://www. youtube. com/watch?v=tTuWmcikE0Q [3] https://www. expii. com/t/solving-linear-congruence-ax-b-mod-n-3389 [4] Evernote link to [3]. [5] https://www. hostinger. com/tutorials/ssh-tutorial-how-does-ssh-work [6] https://www. digitalocean. com/community/tutorials/understanding-the-ssh-encryption-and-connection-process [7] https://www. digitalocean. com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys [8] https://www. ssh. com/attack/man-in-the-middle [9] https://brosite. org/2020/12/27/the-ftc-is-investigating-data-collection-at-youtube-facebook-and-seven-other-companies/ "
    }, {
    "id": 53,
    "url": "http://localhost:4001/2020-07-27-thermo_2nd/",
    "title": "‰∏∫‰ªÄ‰πà‰∏çËÉΩÈÄöËøáËÆ©Êµ∑Ê∞¥‰∏çÊñ≠ÈôçÊ∏©‰ªéËÄåËé∑ÂèñÊó†Â∞ΩÁöÑËÉΩÈáèÔºü",
    "body": "2020/07/27 -        Ê†πÊçÆÁÉ≠ÂäõÂ≠¶Á¨¨‰∫åÂÆöÂæãÁöÑÂºÄÂ∞îÊñáË°®Ëø∞Ôºå‰∏çÂèØËÉΩ‰ªéÂçï‰∏ÄÁÉ≠Ê∫êÂê∏ÁÉ≠Âπ∂ÂÖ®ÈÉ®Áî®Êù•ÂÅöÂäüËÄå‰∏çÂºïËµ∑ÂÖ∂‰ªñÂèòÂåñÔºå‰ªéËøô‰∏™ËßíÂ∫¶ÂÆåÂÖ®ÂèØ‰ª•ËØ¥Êòé‰∏∫‰ªÄ‰πà‰∏çËÉΩ‰ª•Êµ∑Ê∞¥‰∏∫Âçï‰∏ÄÁÉ≠Ê∫êÔºå‰ªéÂÆÉËé∑ÂèñÊ∫êÊ∫ê‰∏çÊñ≠ÁöÑËÉΩÈáèÂπ∂Áî®Êù•ÂÅöÂäü„ÄÇÂà∞ËøôÈáå‰ºº‰πéÈóÆÈ¢òÂ∞±Â∑≤ÁªèÁªìÊùü‰∫ÜÔºå‰ΩÜÊòØÂ¶ÇÊûúÊµ∑Ê∞¥Âπ∂‰∏çÊòØ‰ΩìÁ≥ªÂΩì‰∏≠ÂîØ‰∏ÄÁöÑÁÉ≠Ê∫êÔºåÈô§Ê≠§‰πãÂ§ñËøòÂ≠òÂú®Âè¶Â§ñ‰∏Ä‰∏™È´òÊ∏©ÁÉ≠Ê∫êÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºå       Âú®ËøôÁßçÊÉÖÂÜµ‰∏ãÊòØÂê¶ËÉΩÂÆûÁé∞ÈÄöËøáËÆ©Êµ∑Ê∞¥‰∏çÊñ≠ÈôçÊ∏©Â∞ÜÁÉ≠Èáè‰º†ÂêëÈ´òÊ∏©ÁÉ≠Ê∫ê‰ªéËÄåÊ∫êÊ∫ê‰∏çÊñ≠ÁöÑÂêëÂ§ñËæìÂá∫ÂäüÔºüÂêåÁêÜÂèØ‰ª•ÈóÆÁ±ª‰ººÁöÑ‰∏Ä‰∏™ÈóÆÈ¢òÔºåËÉΩÂê¶Â∞ÜÂÜ∞ÁÆ±Âú®Âà∂ÂÜ∑ÁöÑËøáÁ®ã‰∏≠ÊîæÂá∫ÁöÑÁÉ≠ÈáèÊî∂ÈõÜËµ∑Êù•ÁÑ∂ÂêéÂ∏¶Âä®ÁÉ≠Êú∫ÂØπÂ§ñÂÅöÂäüÔºåÊàñËÄÖÂπ≤ËÑÜÂ∏¶Âä®ÂÜ∞ÁÆ±Ëá™Â∑±Êù•ÂÆûÁé∞‰∏ã‰∏ÄËΩÆÁöÑÂà∂ÂÜ∑ËøáÁ®ãÔºå‰ªéËÄåÂÆûÁé∞ÂÜ∞ÁÆ±Ëá™Â∑±Â∏¶Âä®Ëá™Â∑±Âà∂ÂÜ∑ËøõËÄåÊó†ÈôêÂæ™ÁéØ‰∏ãÂéªËÄå‰∏çÈúÄË¶ÅÂ§ñÁïåÊèê‰æõ‰ªª‰ΩïËÉΩÈáèÔºü‰∏§‰∏™ÈóÆÈ¢òÁöÑÁ≠îÊ°àÊòæÁÑ∂ÈÉΩÊòØÔºå‰∏çËÉΩ„ÄÇÂ¶ÇÂõæÊâÄÁ§∫ÔºåÂ∑¶ÂçäÈÉ®ÂàÜ‰ª£Ë°®ÁöÑÊòØÂÜ∞ÁÆ±Âà∂ÂÜ∑ÁöÑËøáÁ®ãÔºà‰πüÂèØ‰ª•‰ª£Ë°®Êµ∑Ê∞¥ÈôçÊ∏©ÂêëÂ§ñÊîæÁÉ≠ÁöÑËøáÁ®ãÔºâÔºåËøôÈáåÂÆûÈôÖ‰∏äÂ∞±ÊòØÁÉ≠ÂäõÂ≠¶Á¨¨‰∫åÂÆöÂæãÁöÑÂÖãÂä≥‰øÆÊñØË°®Ëø∞ÔºåË¶ÅÊÉ≥ÂÆûÁé∞ÁÉ≠Èáè‰ªé‰ΩéÊ∏©ÁÉ≠Ê∫ê‰º†ÂêëÈ´òÊ∏©ÁÉ≠Ê∫êÔºåÂ§ñÁïåÊòØÂøÖÈ°ªË¶ÅÂÅöÂäüÁöÑÔºàÂõæ‰∏≠(W_1)ÔºâÔºåÂè≥ÂçäÈÉ®ÂàÜÂØπÂ∫îÁöÑÊòØ‰ªéÈ´òÊ∏©ÁÉ≠Ê∫êÊî∂ÈõÜÁÉ≠ÈáèÂÜçÁî®Êù•È©±Âä®ÁÉ≠Êú∫ÂØπÂ§ñÂÅöÂäüÁöÑËøáÁ®ãÔºåËøôÈáåÂØπÂ∫îÁöÑÊòØÁÉ≠ÂäõÂ≠¶Á¨¨‰∫åÂÆöÂæãÁöÑÂºÄÂ∞îÊñáË°®Ëø∞ÔºåÂú®È©±Âä®ÁÉ≠Êú∫ÂÅöÂäüÁöÑËøáÁ®ã‰∏≠ÔºåÊòØÂøÖÈ°ªË¶ÅÂêë‰ΩéÊ∏©ÁÉ≠Ê∫êÔºàÂÜ∞ÁÆ±ÔºåÊàñËÄÖÊµ∑Ê∞¥ÔºâÊîæÂá∫‰∏ÄÂÆöÁöÑÁÉ≠ÈáèÁöÑ„ÄÇÂ¶ÇÊûúÊÉ≥Ë¶ÅÂÆûÁé∞‰∏äÈù¢ÊâÄËØ¥ÁöÑ‰∏§‰∏™Ê∞∏Âä®Êú∫ÔºåÊï¥‰∏™ÂõæÁ§∫ÁöÑËøáÁ®ãÁªºÂêàËµ∑Êù•ÊúÄÁªàË¶ÅÊª°Ë∂≥‰∏Ä‰∏™ÂÖ≥Á≥ªÔºö(W_2 &gt; W_1)ÔºåÂõ†‰∏∫Âè™ÊúâËøôÊ†∑ÊâçÊúâÊúâÊïàÁöÑÂØπÂ§ñÂáÄËæìÂá∫„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂ¶ÇÊûúËøôÈáåÊèêÂà∞ÁöÑ‰∏§‰∏™Ê∞∏Âä®Êú∫ËÉΩÂ§üÂØπÂ§ñËæìÂá∫ÁöÑÂäüËøò‰∏çÂ§üËÆ©‰ΩéÊ∏©ÁÉ≠Ê∫êÈôçÊ∏©ÊâÄÈúÄË¶ÅÂÅöÁöÑÂäüÔºàÊàñËÄÖÂàöÂ•ΩËÉΩÂ§üÊèê‰æõ‰ΩéÊ∏©ÁÉ≠Ê∫êÈôçÊ∏©ÊâÄÈúÄË¶ÅÂÅöÁöÑÂäüÔºâÔºåÈÇ£‰πàËøô‰∏™Êó∂ÂÄôÊ≠§Á±ªÊ∞∏Âä®Êú∫Ê†πÊú¨‰∏çÊòØ‚ÄúÊ∞∏Âä®‚ÄùÁöÑÔºàÂõ†‰∏∫ÂÆÉÊó†Ê≥ïÂêëÂ§ñÁïåËæìÂá∫ÊúâÁî®ÂäüÔºâ„ÄÇÈíàÂØπ(W_1=W_2)ÁöÑÊÉÖÂÜµÈúÄË¶Å‰∏ÄÁÇπÁâπÊÆäËØ¥ÊòéÔºåËøô‰∏™Êó∂ÂÄôÔºå‰∏äÈù¢ÊèêÂà∞ÁöÑ‰∏§‰∏™Ê∞∏Âä®Êú∫ÁêÜËÆ∫‰∏äÊòØÂèØ‰ª•‚ÄúÊ∞∏Âä®‚ÄùÁöÑÔºåÂè™ÊòØÊó†Ê≥ïÂêëÂ§ñÁïåËæìÂá∫Âäü„ÄÇ‰ΩÜÊòØÂÆûÈôÖ‰∏äËøô‰πüÊòØ‰∏çÂèØËÉΩÁöÑÔºåÂõ†‰∏∫ÁÉ≠Êú∫Âú®ËøêËΩ¨ÁöÑËøáÁ®ã‰∏≠ÊÄªÊòØÂ≠òÂú®ÂêÑÁßçËÉΩÈáèÊçüËÄóÔºåÂ¶ÇÊûú(W_1 = W_2)ÔºåÈÇ£‰πà‰ΩìÁ≥ªÊòØÊ≤°ÊúâÂ§ö‰ΩôÁöÑËæìÂá∫Êù•ÊäµÊ∂àÂì™ÊÄïÊòØ‰∏ùÊØ´ÁöÑÊçüËÄóÁöÑÔºåËøôÊó∂Ê∞∏Âä®Êú∫‰πüÂ∞±Êó†Ê≥ï‚ÄúÊ∞∏Âä®‚Äù‰∫Ü„ÄÇËøôÊúâÁÇπÁ±ª‰ºº‰∫éËØ¥Áâ©‰ΩìÂú®Ê∞¥Âπ≥ÊñπÂêë‰∏çÂèóÂ§ñÂäõÁöÑÊÉÖÂÜµ‰∏ãÂèØ‰ª•Âú®Ê∞¥Âπ≥ÁªùÂØπÂÖâÊªëÁöÑÂπ≥Èù¢‰∏ä‰∏ÄÁõ¥ËøêÂä®‰∏ãÂéªÁöÑÔºå‰ΩÜÊòØÂÆûÈôÖ‰∏äÁªùÂØπÂÖâÊªëÁöÑÂπ≥Èù¢ÊòØ‰∏çÂ≠òÂú®ÁöÑ„ÄÇÂêåÁêÜÔºåÊ≤°ÊúâÊçüËÄóÁöÑÁÉ≠Êú∫‰πüÊòØ‰∏çÂ≠òÂú®ÁöÑÔºåÂõ†ËÄå(W_1=W_2)‰πüÊòØÊó†Ê≥ï‰øùËØÅÊ∞∏Âä®Êú∫‚ÄúÊ∞∏Âä®‚ÄùÁöÑ„ÄÇË¶ÅÊª°Ë∂≥(W_2 &gt; W_1)ÔºåÊÄª‰Ωì‰∏äÁúãÔºåÂ¶ÇÂõæÊâÄÁ§∫ÔºåËøôÂ∞±Áõ∏ÂΩì‰∫é‰ªéÈ´òÊ∏©ÁÉ≠Ê∫êÊîæÂá∫‰∫Ü((Q_2^{‚Äò} - Q_2) - (Q_1^{‚Äò} - Q_1))ÁöÑÁÉ≠ÈáèÂÖ®ÈÉ®Áî®Êù•ÂÅöÂäüËÄåÂπ∂Ê≤°ÊúâÂºïËµ∑ÂÖ∂‰ªñÂèòÂåñÔºåËøô‰∏éÁÉ≠ÂäõÂ≠¶Á¨¨‰∫åÂÆöÂæãÁöÑÂºÄÂ∞îÊñáË°®Ëø∞ÊòØÁüõÁõæÁöÑÔºåÊâÄ‰ª•‰∏äÈù¢ÊèêÂà∞ÁöÑ‰∏§‰∏™Ê∞∏Âä®Êú∫ÈÉΩÊòØ‰∏çÂèØËÉΩÂ≠òÂú®ÁöÑ„ÄÇ "
    }, {
    "id": 54,
    "url": "http://localhost:4001/2020-07-22-temperature/",
    "title": "Notes On Temperature",
    "body": "2020/07/22 - üìåIntroduction - What is temperature?By temperature ((T)), we could mean simply the ‚Äòhotness‚Äô of something, i. e. as always the case in our daily life, the higher (T) of an object, the hotter it is. But in physics, when we say temperature, we could also mean a parameter that is shared between systems when they reach equilibrium, in terms of heat flow. Quite often, these two specific meanings of temperature agree with each other. For example, in terms of heat flow, the natural (by which we mean no extra work needs to be done for it to happen, naturally) direction of heat flow will always be from hotter object (thus with higher (T)) to colder (thus with lower (T)) one. As heat flows out of the hotter object, its temperature (now, we mean ‚Äòtemperature‚Äô by its first definition as given above) will decrease, and vice versa for the colder object. This process will continue until these two objects in question reach equilibrium ‚Äí they now share the same temperature and now, we mean ‚Äòtemperature‚Äô by its second definition as given above. üìåWhy is that we will never touch 0 K? Or, what does 0 K really mean? Concerning the first way of defining temperature, to get its definite value, one needs to set up a scale first. Usually, such systems will be used as the indicator of temperature that they respond differently and definitely to different temperature magnitude (i. e. the extent of hotness). For example, mercury will expand differently at different temperature so conventionally it is used as the medium of thermometer. Though thermometers like those made of mercury are used commonly, their disadvantage from the perspective of physics is obvious ‚Äí the definition of temperature scale depends on the properties of particular matter that is used as the medium for measuring temperature. Here, by ‚Äòproperties of matter‚Äô, we mean basically the amount of heat flow, given certain increase or decrease of temperature of the matter in question. Lord Kelvin then developed the idea of defining an absolute scale of temperature, vis a vis the uniqueness of temperature value in terms of heat flow [1]. The idea was originated from Carnot‚Äôs theory on ideal gas engine, whereby we have the relationship between the heat flow (in between working matter of high and low temperature) and temperature of working matters as follows, [\frac{Q_1}{Q_2} = \frac{T_1}{T_2}] Kelvin‚Äôs ideas was that if following Carnot‚Äôs principle of ideal engine to define temperature, it will be on an absolute scale then since as shown in the equation above, the heat flow only depends on the temperature of the working matter but nothing else. Saying this in another way, if we are using some other temperature scales (e. g. the mercury one and some other similar ones), the equation above will not simply hold universally in between the situations where different scale is used. Knowing what we mean by absolute scale of temperature, we then need to know how we can obtain its value. To do this, we need to first know a fact that the absolute scale of temperature defined by Kelvin is identical to that defined on a special working matter ‚Äí among all the possible working matters that we can choose to use ‚Äí the ideal gas. The proof of this can be found in Ref. [2] (page 35-36). Then suppose we use (T) to represent the temperature, of ideal gas, in absolute scale and we have a parameter (b) for the transformation between absolute scale and conventionally used temperature scale (e. g. the Celsius scale), we then have the following famous expression (ideal gas law), [PV = nR(T - b)] where, as we already know, (R) is a constant. Now suppose we fix our volume and the amount of matter in question (i. e. (n) in the equation above), we can then measure the change of pressure (P) versus the change of temperature (T). The constant (R) can thus be estimated. Once we know (R), we then proceed to seek for the zero point in the absolute scale - where the pressure goes to absolute 0 (which means all atoms are then staying statically and not moving) - by simply extrapolating the (P)-((T-b)) line from whatever ([P_x, (T_x - b)]) point we measured the system at, to ((0, 0)). That is to say, [b = T_x - \frac{P_xV}{nR}] Originally, the value of (b) was calculated to be around (237. 15) [3]. In 1954, the resolution 3 of the 10th CGPM meeting defines one unit (K) of temperature in absolute scale equals (1/237. 16) the interval between absolute (0) and the temperature of triple-phase point of water [4]. Hereby, we know the reason why the absolute (0) is EXACTLY (-273. 15) degree in Celsius: the temperature of water triple point is DEFINED to be (0. 01) degree in Celsius and also DEFINED to be (273. 16) degree in absolute scale, which means simply the (0) degree in Celsius is EXACTLY (273. 15) degree in absolute scale. Back to the question in the section title - why we can never reach absolute (0)? As discussed above, (0) (K) is an assumed state with pressure of (0) and is proposed mathematically by extrapolating the ideal gas equation to (0) (K). In the assumed state, since we will have pressure to be (0), we will then have all atoms staying statically, which is obviously impossible - fundamentally due to the Heisenberg uncertainty principle. üìåBut, why do we have negative temperature?Now we know why absolute zero can never be reached, but sometimes we will come across negative temperature in literature. Wait‚Ä¶what??? We just said (0) (K) is even impossible, how will it be possible that we have negative temperature? To get an idea about negative temperature, we need turn back to the definition of temperature again, as we have already mentioned at the very beginning of this blog. Up until now, we haven‚Äôt talked about the second approach of defining temperature mentioned there ‚Äí temperature defined as the parameter shared in between systems in equilibrium. To discuss negative temperature, that‚Äôs something we have to go for now. Suppose we have an isolated system containing two subsystems. The overall number of particles and energy of the whole system will be kept as constants, i. e. we have a microcanonical ensemble. Say we have the overall energy of the whole system to be (E) and the two subsystems are with energy of (E_1) and (E_2), respectively, we should then have (E = E_1 + E_2). Our question is then when, or in what condition can we say the two subsystems are in an equilibrium state, in terms of heat flow. Since we have an overall microcanonical ensemble, we know that the equilibrium state will be the one with maximum number of microstates. The total number of microstates of the overall system is given as, [N(E_1, E_2) = N_1(E_1)\times N_2(E_2)] where we have (E_1) and (E_2) as our variables of the function of microstates number, with the constraint that, as we mentioned above, (E = E_1 + E_2). Going a bit further, a famous quantity is defined to describe the number of states ‚Äí entropy, which originated from Boltzmann. In fact, entropy ((S)) is nothing but taking the log of total number of states of the system in question, to within a multiplicative constant ‚Äí Boltzmann constant (k_B). Now, the entropy of the overall system mentioned here in the context can be expressed as, [S(E_1, E_2) = k_Bln[N(E_1, E_2)]] From the discussion above, we know that when the two subsystems reach equilibrium, we will have (S) to be stationary, with regard to infinitesimal change in (E_1) and/or (E_2), i. e. , [\begin{equation}\begin{aligned}dS &amp; = dS_1 + dS_2\ &amp; = \big(\frac{dS_1}{dE_1}\big)dE_1 + \big(\frac{dS_2}{dE_2}\big)dE_2\ &amp; = \big(\frac{dS_1}{dE_1}\big)dE_1 - \big(\frac{dS_2}{dE_2}\big)dE_1\ &amp; = \big(\frac{dS_1}{dE_1} - \frac{dS_2}{dE_2}\big)dE_1 = 0\end{aligned}\nonumber\end{equation}] Here there are two things to mention about the derivation. First, for the first line in the equation above, we have, [\begin{equation}\begin{aligned}S &amp; = k_Bln[N(E_1, E_2)]\ &amp; = k_Bln[N_1(E_1)\times N_2(E_2)]\&amp; = k_Bln[N_1(E_1)] + k_Bln[N_2(E_2)]\ &amp; = S_1 + S_2\end{aligned}\nonumber\end{equation}] The second thing is from the 3rd to 4th line in the same equation. Here we need to recall that (E = E_1 + E_2) is kept as a constant, and therefore we have, [dE = dE_1 + dE_2 = 0 \Rightarrow dE_2 = -dE_1] Then from the equation (dS = 0) given above, we will have, [\frac{dS_1}{dE_1} - \frac{dS_2}{dE_2} = 0 \Rightarrow \frac{dS_1}{dE_1} = \frac{dS_2}{dE_2}] Till here, we arrive at a quantity that is shared between two systems in equilibrium, which then becomes our theoretical definition for temperature (T), [T = \frac{dS}{dE}] For most systems, when its energy increases, the entropy will also increase ‚Äí as we pump energy into a system, the overall energy of atoms (or whatever building block of the system) within the system will increase. This will create more possibilities for the system, i. e. the number of states will increase as the result of energy increase. Therefore, in most cases, our definition for (T) will get a positive value. However, this may not be the case of some spin systems. Suppose we have (N) spins existing in magnetic field. The ground state will be that all spins pointing along the direction of the magnetic field (ignoring spin-orbital coupling for the moment), say, spin-up direction. As we flip over one spin from spin-up to spin-down, the system energy will for sure increase. As for entropy, flipping over one spin will change the entropy from (S = k_Bln1 = 0) to (S = k_BlnC_N^1 = k_BlnN), where we also have entropy increasing as the result of the spin flip-over. As we continue to flip over spins one by one, the increase of energy will continue. However, the increasing of entropy will stop when we reach the turning point of (C_N^j) function (of (j)), where (j) is the number of flipped-over spins ‚Äí (j = N/2) if (N) is an even number and (j = (N\pm 1)/2) if (N) is an odd number. Going over the turning point, the entropy will decrease as we continue to flip over spins. In this case, according to the definition of the theoretical temperature, (T) will become negative. Furthermore, it should be pointed out that the negative temperature system is actually hotter than the positive temperature system. What does that mean? Imagine two systems touching each other, one of them is with negative temperature, and the other one with positive temperature. Now if energy flows from the negative-(T) system to the positive-(T) system, what will happen? The number of microstates (i. e. the entropy (S)) of the whole system will increase. Why? For negative-(T) system, when energy was taken away from it, (S) will increase since for negative-(T) system, entropy increases as the decreasing of energy. Similarly, the accepting of extra energy for the positive-(T) system will also lead to the increase of entropy, since for positive-(T) system, entropy increases as the increasing of energy. Therefore, when negative- and positive-(T) systems touch each other, the energy naturally tends to flow from the negative to the positive one, to maximize the entropy (thus to reach a more stable overall state) ‚Äí till the whole system reaches its equilibrium.  References [1] Lord Kelvin (William Thomson), On an Absolute Thermometric Scale. Philosophical Magazine October 1848 [from Sir William Thomson, Mathematical and Physical Papers, vol. 1 (Cambridge University Press, 1882), pp. 100-106. ] [2] Ê±™ÂøóËØöÔºåÁÉ≠ÂäõÂ≠¶(\cdot)ÁªüËÆ°Áâ©ÁêÜÔºàÁ¨¨ÂõõÁâàÔºâÔºåÈ´òÁ≠âÊïôËÇ≤Âá∫ÁâàÁ§æ„ÄÇ [3] Q &amp; A on Zhihu, https://www. zhihu. com/question/54691426. [4] https://www. bipm. org/en/CGPM/db/10/3/. "
    }, {
    "id": 55,
    "url": "http://localhost:4001/2020-07-06-occ_order/",
    "title": "Notes on occupational short-range ordering in crystal",
    "body": "2020/07/06 - When multiple atomic species (including vacancies) coexist on the same crystallographic site, it immediately brings up a question - say, we have species A and B sharing the same site, then do we have clustering of A and B in separate domains, or do we have A and B preferring to stay together, or do we have random distribution of A and B? This is usually what we mean by short-range order (SRO) and what we have mentioned here is specifically the occupational SRO (one can find introduction about more types of SRO in Chapter-10 in Ref. [1]). Detailed theoretical description about SRO can be found in Refs. [1-3] - the early paper by J. M. Cowley [2] gives the definition of SRO for binary systems; the one by D. De Fontaine [3] extends the definition to multi-component system (to give the so-called pairwise multi-component SRO, i. e. PM-SRO); the book by R. B. Neder and T. Proffen presents in details practical implementation and calculation of SRO, in DISCUS framework. Here I am not going to reproduce what has been covered in Refs mentioned here. Instead, only two main aspects, which I think is crucial for understanding the topic, will be recovered here.  In current blog, when we say SRO, we mean the Warren-Cowley (WC, or WC-like) coefficient. üìåSRO in terms of one-to-one connection VS shell Taking the simple binary system shown above as an example, we have two types of atoms here - A and B. When we say SRO, we may mean the correlation between specific sites (left part of the picture above). For example, if we want to calculate the correlation between A and B along the [10] direction with A as the center, the only connection we have here is from A2 to B3, and vice versa for B (but now we focus on the connection along [-10] and the only connection we have here is from B3 to A2). In this case, the calculation for SRO is given as,For A(\rightarrow)B, [\alpha_{AB} = 1 - \frac{\bar{P}_{AB}}{c_B} = 1 - \frac{\frac{0+1}{2}}{\frac{3}{5}} = \frac{1}{6}] For B(\rightarrow)A, [\alpha_{BA} = 1 - \frac{\bar{P}_{BA}}{c_A} = 1 - \frac{\frac{0+0+1}{3}}{\frac{2}{5}} = \frac{1}{6}] from which one can see the SRO with either A or B as the centering atom simply agrees with each other in quantity. Fundamental reason for this is that concerning the correlation along a certain direction, we have a one-to-one connection between A and B in question. This is exactly the case discussed in Ref. [2], concerning the pairwise correlation between species (the definition is not restricted to binary systems there). However, when we say SRO, we could also mean the correlation in terms of shells, like shown in the right side of the picture above. In this case, the calculation for SRO changes to,For A(\rightarrow)B, [\alpha_{AB} = 1 - \frac{\bar{P}_{AB}}{c_B} = 1 - \frac{\frac{0+\frac{3}{4}}{2}}{\frac{3}{5}} = \frac{3}{8}] For B(\rightarrow)A, [\alpha_{BA} = 1 - \frac{\bar{P}_{BA}}{c_A} = 1 - \frac{\frac{1+1+1}{3}}{\frac{2}{5}} = -\frac{3}{2}] Since in this case, the connection between A and B in terms of coordination shells is no longer a one-one-one connection, we therefore no longer necessarily have the result of SRO with A or B as the centering atom being equal to each other. üìåThe limit value of SROAccording to the definition of SRO, [\alpha_{AB} = 1 - \frac{P_{AB}}{c_B}] (P_{AB}) means the probability of find B around A, and (c_B) is the number concentration of B. Given fixed (c_B), the limit value of (\alpha_{AB}) is determined by (P_{AB}) which we know is a probability and therefore will range from 0 to 1 in theory. However in practice, we should have the following restriction for the value that (P_{AB}) can take, [P_{AB}\times N_A \leq N_B \Rightarrow P_{AB}\leq \frac{N_B}{N_A}] where (N_A) and (N_B) refers to the total number of atoms of type A and B in the system, respectively. Then accordingly, we have, [\alpha_{AB} = 1 - \frac{P_{AB}}{c_B}\geq 1 - \frac{\frac{N_B}{N_A}}{\frac{N_B}{N_A + N_B}} = -\frac{N_B}{N_A}] As the result of (P_{AB}) potentially not reaching its theoretical limit of 1, (\alpha_{AB}) may have a floor higher than its theoretical limit, accordingly. On the other side, we simply have, [P_{AB} \geq 0] and therefore, [\alpha_{AB} = 1 - \frac{P_{AB}}{c_B} \leq 1] References [1] R. B. Neder and T. Proffen. Diffuse Scattering and Defect Structure Simulations: A Cook Book Using the Program DISCUS. Oxford University Press. (2008). [2] J. M. Cowley. Phys. Rev. 77, 5. (1950). [3] D. De Fontaine. J. Appl. Cryst. 4, 15. (1971). "
    }, {
    "id": 56,
    "url": "http://localhost:4001/2020-07-04-sublime/",
    "title": "Notes on Sublime Text 3",
    "body": "2020/07/04 -  For many packages installed in Sublime Text 3, either we can configure the key bindings for executing available commands by going to ‚ÄòPreferences‚Äô(\rightarrow)‚ÄòKey Bindings‚Äô, or we can go to the package specific key binding setting section. However, sometimes, we don‚Äôt have a dedicated key binding setting section for some of the installed package, e. g. ‚ÄòGoogle Search‚Äô package. In this case, it becomes a headache to set the key binding since we don‚Äôt even know what commands are actually available there. To get an idea about what commands are available for such types of packages, we can go to ‚Äò%APPDATA%\Sublime Text 3\Installed Packages‚Äô directory (taking Windows OS as an example) and find the package file, e. g. ‚ÄòGoogle Search. sublime-package‚Äô. This file is just a zip file which contains all the necessary stuff of the installed package. Therefore, we can copy it to somewhere and change the file name extension to ‚Äò. zip‚Äô and open the package with whatever available zip file manager program to inspect the content of the package. Within the package, we can find the file ‚ÄòDefault (Windows). sublime-keymap‚Äô (again, taking Windows OS as an example). Opening the file, we can see what command are actually available there and then we can go to ‚ÄòPreferences‚Äô(\rightarrow)‚ÄòKey Bindings‚Äô in Sublime Text 3 to assign new key bindings, if necessary. "
    }, {
    "id": 57,
    "url": "http://localhost:4001/2020-06-28-fourier_transform/",
    "title": "When Fourier transform meets total scattering",
    "body": "2020/06/28 -  In this article, I am going to note down my bits of understanding for the role that Fourier transform is playing in total scattering regime. Quite often we hear people talking about real space or reciprocal space representation of the total scattering signal. Also, it‚Äôs probably a common sense that the two spaces are coupled by Fourier transform. But if pulling ourselves out of those technical details for the moment and think about why Fourier transform comes into play in total scattering regime in the first place, sometimes we may find ourselves in a situation like ‚Äòum‚Ä¶but‚Ä¶why?‚ÄôBefore diving into the specific total scattering topic, I will first mention a little bit background about Fourier transform. Here I will not try to reproduce details about it from head to toe, since obviously a simple Googling will guide us to tons of available resources about such a topic. Therefore, there is no need at all to reinvent the wheel. Instead, I will pick up a very interesting visualization of Fourier transform that I came across on YouTube and try to reproduce it here as an intro before going into my topic. Also, I will recover two little pieces of problems that I encountered during learning total scattering. They are not crucial for understanding the topic but I think it‚Äôs always good to stop and think why, instead of just accepting them as being granted. So, first lets start with the visualization of Fourier transform mentioned above. As I said, I first came across this fantastic visualization in a YouTube video, which one can check out here: Click Me! The original post can be found in the blog titled Purrier Series (Meow) and Making Images Speak, in which Mathematica was used to generate those fabulous animations. Also, mathematical formulation can be found either in the post mentioned here or the link here: Click Me! Here, I took the same idea and make a simple reproduction of two simple animations with Python, just as a practice. What we are transforming here is a square function and only the first two components are considered here. The transformation involving only the first component is like this: Then the first and third components are involved: The Python script used to generate the two animations above is reproduced as follows (one needs numpy and matplotlib to run it):  Copy snippet to clipboard!   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246import numpy as npimport matplotlib. pyplot as pltimport matplotlib. animation as animation# Function to be used as the updator for first Fourier component. # Here we have,# 'line'  for rotating bar# 'line1'  for scanning bar moving up and down# 'line2'  for plotting the first Fourier component. # 'line3'  for plotting the original square function. def update_line_1(num, xy_plot, line, line1, line2, line3):  line. set_data([-2, xy_plot[num - 1][0]], [0, xy_plot[num - 1][1]])  line1. set_data([xy_plot[num - 1][0], 0],          [xy_plot[num - 1][1], xy_plot[num - 1][1]])  # x2_temp = [item[0] for item in xy1_plot[:num]]  # y2_temp = [item[1] for item in xy1_plot[:num]]  x2_temp = [item[0] for item in xy1_plot[num]]  y2_temp = [item[1] for item in xy1_plot[num]]  line2. set_data(x2_temp, y2_temp)  x2_temp = [item[0] for item in xy_line_plot[num]]  y2_temp = [item[1] for item in xy_line_plot[num]]  line3. set_data(x2_temp, y2_temp)  return line, line1, line2, line3# Function to be used as the updator for first and third Furier component. # Here we have,# 'line'  for rotating bar indicating the first component. # 'line1'  for scanning bar moving up and down. # 'line2'  for plotting the first and third Fourier components. # 'patch1' for rotating circle indicating the third component. # 'line3'  for the center of the rotating circle (again, indicating the#      third component). # 'line4'  for the rotating bar indicating the third component. # 'line5'  for plotting the original square function. def update_line_3(num, xy_plot, line, line1, line2,         patch1, line3, line4, line5):  line. set_data([-2, xy_plot[num - 1][0]], [0, xy_plot[num - 1][1]])  line1. set_data([xy_plot_1[num - 1][0], 0],          [xy_plot_1[num - 1][1], xy_plot_1[num - 1][1]])  x2_temp = [item[0] for item in xy3_plot[num]]  y2_temp = [item[1] for item in xy3_plot[num]]  line2. set_data(x2_temp, y2_temp)  patch1. center = (xy_plot[num - 1][0], xy_plot[num - 1][1])  patch1. radius = 4. 0 / 3. 0 / np. pi  ax2. add_patch(patch1)  line3. set_data([xy_plot[num - 1][0]], [xy_plot[num - 1][1]])  line4. set_data([xy_plot[num - 1][0], xy_plot_1[num - 1][0]],          [xy_plot[num - 1][1], xy_plot_1[num - 1][1]])  x2_temp = [item[0] for item in xy_line_plot[num]]  y2_temp = [item[1] for item in xy_line_plot[num]]  line5. set_data(x2_temp, y2_temp)  return line, line1, line2, patch1, line3, line4, line5fig1, ax1 = plt. subplots()ax1. set_aspect('equal')ax1. spines[ bottom ]. set_linewidth(2)ax1. spines[ top ]. set_linewidth(2)ax1. spines[ left ]. set_linewidth(2)ax1. spines[ right ]. set_linewidth(2)ax1. tick_params(direction='out', length=6)# The static circle indicating the first component. circle = plt. Circle((-2, 0), 4 / np. pi, color='red', fill=False)ax1. add_artist(circle)# The rotating circle indicating the third component. patch1 = plt. Circle((0, 0), 0. 0, fc='y')# Plot some indicator ticks for the graph. plt. plot(-2, 0, '-o', color='gray',     markersize=5, linewidth=4,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([0, 0], [-2, 2],     '-', color='black',     markersize=5, linewidth=2,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([-0. 25, 0], [0, 0],     '-', color='black',     markersize=5, linewidth=1,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([-0. 25, 0], [1, 1],     '-', color='black',     markersize=5, linewidth=1,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([-0. 25, 0], [-1, -1],     '-', color='black',     markersize=5, linewidth=1,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)# Generating data for plotting. x_temp = np. linspace(0, 4. 0, 500)# First, the rotating bar indicating the first component. xy_plot = []for i in range(len(x_temp)):  xy_plot. append([4. 0 / np. pi * np. cos(np. pi / 2. 0 * x_temp[i]) - 2. 0,          4. 0 / np. pi * np. sin(np. pi / 2. 0 * x_temp[i])])# Then, the rotating bar indicating the third component. For this one,# the origin is rotating as well. xy_plot_1 = []for i in range(len(x_temp)):  center_1 = [-2. 0, 0]  center_2 = [4. 0 / np. pi * np. cos(np. pi / 2. 0 * x_temp[i]),        4. 0 / np. pi * np. sin(np. pi / 2. 0 * x_temp[i])]  ending = [4. 0 / np. pi / 3. 0 * np. cos(3. 0 * np. pi / 2. 0 * x_temp[i]),       4. 0 / np. pi / 3. 0 * np. sin(3. 0 * np. pi / 2. 0 * x_temp[i])]  xy_plot_1. append([center_1[0] + center_2[0] + ending[0],           center_1[1] + center_2[1] + ending[1]])# Moving square function. xy_line_plot = []for i in range(len(x_temp)):  xy_line_plot. append([])  for j in range(len(x_temp)):    t_part = np. pi / 2. 0 * x_temp[i]    x_part = np. pi / 2. 0 * x_temp[j]    y_temp = np. sign(np. sin(t_part - x_part))    xy_line_plot[i]. append([x_temp[j], y_temp])# Function of the first component. xy1_plot = []for i in range(len(x_temp)):  xy1_plot. append([])  for j in range(len(x_temp)):    t_part = np. pi / 2. 0 * x_temp[i]    x_part = np. pi / 2. 0 * x_temp[j]    y_temp = 4 / np. pi * np. sin(t_part - x_part)    xy1_plot[i]. append([x_temp[j], y_temp])# Function of the third component. xy3_plot = []for i in range(len(x_temp)):  xy3_plot. append([])  for j in range(len(x_temp)):    t_part_1 = np. pi / 2. 0 * x_temp[i]    x_part_1 = np. pi / 2. 0 * x_temp[j]    t_part_3 = 3. 0 * np. pi / 2. 0 * x_temp[i]    x_part_3 = 3. 0 * np. pi / 2. 0 * x_temp[j]    y_temp_1 = 4 / np. pi * np. sin(t_part_1 - x_part_1)    y_temp_2 = 4. 0 / np. pi / 3. 0 * np. sin(t_part_3 - x_part_3)    xy3_plot[i]. append([x_temp[j], y_temp_1 + y_temp_2])# Initialize and update the animation. First, we include only first# Fourier component. l, = plt. plot([], [], 'r-')l1, = plt. plot([], [], 'r-')l2, = plt. plot([], [], 'r-')l3, = plt. plot([], [], 'k-')plt. xlim(-5, 5)plt. ylim(-2, 2)line_ani_1 = animation. FuncAnimation(fig1, update_line_1, 500,                   fargs=(xy_plot, l, l1, l2, l3),                   interval=5, blit=True)# Then we add in the third component (the components of even number# are all 0). fig2, ax2 = plt. subplots()ax2. set_aspect('equal')ax2. spines[ bottom ]. set_linewidth(2)ax2. spines[ top ]. set_linewidth(2)ax2. spines[ left ]. set_linewidth(2)ax2. spines[ right ]. set_linewidth(2)ax2. tick_params(direction='out', length=6)circle = plt. Circle((-2, 0), 4 / np. pi, color='red', fill=False)ax2. add_artist(circle)patch1 = plt. Circle((0, 0), 0. 0, color='blue', fill=False)# Plot some indicator ticks for the graph. plt. plot(-2, 0, '-o', color='gray',     markersize=5, linewidth=2,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([0, 0], [-2, 2],     '-', color='black',     markersize=5, linewidth=2,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([-0. 25, 0], [0, 0],     '-', color='black',     markersize=5, linewidth=1,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([-0. 25, 0], [1, 1],     '-', color='black',     markersize=5, linewidth=1,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)plt. plot([-0. 25, 0], [-1, -1],     '-', color='black',     markersize=5, linewidth=1,     markerfacecolor='black',     markeredgecolor='black',     markeredgewidth=2)l, = plt. plot([], [], 'r-')l1, = plt. plot([], [], 'b-')l2, = plt. plot([], [], 'b-')l3, = plt. plot([], [], '-o', color='gray',        markersize=5, linewidth=2,        markerfacecolor='black',        markeredgecolor='black',        markeredgewidth=2)l4, = plt. plot([], [], 'b-')l5, = plt. plot([], [], 'k-')plt. xlim(-5, 5)plt. ylim(-2, 2)line_ani_3 = animation. FuncAnimation(fig2, update_line_3, 500,                   fargs=(xy_plot, l, l1, l2, patch1,                      l3, l4, l5),                   interval=5, blit=True)# Save the animation to movie file. For some reason, saving to# GIF file won't allow us to change the FPS and the whole animation# will become very slow. Therefore, we save the animation first as# MP4 file and use the online converter to transform to GIF file:# https://ezgif. com/line_ani_1. save('first_component. mp4', fps=250, dpi=300)line_ani_3. save('third_component. mp4', fps=250, dpi=300)plt. show()Next, I will briefly talk about the two problems about Fourier transform that I mentioned earlier. üìåThe (1/2\pi) factor appearing in the inverse Fourier transformUsually, the Fourier transform of function (f(x)) is defined as, [F(f) = \int_{-\infty}^{\infty}f(x)e^{-2\pi i xf}dx] The inverse Fourier transform will then be symmetrically and nicely given as, [f(x) = \int_{-\infty}^{\infty}F(f)e^{2\pi i xf}df] according to the Fourier inversion theorem. However, quite often we will see an extra factor (1/2\pi) in front of the inverse Fourier transform. So the natural question is - why do we have an extra factor there? Why do we not stay with the nice and symmetric form of forward and inverse Fourier transform? The reason is simply due to the using of angular frequency ((\omega)) instead of frequency ((f)) as the independent variable in Fourier space. The relation between these two variables is simply, [\omega = 2\pi f] Using (\omega) as our Fourier space variable, one has the forward Fourier transform as, [\hat{F}(\omega) = F(\frac{\omega}{2\pi}) = \int_{-\infty}^{\infty}f(x)e^{-i\omega x}dx] where the symbol (\hat{F}) is used to represent the functional form with (\omega) as the independent variable, in contrast to the symbol (F) with (f) as the independent variable. Accordingly, the inverse Fourier transform will be given as, [f(x) = \int_{-\infty}^{\infty}F(f)e^{2\pi i xf}df = \int_{-\infty}^{\infty}\hat{F}(\omega)e^{ix\omega}d(\frac{\omega}{2\pi}) = \frac{1}{2\pi}\int_{-\infty}^{\infty}\hat{F}(\omega)e^{ix\omega}d\omega] from which one can clearly see the popping up of the extra factor (1/2\pi). üìåDiscrete Fourier transformThe definition of Fourier transform given above is in its continuous format, whereas in practice the signal we hold in hand will never be continuous. Unlike the continuous version of Fourier transform (of which the definition is unique, as given above), we need to first pin down what we really mean by discrete Fourier transform. Suppose we have a series of data measured to be (0. 1, 100), (0. 12, 101), (0. 15, 300), (0. 16, 321), ‚Ä¶, where the first number in each pair represents our variable (say, time (t)) and the second one is our response (say, voltage (V)), then how do we proceed to do the Fourier transform? This is where the definition of discrete Fourier transform is introduced. According to Wikipedia, we have,  in mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples‚Ä¶ Therefore, for the example given above (and also in the case of total scattering as we will see later), one needs to first group the measured data into bins with equal width and then carry out the discrete Fourier transform as defined (see, e. g. , Wikipedia for the exact definition).  ========================I AM A SEPARATOR======================== Finishing the preparation work, we now move on to discuss the reflection of Fourier transform in total scattering regime. First of all, what is total scattering? Scattering is scattering, but what do we mean by ‚Äòtotal‚Äô? Does it mean that not mentioning ‚Äòtotal‚Äô in the context indicates we are missing something? The answer is YES. But what do we miss?In terms of scattering experiment, either with X-ray, neutron or electron, what we usually mean by ‚Äòscattering‚Äô is actually the Bragg reflection, in which we are specially concerned about the reflection from atom planes. The underlying rule is the famous Bragg‚Äôs law, [2dsin(\theta) = n\lambda] The common approach for analyzing Bragg pattern then focuses on the positions and intensities of those reflection peaks, which is fundamentally determined by atomic structure of material under radiation beam. Structures extracted in such a way is what we usually call as average structure. To go beyond the Bragg reflection and talk about total scattering, we need to dig into the base level of the scattering event. We already know that Bragg reflection originates from the scattering from atom planes. This is fundamentally owing to the in-phase reflection of the incoming beam from group (certain lattice plane) of atoms, leading to the overall enhanced interference effect. In that sense (and also in fact), the scattering event actually happens on the atomic level (to be more precise, X-ray interacts with electrons surrounding atoms, neutron interacts with nuclei, electron‚Äôs interaction with materials being complicated). Accordingly, the normalized (over all (N) atoms in the system) scattering intensity is given as, [\frac{1}{N}\frac{d\sigma}{d\Omega} = \frac{1}{N}\sum_{j,k}b_jb_kexp[i\mathbf{Q}\cdot(\mathbf{r}_j - \mathbf{r}_k)]] with the dimension of area ((\sigma) for cross section, (\Omega) for solid angle, (b) for scattering length (form factor in the case of X-ray scattering), (\mathbf{Q}) for scattering vector, (\mathbf{r}) for atomic position). Given the incoming flux of incoming beam (e. g. number of neutrons) per area, the product is equal to the flux of scattered beam per solid angle, which can then be equated to the experimental measurement. From the formulation given right above, one can see that the Bragg peak positions are only some special points in reciprocal space (i. e. (Q)-space). When only focusing on those special points in (Q)-space and ignoring all the other (Q) points (in practice, all the points other than those special ones are treated as background, in, e. g Rietveld refinement), no doubt one will lose a lot of useful information from the scattering measurement! By bringing back those ignored (Q) points, we will have the total scattering pattern, enabling us to retrieve those missing information - the local structure - in conventional Bragg data analysis. This is where Fourier transform comes to play an important role, which is what we will cover right next. For the following discussion, we refer ourselves to the book by M. Dove [1] (see Appendix-J in the book for detailed derivations), with several key aspects recovered in current context. First, by pulling out all the self-terms, one arrives at, [\frac{1}{N}\frac{d\sigma}{d\Omega} = F(Q) + \sum_ic_ib_i^2] in which (F(Q)) can be further expressed as, [F(Q) = \rho\sum_{j,k}c_jc_kb_jb_k4\pi\int_{0}^{\infty}r^2g_{jk}(r)\frac{sin(Qr)}{Qr}dr] where (c) represents the proportion of atoms of each type, (\rho) refers to the overall number density of the system, and the term (sin(Qr)/Qr) comes from the isotropic orientational average of (\langle exp[i\mathbf{Q}\cdot(\mathbf{r}_j - \mathbf{r}_k)]\rangle). It‚Äôs worth mentioning that the following part in the definition of (F(Q)) gives the average number of atoms of type (k) within the shell (r\rightarrow r+dr) surrounding atoms of type (j), [\rho c_k4\pi r^2g_{jk}(r)dr] while (c_j) in the definition of (F(Q)) fundamentally comes from the normalization over the total number of atoms ((N)) in the system. The logic here is that we treat all inter-atomic distances within the range (r\rightarrow r+dr) to be the same and we count the number of atomic pairs with such a distance and multiply that number to the phase factor (in this case, (sin(Qr)/Qr)). Saying that, we are still doing the same thing as given in the original formation of the normalized scattering intensity above. The difference here is we group distances falling into the same bin together, instead of calculating every single possible distance individually and explicitly. This is the fundamental reason why calculating the reciprocal space total scattering pattern following the Debye approach (see Eqn. 4. 9 in the book by R. Neder and T. Proffen [2]) and the Fourier transform approach (as we will see next) should give very similar result (slight difference may pop up due to the difference between considering each pair explicitly and binning similar distances). Furthermore, by defining a new function, [G(r) = \sum_{j,k}c_jc_kb_jb_k[g_{jk}(r) - 1]] the function (F(Q)) can be further expressed as, [QF(Q) = \rho\int_{0}^{\infty}4\pi rG(r)sin(Qr)dr] from which one can clearly see that (QF(Q)) and (rG(r)) are linked by Fourier transform. Here we have the real version of Fourier transform, since the scattering measurement are measuring intensity only but not the phase and therefore we lose the phase information. Theoretically, accordance with such an experimental fact during our derivation for the scattering intensity dates back to Eqn. 6. 22 in M. Dove‚Äôs book [1], where the square of the phase shift instead of the phase shift itself is used to reproduce the experimental scattering intensity. As the partner equation of the one given just above, one has, [rG(r) = \frac{1}{(2\pi)^3\rho}\int_{0}^{\infty}4\pi QF(Q)sin(Qr)dQ] Here, the reason why we have (1/(2\pi)^3) term in the pre-factor is just that presented in early part of current blog. Specifically, the definition of (Q) is analogous to the angular frequency (\omega) we mentioned before, since we have (Q = 2\pi/d) where (1/d) is analogous to the frequency (f) we have before. Analogously, we can call (1/d) the space frequency and (Q) the space angular frequency. The cubic exponential in (1/(2\pi)^3) is coming from the fact that we have a 3D space and therefore naturally the factor (1/2\pi) should appear three times. üìåAbout maximum (r) or (Q)Given a certain (r) or (Q) grid, one question one may ask is what is the corresponding maximum (Q) or (r) that we can reach - we know resolution in one space corresponds to the spanning range in the coupled space. However, how to quantify such a coupled relation is a question and this is to be covered next. Given the relation (Q = 2\pi/d), it may be straightforward to tell that (Q_{range} = 2\pi/\Delta d), where (Q_{range}) refers to the (Q)-space coverage range and (\Delta d) is the (d)-space interval between nearest points. However, this is INCORRECT and the CORRECT version should be, [Q_{range} = \pi/\Delta d] Similarly one has, [d_{range} = \pi/\Delta Q] where ‚Äòrange‚Äô and (\Delta) carries the same meaning as mentioned above. So the question is, why do we miss the factor ‚Äò2‚Äô there? The fundamental reason for this is, in the Fourier transform space, alongside with the positive frequency, we also have the corresponding negative frequency and the negative frequency part is simply a mirror image of the positive part. Taking the Fourier transform from (d)- to (Q)-space as an example, the existence of mirroring to negative frequency means the actual (Q)-space coverage is (2Q_{range}) and therefore we cancel out the factor ‚Äò2‚Äô on both sides of the equation to give us (Q_{range} = \pi/\Delta d). So, next, we should spend a bit time to understand what negative frequency is and why we have it. Going back to the definition of Fourier transform presented above (e. g. , the angular frequency case), we see that (\hat{F}(\omega)) is defined over the whole (\mathcal{R}) axis - this means definitely we will have negative frequency. Giving it a closer look, we have, [\begin{equation}\begin{aligned}\hat{F}(\omega) &amp; = \int_{-\infty}^{\infty}f(x)e^{-i\omega x}dx\ &amp; = \int_{-\infty}^{\infty}f(x)cos(\omega x)dx - i\int_{-\infty}^{\infty}f(x)sin(\omega x)dx\ &amp; = A(\omega) - iB(\omega)\end{aligned}\nonumber\end{equation}] When changing (\omega) to (-\omega), we know that (cos) function will not change while (sin) function will become negative. Therefore, we have, [\hat{F}(-\omega) = A(\omega) + iB(\omega)] so that we know the positive and negative frequency is not independent which means in fact the negative frequency does not bring in anything new to our signal. So why do we still have negative frequency? Why don‚Äôt we change the definition domain for (\hat{F}(\omega)) to be ([0, \infty))? The reason is, with (\hat{F}(\omega)) being defined on the full (\mathcal{R}) axis, the inverse Fourier transform of (\hat{F}(\omega)) will give real function which has physical meaning (since simply the observable signal in practice should be real). To see this, we need to revisit the inverse Fourier transform, [f(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty}\hat{F}(\omega)e^{ix\omega}d\omega] where (\hat{F}(\omega)) is complex according to the definition of Fourier transform, and therefore, we can write,       [\hat{F}(\omega) =   \hat{F}(\omega)   e^{i\phi(\omega)}]   where (|\hat{F}(\omega)|) and (\phi(\omega)) refers to the amplitude and phase of (\hat{F}(\omega)), respectively. So, the inverse Fourier transform can be written as,       [\begin{equation}\begin{aligned}f(x) &amp; = \frac{1}{2\pi}\bigg[\int_0^\infty\hat{F}(\omega)e^{ix\omega}d\omega + \int_{-\infty}^0\hat{F}(\omega)e^{ix\omega}d\omega\bigg]\ &amp; = \frac{1}{2\pi}\bigg[\int_0^\infty   \hat{F}(\omega)   e^{i[\phi(\omega) + x\omega]}d\omega + \int_{-\infty}^0   \hat{F}(\omega)   e^{i[\phi(\omega) + x\omega]}d\omega\bigg]\ &amp; = \frac{1}{2\pi}\bigg[\int_0^\infty   \hat{F}(\omega)   e^{i[\phi(\omega) + x\omega]}d\omega + \int_{\infty}^0   \hat{F}(-\omega_t)   e^{i[\phi(-\omega_t) - x\omega_t]}d(-\omega_t)\bigg]\ &amp; = \frac{1}{2\pi}\bigg[\int_0^\infty   \hat{F}(\omega)   e^{i[\phi(\omega) + x\omega]}d\omega + \int_0^\infty   \hat{F}(-\omega)   e^{i[\phi(-\omega) - x\omega]}d\omega\bigg]\ &amp; = \frac{1}{2\pi}\bigg[\int_0^\infty   \hat{F}(\omega)   e^{i[\phi(\omega) + x\omega]}d\omega + \int_0^\infty   \hat{F}(\omega)   e^{-i[\phi(\omega) + x\omega]}d\omega\bigg]\ &amp; =\frac{1}{2\pi}\int_0^\infty   \hat{F}(\omega)   \bigg[e^{i[\phi(\omega) + x\omega]} + e^{-i[\phi(\omega) + x\omega]}\bigg]d\omega\ &amp; = \frac{1}{2\pi}\int_0^\infty   \hat{F}(\omega)   cos[\phi(\omega) + x\omega]d\omega\end{aligned}\nonumber\end{equation}]   where we change the integration variable ((\omega \rightarrow \omega_t)) from line-2 to line-3. Using the fact that (\omega_t) is simply an integration dummy variable, we change it back to (\omega) and adjust the integration range accordingly (line-3 to line-4). From line-4 to line-5, we apply the relation between (\hat{F}(\omega)) and (\hat{F}(\omega)) ‚Äì they have identical amplitude but opposite phase. From the result, we can see that by expanding the definition domain to include negative frequency, we can guarantee that the inverse Fourier transform will always give real result, which is exactly what we need in practice. As for the physical meaning of negative frequency, we can imagine the sinusoidal function pictorially as rotation - the positive and negative then just corresponds to the rotation in different directions, i. e. clockwise or counterclockwise.  References [1] M. T. Dove, Structure and Dynamics: An Atomic View of Materials. Oxford University Press, New York, 2002. [2] R. B. Neder and T. Proffen, Diffuse Scattering and Defect Structure Simulations, Oxford University Press, New York, 2008. "
    }, {
    "id": 58,
    "url": "http://localhost:4001/2020-06-27-conda_build/",
    "title": "Build package with conda recipe",
    "body": "2020/06/27 - There are indeed instructions and tutorials about how to build conda packages (which we can then install easily through conda, e. g. by simply executing ‚Äòconda install ‚Ä¶‚Äô from command line) with conda recipe. However, as a beginner to conda build, it was really difficult for myself to find the way out of pieces of information all over the place. I was trying to find a minimal example which then I can use as a template for further tweaking and potentially adding in new things according to my pwn need. It turns out that I could not find such a working example, and that‚Äôs what this blog is really for - just to provide a very minimal working example to demonstrate the basic work flow of conda build. Here follows is a screenshot of the demo program, with which one can calibrate the total scattering in reciprocal space with the corresponding Bragg pattern.  One can install this program by executing the following command from terminal,  conda install -c apw247 sofq_calib Next, I will share all the configurations necessary for making the easy installation of this program possible, with conda. First, the actual codes are included here: sofq_calib. zip, which has the following tree structure, . ‚îú‚îÄ‚îÄ LICENSE. txt‚îú‚îÄ‚îÄ README. txt‚îú‚îÄ‚îÄ setup. py‚îî‚îÄ‚îÄ sofq_calib  ‚îú‚îÄ‚îÄ init. py  ‚îú‚îÄ‚îÄ sofq_calib. py  ‚îú‚îÄ‚îÄ stuff  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ doc. txt  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ help. txt  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ icon. ico One should save the top-level unzipped folder as ‚Äòsofq_calib‚Äô. In this folder, we have all files relevant to running the GUI shown above. Besides that, one can also notice a ‚Äòsetup. py‚Äô file - this is actually the file that is really doing the packaging job. Later on, conda recipe will try to get access to this folder and fundamentally to this ‚Äòsetup. py‚Äô file to kick off the packaging process. Given the source codes above, we now turn to the conda build side. Here one can find the package containing all components relevant to conda build: sofq_calib_conda_recipe. zip which has the following tree structure, . sofq_calib_conda_recipe ‚îú‚îÄ‚îÄ bld. bat ‚îú‚îÄ‚îÄ build. sh ‚îú‚îÄ‚îÄ icon. ico ‚îú‚îÄ‚îÄ menu-windows. json ‚îî‚îÄ‚îÄ meta. yaml One can find detailed introduction about conda build recipe following the link: Click Me! Several things need to be specifically mentioned here - it is NOT necessary to save the top-level folder as the name appearing here; within the top-level folder, several files need to be with exactly the name as shown: bld. bat, build. sh, ‚Äòmenu-windows. json‚Äô and ‚Äòmeta. yaml‚Äô; the ‚Äòbld. bat‚Äô and ‚Äòbuild. sh‚Äô are scripts to kick off the packaging, respectively on Windows and Unix-like OS; the ‚Äòmeta. yaml‚Äô file contains necessary configurations (metadata) guiding the packaging engine to do what we want it to do. One can refer to the link here for more information about ‚Äòmeta. yaml‚Äô file: Click Me; the build script and the YAML file are the minimal requirement for a successful packaging. For current example, apart from the very basic packaging, we also have included a useful feature - on Windows platform, when users install our package, a corresponding shortcut will be generated both on Desktop and in the Windows start menu. To make this possible, we need two extra files in the conda build folder - one is obviously the icon file (‚Äòicon. ico‚Äô in the folder above) and the other one is ‚Äòmenu-windows. json‚Äô. Accordingly, in the ‚Äòbld. bat‚Äô, we have entries responsible for copying both the ‚Äòicon. ico‚Äô and ‚Äòmenu-windows. json‚Äô files into the right place with the right name (‚Äòmenu-windows. json‚Äô will be renamed as ‚Äòpackage-name. json‚Äô where ‚Äòpackage-name‚Äô refers to the name of our package and in this case, it is ‚Äòsofq_calib‚Äô). Here following is the relevant contents in the build script,    set MENU_DIR=%PREFIX%\Menuif not exist (%MENU_DIR%) mkdir %MENU_DIR%copy %RECIPE_DIR%\icon. ico %MENU_DIR%if errorlevel 1 exit 1copy %RECIPE_DIR%\menu-windows. json %MENU_DIR%\sofq_calib. jsonif errorlevel 1 exit 1 where the environment variable ‚Äò%PREFIX%‚Äô refers to the top-level folder of corresponding conda environment. One can find out where it is, by typing ‚Äòconda info‚Äô in terminal. Then both files mentioned above concerning Windows menu entry will appear under the ‚Äò%PREFIX%\Menu‚Äô folder once the package is successfully installed. In the ‚Äòmenu-windows. json‚Äô file is given the properties of the shortcut that will be created for the installed package on Windows. The content is reproduced here,    {   menu_name :  Anaconda${PY_VER} ${PLATFORM} ,   menu_items :  [    {       name :  SofQ_Calib ,     pywscript  :  ${PYTHON_SCRIPTS}/sofq_calib-script. pyw ,     icon :  ${MENU_DIR}/icon. ico ,     desktop : true  }  ]} where each entry within the ‚Äòmenu-items‚Äô should be self-explaining. Attention here to the ‚Äòpywscript‚Äô entry which specifies the script that will be launched when double-clicking the shortcut. The full target entry of the shortcut (right click the shortcut ‚Üí select [Properties] to see/change the target) will become,  C:\Users\yuanp\anaconda3\pythonw. exe C:\Users\yuanp\anaconda3\cwp. pyC:\Users\yuanp\anaconda3 C:\Users\yuanp\anaconda3\pythonw. exeC:\Users\yuanp\anaconda3\Scripts\sofq_calib-script. pyw One does not need to worry about the ‚Äòsofq_calib-script. pyw‚Äô file appearing here. This is a file that is automatically generated during the conda package building/installation procedure and also ‚Äò-script. pyw‚Äô is automatically appended to the end of package name to give the corresponding script name of ‚Äòsofq_calib-script. pyw‚Äô. The purpose of generating such a file is to disable the command window popup specifically on Windows. Accordingly, in the YAML file, the entry point under the ‚Äòapp:‚Äô block should also be specified as ‚Äòpythonw -m sofq_calib. sofq_calib‚Äô, where ‚Äòpythonw‚Äô means the script will be executed by pythonw instead of python. The first ‚Äòsofq_calib‚Äô refers to the package name and the second ‚Äòsofq_calib‚Äô means the script to be executed - remember the ‚Äò-script. pyw‚Äô to be appended to the script file name to give ‚Äòsofq_calib-script. pyw‚Äô, as already mentioned above. "
    }, {
    "id": 59,
    "url": "http://localhost:4001/2020-06-26-discus_install/",
    "title": "Install DISCUS version 6 on Windows 10",
    "body": "2020/06/26 -  On my Windows 10 machine, I first tried to install DISCUS version 6 following the one-touch installation procedure and got the error relevant to ‚ÄòHDF5‚Äô. Therefore, I turned to the manual installation procedures. During the installation, I have to install the ‚Äòlibssl1. 1‚Äô library manually. After successful installation of discus_suite on WSL ubuntu machine, I could not find the ‚ÄòDiscusWSL‚Äô folder under ‚ÄòC:\Users\DISCUS_INSTALLATION‚Äô as specified in the installation instruction. Instead, I have to manually copy the ‚ÄòDiscusWSL‚Äô folder from WSL directory/home/discus/DIFFUSE_INSTALL/DiscusWSLto the Windows folderC:\Program Files (x86). After the successful configuration following the manual installation instruction, I can lanuch the discus_suite terminal without problems. However, I came across the problem of not being able to start any xserver relevant service. For example, typing ‚Äòmanual‚Äô within the ‚Äòsuite‚Äô environment will give the error of something like ‚Äòcannot start display :0‚Äô. After a bit Googling, I found this is something to do with the xserver settings. I have to put the following line in the ‚Äò. profile. local‚Äô file (this file will be called anytime discus_suite is started) on WSL system for the WSL subsystem to configure the display properly:export DISPLAY=$(cat /etc/resolv. conf | grep nameserver | awk '{print $2}'):0Then another problem pops up at this stage complaining about authentication failure, which is again relevant to the xserver stuff. I have to use the following command to start the ‚Äòvcxsrv‚Äô server to disable the authentication, C:\Program Files\VcXsrv\vcxsrv. exe  :0 -ac -terminate -lesspointer -multiwindow -clipboard -wglI haven‚Äôt figured out the way to put the command above into the starting batch file of discus_suite, so currently I have to manually execute the command above before launching the discus_suite program. To make life easier, I created a shortcut and associate the shortcut with the command here. Then I put the shortcut into the starting up folder (open the Windows run box by pressing ‚Äò#+r‚Äô - where ‚Äò#‚Äô represents the Windows start key - and put ‚Äòshell:startup‚Äô in it, followed by pressing ‚Äòenter‚Äô to open up the starting up folder). In this way, every time Windows starts, the ‚Äòvcxsrv‚Äô will launch automatically with authentification disabled. "
    }, {
    "id": 60,
    "url": "http://localhost:4001/2020-04-19-cuda_note_II/",
    "title": "Notes on CUDA programming II",
    "body": "2020/04/19 - First of all, we may need a review for the very basic CUDA programming and GPU execution principle. Here, I want to use the diagram below to demonstrate the threadings on GPU with a very simple array addition operation example.  In this simple case, we only have a single block on GPU, which contains, say, 500 threads (the actual number of threads may be larger than 500 but in this example, we only need 500 of them). The part above the dashed line refers to the single block. The for loop in the middle of the bottom half is usually what we do for coding in the array addition task. Basically, we loop over all the 500 indexes to do the addition one-by-one in a serial manner. Using GPU, the working scheme is different. Instead of a single ‚Äòworker‚Äô executing our commands one after another, we now have a whole bunch of ‚Äòworkers‚Äô ready at the same time, waiting for our commands so that they can do their own job, independently. Each ‚Äòworker‚Äô has his/her unique ID - the location within the grid-block-thread organization we talked about in previous note (Click me to transfer there). At the beginning of the workflow, we let each ‚Äòworker‚Äô shout out their unique ID (‚ÄòthreadIdx. x‚Äô in the diagram above). Then we decide which part of the job to assign to each specific ‚Äòworker‚Äô (the assignment ‚Äòi = threadIdx. x‚Äô in the diagram above). After that, each ‚Äòworker‚Äô knows exactly what he/she is responsible for and then goes directly to do job (e. g. ‚Äòc[35] = a[35] + b[35]‚Äô in the diagram above). Here, the diagram only shows the working mechanism on GPU and the data copying in between the host (CPU) and the device (GPU) is not shown. Basically, copying data (the array ‚Äòa‚Äô and ‚Äòb‚Äô here) from host to device is analogous to trucks delivering materials to the factory (the device, our GPU) and copying data (the resulted array ‚Äòc‚Äô here) from device back to host is analogous to factory delivering products to the boss (the host, CPU). Since each ‚Äòworker‚Äô has his/her own unique ID with which we can assign a unique task for each of them. Therefore, the actual order of the job to be carried out does not really matter that much. That‚Äôs why we see that in the diagram above, the #35 part of the job is shown above #10. This is just to demonstrate the idea that order here does not matter. In practice, they all happen in parallel and no one really knows or cares which one of them gets executed/finished first. Based on the further discussion above, we now move on to a slightly complicated case, where we are going to do matrix multiplication with GPU. First, the basic principle of conducting matrix multiplication is shown in the following picture, To conduct the matrix multiplication in a parallel way on GPU, the fundamental idea is to execute each of the block within dashed boxes, independently on individual thread on GPU. To realize that, the basic workflow is presented in the following picture, Following the coding scheme as presented above, the fundamental difference as compared to usual serial coding here is that we represent the matrix in a one-dimensional manner, as indicated by the red arrows on the top of the figure above. The purpose of such a representation is for the ease of coding on GPU kernel, as we will see in the code snippet that will be presented later in current blog. Once we transform our matrix to its one dimensional form, the next step is again to let ‚Äòworkers‚Äô shout out their unique ID, as we have discussed above. In this case, for demo purpose, assume we have a single block which contains (3\times2) thread structure, then in practice we have a one-to-one mapping between ‚Äòworkers‚Äô and the entries of the final product matrix, i. e. each ‚Äòworker‚Äô is responsible for one entry in the final product matrix and none of them is wasted. The reason why we want to point out ‚Äònone is wasted‚Äô is that in practice, it often happens the overall GPU block unit is larger than what we really need. For example, in current example, if we claim a single GPU block with (5\times4) thread structure, we can still find right amount of ‚Äòworkers‚Äô to do jobs for us, but in this case, for sure some of the ‚Äòworkers‚Äô will not be assigned jobs, thus ‚Äòwasted‚Äô. Back to our workflow, once all ‚Äòworkers‚Äô know what they are responsible for, they can go ahead to do their jobs, i. e. multiplying the right row and column of the input matrices and sum up the result to obtain the entry for the final product matrix, as indicated by the part of the diagram above containing a whole bunch of grouped (by ‚Äòworker‚Äô) squares. The explanation presented above about matrix multiplication with CUDA is based on the original blog post in Ref. [1]. Also, the code snippets there are reproduced here in current blog, with detailed comments for better understanding. A makefile, together with instructions about how-to, is also provided at the end of current blog, with which one can straightforwardly compile the code given below. main_mat_mul. cu  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;stdlib. h&gt;#include &lt;time. h&gt;#include &lt;cuda_runtime. h&gt;#include  kernel. h #include  kernel. cu #include  dev_array. h #include &lt;math. h&gt;using namespace std;int main(){  // Perform matrix multiplication C = A * B  // where A, B and C are NxN matrices.   int N = 16;  int SIZE = N*N;  // Allocate memory on the host.   vector&lt;float&gt; h_A(SIZE);  vector&lt;float&gt; h_B(SIZE);  vector&lt;float&gt; h_C(SIZE);  // Initialize matrices on the host.   for (int i=0; i&lt;N; i++){    for (int j=0; j&lt;N; j++){      h_A[i*N+j] = sin(i);      h_B[i*N+j] = cos(j);    }  }  // Allocate memory on the device. The 'dev_array' refers to a class  // defined separately in the 'dev_array. h' file - refer to the header  // list on top of current file.   dev_array&lt;float&gt; d_A(SIZE);  dev_array&lt;float&gt; d_B(SIZE);  dev_array&lt;float&gt; d_C(SIZE);  // The 'set' method defined in the 'dev_array. h' file is responsible for  // copying data from host to device. Here, the first parameter '&amp;h_A[0]' or  // '&amp;h_B[0]' is a pointer specifying the starting position in memory to  // copy from. The second parameter 'SIZE' specifies the number of 'blocks'  // we will copy. Detailed explanation about 'block' will be given in the   // 'dev_array. h' file (refer to the definition of 'set' method there).   d_A. set(&amp;h_A[0], SIZE);  d_B. set(&amp;h_B[0], SIZE);  // Now, we do the matrix multiplication on GPU, by calling the function  // below, which is defined in another separate . cu file - 'kernel. cu' in  // the header of current file. Within 'kernel. cu' file, the fundamental  // kernel function will be defined and called, which is the real part that  // is executing the matrix multiplication. Therefore, the calling scheme  // can be roughly depicted as follows:  //  //         call            call  // Current file  -----&gt; matrixMultiplication -----&gt; kernel  //   matrixMultiplication(d_A. getData(), d_B. getData(), d_C. getData(), N);  cudaDeviceSynchronize();  // The 'get' function is also defined in 'dev_array. h' file, as the 'set'   // function above. It is responsible for copying data from device to host.   d_C. get(&amp;h_C[0], SIZE);  cudaDeviceSynchronize();  // Next, we are going to do the same thing as above, i. e. matrix   // multiplication. This time, we will be doing it on CPU only.   float *cpu_C;  cpu_C=new float[SIZE];  // This is the familiar way of doing matrix multiplication in a serial  // manner on CPU.   float sum;  for (int row=0; row&lt;N; row++){    for (int col=0; col&lt;N; col++){      sum = 0. f;      for (int n=0; n&lt;N; n++){        sum += h_A[row*N+n]*h_B[n*N+col];      }      cpu_C[row*N+col] = sum;    }  }  // Compare GPU and CPU calculation results, for the same job.   double err = 0;  for (int ROW=0; ROW &lt; N; ROW++){    for (int COL=0; COL &lt; N; COL++){      err += cpu_C[ROW * N + COL] - h_C[ROW * N + COL];    }  }  cout &lt;&lt;  Error:   &lt;&lt; err &lt;&lt; endl;  return 0;} dev_array. h  Copy snippet to clipboard!   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99100101102103104105106107108109110111112113114115116117118#ifndef _DEV_ARRAY_H_#define _DEV_ARRAY_H_#include &lt;stdexcept&gt;#include &lt;algorithm&gt;#include &lt;cuda_runtime. h&gt;// Template of type - it's just like a place holder, specifying the declared// variable is of SOME type (not known when being declared). Only when the // declared variable is used do we know what its type is. // See the following site for detailed explanation:// http://www. cplusplus. com/doc/oldtutorial/templates/template &lt;class T&gt;class dev_array{public:  // Refer to the following link for explanation about 'explicit':  // https://stackoverflow. com/questions/121162/what-does-the-explicit-keyword-mean  //   // Here follows we can find explanation about the functionality of  : :  // https://stackoverflow. com/questions/2785612/c-what-does-the-colon-after-a-constructor-mean  //   // Basicaly, we are initializing variables here.   explicit dev_array()    : start_(0),     end_(0)  {}  // Refer to the following link for explanation about data type 'size_t':  // https://en. cppreference. com/w/cpp/types/size_t  explicit dev_array(size_t size)  {    // The 'allocate' function is responsible for allocating memory on     // GPU - refer to the definition of 'allocate' function in the end of     // current file - the private functions part.     allocate(size);  }  ~dev_array()  {    free();  }  // Both the variables 'start_' and 'end_', as we will see later in current  // file, are pointers - 'start_' points to the starting position (in   // memory) and 'end_' points to the end. Therefore, the function defined  // here follows returns the size of the allocated array on GPU.   // Refer to the following site for explanation about const member function  // (i. e. the 'const' keyword after the function name below):  // https://docs. microsoft. com/en-us/cpp/cpp/const-cpp?view=vs-2019  size_t getSize() const  {    return end_ - start_;  }  // Return the starting position in memory, as a pointer.   T* getData() const  {    return start_;  }  // Function responsible for copying data from host to device. 'start_'  // specifies where the copied data will start on device; 'src' specifies  // the source of the copying on host; 'sizeof(T)' specifies the unit of  // the copied block and 'min' here gives how many such units of block will  // be copied.    void set(const T* src, size_t size)  {    size_t min = std::min(size, getSize());    cudaError_t result = cudaMemcpy(start_, src, min * sizeof(T), cudaMemcpyHostToDevice);    if (result != cudaSuccess)    {      throw std::runtime_error( failed to copy to device memory );    }  }  // Similar to the 'set' function above. In this case, we have the copy  // direction reversed - from device to host.   void get(T* dest, size_t size)  {    size_t min = std::min(size, getSize());    cudaError_t result = cudaMemcpy(dest, start_, min * sizeof(T), cudaMemcpyDeviceToHost);    if (result != cudaSuccess)    {      throw std::runtime_error( failed to copy to host memory );    }  }private:  // Allocate memory on device. The starting position in memory on device will  // be returned as a pointer.   void allocate(size_t size)  {    cudaError_t result = cudaMalloc((void**)&amp;start_, size * sizeof(T));    if (result != cudaSuccess)    {      start_ = end_ = 0;      throw std::runtime_error( failed to allocate device memory );    }    end_ = start_ + size;  }  // Free memory on device.   void free()  {    if (start_ != 0)    {      cudaFree(start_);      start_ = end_ = 0;    }  }  T* start_;  T* end_;};#endif kernel. h  Copy snippet to clipboard!  123456#ifndef KERNEL_CUH_#define KERNEL_CUH_void matrixMultiplication(float *A, float *B, float *C, int N);#endif kernel. cu  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;math. h&gt;#include &lt;iostream&gt;#include  cuda_runtime. h #include  kernel. h #include &lt;stdlib. h&gt;using namespace std;// This is where the real magic is happening - the matrix multiplication on GPU// in a parallel manner. __global__ void matrixMultiplicationKernel(float* A, float* B, float* C, int N){  // Here, 'workers' are assigned task, according to their unique ID.   // N. B. the way used here to assign rows and columns for 'workers'  // guarantee that no two 'workers' will be assigned the same row and column  // at the same time.   int ROW = blockIdx. y*blockDim. y+threadIdx. y;  int COL = blockIdx. x*blockDim. x+threadIdx. x;  float tmpSum = 0;  // Now each 'worker' knows exactly what he/she is responsible, it's time  // for them to do their jobs, individually.   if (ROW &lt; N &amp;&amp; COL &lt; N) {    for (int i = 0; i &lt; N; i++) {      tmpSum += A[ROW * N + i] * B[i * N + COL];    }  }  C[ROW * N + COL] = tmpSum;}void matrixMultiplication(float *A, float *B, float *C, int N){  // Here, we use 'dim3' type variables for declaring the number of blocks   // per grid and the number of threads per block.   // Refer to the following link about 'dim3' in CUDA:  // https://codeyarns. github. io/tech/2011-02-16-cuda-dim3. html  // or   // https://docs. nvidia. com/cuda/cuda-c-programming-guide/index. html  dim3 threadsPerBlock(N, N);  dim3 blocksPerGrid(1, 1);  // The IF statement guarantees that we have at most 512 threads per block.   if (N*N &gt; 512){    threadsPerBlock. x = 32;    threadsPerBlock. y = 16;    blocksPerGrid. x = ceil(double(N)/32);    blocksPerGrid. y = ceil(double(N)/16);  }  matrixMultiplicationKernel&lt;&lt;&lt;blocksPerGrid,threadsPerBlock&gt;&gt;&gt;(A, B, C, N);} ========================I AM A SEPARATOR======================== To compile the codes given above, one may want to first save each individual snippet to a separate file (with file name as exactly given on top of each snippet) and also guarantee that all files stay in the same folder. Then one can use the makefile given below to compile the codes to get the executable, by simply executing ‚Äòmake‚Äô on terminal.  Makefile  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 9101112NCC=nvccOBJ=kernel. o main_mat_mul. omat_mul: $(OBJ)&nbsp;&nbsp; &nbsp;$(NCC) -o $@ $^main_mat_mul. o: kernel. o&nbsp;&nbsp; &nbsp;$(NCC) -c main_mat_mul. cukernel. o:&nbsp;&nbsp; &nbsp;$(NCC) -c kernel. cu References [1] https://www. quantstart. com/articles/Matrix-Matrix-Multiplication-on-the-GPU-with-Nvidia-CUDA/ "
    }, {
    "id": 61,
    "url": "http://localhost:4001/2020-04-19-cuda_note_I/",
    "title": "Notes on CUDA programming I",
    "body": "2020/04/19 - To understand and implement CUDA codes in practice, the very first step is to understand the allocation of threads on GPU. Fundamentally, threads are basic units on GPU where computation can happen in a parallel way. To the first level, threads are grouped into blocks, either in a 1D, 2D or 3D manner, where each thread within a certain block has its own ‚Äúcoordinate‚Äù - a unique index for pinning down the location of a certain thread in the block. At the second level, blocks are further grouped into grid, in a similar way as how threads are grouped into block. Here we use three diagrams showing the basic idea of such a division manner for GPU computation units and how we really locate a thread in a block and a block in a grid.    Copy snippet to clipboard!  1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233343536373839404142#include &lt;stdio. h&gt;__global__void saxpy(int n, float a, float *x, float *y){ int i = blockIdx. x*blockDim. x + threadIdx. x; if (i &lt; n) y[i] = a*x[i] + y[i];}int main(void){ int N = 1&lt;&lt;20; float *x, *y, *d_x, *d_y; x = (float*)malloc(N*sizeof(float)); y = (float*)malloc(N*sizeof(float)); cudaMalloc(&amp;d_x, N*sizeof(float));  cudaMalloc(&amp;d_y, N*sizeof(float)); for (int i = 0; i &lt; N; i++) {  x[i] = 1. 0f;  y[i] = 2. 0f; } cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice); // Perform SAXPY on 1M elements saxpy&lt;&lt;&lt;(N+255)/256, 256&gt;&gt;&gt;(N, 2. 0f, d_x, d_y); cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost); float maxError = 0. 0f; for (int i = 0; i &lt; N; i++)  maxError = max(maxError, abs(y[i]-4. 0f)); printf( Max error: %f\n , maxError); cudaFree(d_x); cudaFree(d_y); free(x); free(y);}One can save the codes as a file with extension ‚Äò. cu‚Äô and compile the codes using ‚Äònvcc‚Äô compiler provided by NVIDIA (Click Me!), just like usually what we do for compiling normal C codes, e. g. by executing ‚Äònvcc -o first_cuda_demo first_cuda_demo. cu‚Äô. Here, we won‚Äôt go into further details about the code (refer to Ref. [1] for more introduction), and instead we will give here an abstract skeleton of the codes to get a bird view.  Also, one can define all the CUDA relevant executions as a dedicated and callable routine. Then we can call the CUDA routine from normal C, C++, Fortran or whatever relevant codes. For example, we can write the codes above in a manner as shown below. First, the caller C codes,  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829#include &lt;stdio. h&gt;#include &lt;stdlib. h&gt;#include &lt;string. h&gt;#include &lt;cuda. h&gt;extern void cuda_kernel(float *x, float *y, int N);int main(int argc, char *argv[]){ int N = 1&lt;&lt;20; float *x, *y; x = (float*)malloc(N*sizeof(float)); y = (float*)malloc(N*sizeof(float)); for (int i = 0; i &lt; N; i++) { x[i] = 1. 0f; y[i] = 2. 0f; } cuda_kernel(&amp;x, &amp;y, N); float maxError = 0. 0f; for (int i = 0; i &lt; N; i++) {  maxError = max(maxError, abs(y[i]-4. 0f)); } printf( Max error: %f\n , maxError); return 0;}Saving the codes above as, e. g. ‚Äòcaller. c‚Äô. Then the callee CUDA codes,  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 9101112131415161718192021222324252627#include &lt;stdio. h&gt;__global__void saxpy(int n, float a, float *x, float *y){ int i = blockIdx. x*blockDim. x + threadIdx. x; if (i &lt; n) y[i] = a*x[i] + y[i];}int cuda_kernel(float *x, float *y, int N){ float *d_x, *d_y; cudaMalloc(&amp;d_x, N*sizeof(float));  cudaMalloc(&amp;d_y, N*sizeof(float)); cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice); // Perform SAXPY on 1M elements saxpy&lt;&lt;&lt;(N+255)/256, 256&gt;&gt;&gt;(N, 2. 0f, d_x, d_y); cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost); cudaFree(d_x); cudaFree(d_y);}Saving the callee CUDA codes above as, e. g. , ‚Äòcallee. cu‚Äô. Then use the Makefile provided below to compile the executable,  Copy snippet to clipboard!  1 2 3 4 5 6 7 8 91011121314CC=gccNCC=nvccOBJ=caller. oCUDA_OBJ=callee. ocall_cuda: $(OBJ) $(CUDA_OBJ) $(CC) -o $@ $^$(OBJ): %. o: %. c $(CC) -c $&lt;$(CUDA_OBJ): %. o: %. cu  $(NCC) -c $&lt;Basically, during compiling, we can treat the CUDA codes just as normal C codes. Also, as usual, when library is used in the CUDA codes, we need to link to the libraries as we do for normal C codes (or whatever relevant codes, e. g. , Fortran). In the following blog, I will note down a slightly more complicated case - matrix multiplication with CUDA.  References [1] https://devblogs. nvidia. com/easy-introduction-cuda-c-and-c/ "
    }, {
    "id": 62,
    "url": "http://localhost:4001/2020-03-29-notes_mag_II/",
    "title": "Notes on magnetism - II",
    "body": "2020/03/29 - Talking about the magnetism of ions in crystals naturally brings us out of the atomic physics picture which we previously based ourselves in when discussing the free atom and ions (see previous note by clicking me!). Also, for sure we should turn to the many-electron scheme instead of a single-electron one. However, to build up the final multi-electron picture, we can potentially take the single-electron pathway. This is quite similar to the situation of independent atoms, where we have been mentioning the coupling between angular momentum of multi-electrons. The pathway we take thereby is also a single-electron one. For example, based on Hund‚Äôs rule, we talk about filling electrons one-by-one to various energy levels to finally build up the ground state. Here, for discussing the magnetism of ions in crystals, Hund‚Äôs rule can still be used in some situations. However, attention should be paid and we will revisit this issue later by inspecting a specific example. To start, we first notice that usually the orbitals involved in magnetism are either (3d) (e. g. transition metals) or (4f) (e. g. rare earth metals), both of which are strongly localized (as compared to, e. g. (s) orbitals). Therefore, we can still treat those ions as being isolated. However, they are not completely isolated as being free ions and the states will be more or less influenced by the surroundings.  Although we say both (3d) and (4f) orbitals are strongly localized, electrons in either of those states can still move in the whole crystal [1]! In a broad sense, such effect upon states exerted by the surroundings in crystal can be called the crystal field effect, which has different pictures in two distinctive situations - (3d) orbital involved transition metal ions and (4f) orbital involved rare earth metal ions [1].  For rare earth metals, because overlapping between (4f) is weak and therefore the crystal field effect is also weak since it is purely coming from electrostatic potential. In comparison for transition metal, the (3d) orbital overlapping is much stronger and therefore the crystal field effect is also much stronger as the result of hybridization (see page 15 in [2]). In former case, the (LS) coupling is considered first to go into the coupled (J) representation and then the crystal field is considered to split the degenerate (J) levels. Hereby, it should be pointed out that in this case we directly go into multi-electron picture without going through the single-electron pathway as before! Detailed discussion can be found in page 15-18 in Ref. [2], where the magnetic anisotropy pops up naturally as the result of symmetry-adapted Hamiltonian (see page-18 in Ref. [2]). For the latter situation, the crystal field effect is strong and thus is considered as the main factor, which splits the degenerate (L) levels. The (LS) coupling and other effects such as Zeeman effect are then considered as perturbations (see page 27-33 in Ref. [1]). Again, magnetic anisotropy naturally pops up as the result of either (LS) coupling or Zeeman term in the Hamiltonian (see page 34-37 in Ref. [1]). Moreover, Jahn-Teller effect also plays an important role for splitting states if the ground state is non-degenerate (see Ref. [3] and page section-3. 4 in Ref. [1]).  Here we have two important things to mention. 1) When the ground state (see the example below for detailed explanations) is non-degenerate, it can be proved (see page 34-35 in Ref. [1]) that the contribution from orbital angular momentum (the coupled multi-electron one) to the Hamiltonian is 0. We say in such a situation, the orbital angular momentum is quenched. 2) When we have odd number of electrons, the doubly degeneracy of spin (z) component is not broken by the crystal field, which is called Kramers theorem and the still degenerate spin doublet is called Kramers doublet. For understanding the splitting of (L) levels (which is obviously a multi-electron problem), here we can take a single-electron pathway. Taking the cubic symmetry as an example, first we can obtain the split states as the result of crystal field effect - the splitting into (t_{2g}) and (e_g) levels. Then according to the strength of the crystal field effect as compared to the energy for pairing electrons (the first Hund coupling, see previous note, by clicking me), we either have low-spin or high-spin situations - see Ref. [3] and page 21-22 in Ref. [2]. Suppose we have the low-spin situation, and for example we have 6 (d) electrons, the electrons can be filled into available states following the first Hund‚Äôs rule, as follows, Any one of the three situations shown above can be our ground state and therefore in this case we have triplet degeneracy in our ground coupled state. Such a picture is exactly consistent with what we will get following the multi-electron approach, as shown in page 30-34 in Ref. [1].  Since we have hybridization of orbitals here, the single electron orbital angular momentum quantum number is no longer a good one. Therefore, the second Hund‚Äôs rule no longer works here and that‚Äôs why we have the triplet degeneracy in the example shown above. Similar discussion can be made for other situations - refer to the states splitting discussed in page 19 in Ref. [2] and page 32-33 in Ref. [1].  For high-spin situation, we can also follow the single-electron pathway to discuss the degeneracy problems of the ground state. A full picture of electron configurations for both low-spin and high-spin situations can be found in Ref. [3]. N. B. when the energy difference between low-spin and high-spin configuration is not so large, we can potentially have the spin crossover - see page 21-22 in Ref. [2] - as the result of thermal effect.  References [1] K. Yosida. Theory of magnetism. Springer. 1996. [2] Theory of magnetism, by C. Timm. [3] Jahn-Teller Distortions, from Chemistry LibreText. "
    }, {
    "id": 63,
    "url": "http://localhost:4001/2020-03-18-notes_mag_I/",
    "title": "Notes on magnetism - I",
    "body": "2020/03/18 - To understand the magnetism of free atoms and ions, we may go through several stages, as follows, Hartree approximation - electrons are treated in a non-interactive manner. Beyond Hartree - interaction between electrons is taken into account. Spin-orbital coupling. Hyperfine interaction - the interaction between electrons and nucleus. Stage-1At this stage, the single electron Schrodinger equation can be solved in the spherical potential field and one can get quantized energy levels indexed by quantum number (n), (l) and (m). Hydrogen atom is the simplest and the most special case - the Coulomb potential is rigorously inverse proportional to (r) and therefore energy levels with the same (n) but different (l) are degenerate. For general cases, e. g. hydrogen-like atoms, the effective Coulomb potential is not rigorously inverse proportional to (r), as the result of screening effect from the atom core charge (nucleus + electrons). This results in the splitting of (r) levels. However, no matter for which situation, the degeneracy over (m) is always there. Based on the recipes given here, one can then follow the Aufbau principle to fill electrons into various shells. Suppose we have already filled all levels between 1s and 4s and we are left with 5 more electrons to worry about, how many possibilities we have to finish filling the 5 electrons? The general formula is given as (C_{2(2l+1)}^{n_{nl}})where (l) refers to the angular momentum quantum number and (n_{nl}) refers to the number of left-over electrons. The logic here is that we have in total (2(2l+1)) degenerate states (considering spin up and down) and we can just pick up any (n_{nl}) ones from them to fill electrons, simply because they are all degenerate.  Stage-2Going beyond the Hartree approximation, we start to consider the interaction between electrons and here it comes that Hund‚Äôs rule plays an important role for determining the ground state (N. B. Hund‚Äôs rule is not working for determining excited state. Also, it is even not working perfectly, though for most of cases it is working fine, for determining the ground state). Behind the Hund‚Äôs rule, we have some fundamental physics, which we will mention later. But here we take exactly the same example mentioned above - to fill 5 electrons into the 3d levels. The 1st Hund‚Äôs rule says we should have the maximum coupled S. Here it immediately brings in a critical question: what coupled S really is. We already said that by going beyond the Hartree approximation, interaction between electrons is taken into account. Therefore, now electrons are not independent any more and we say they are coupled, including the coupling between orbital and spin momentum. In another word, previously we have been using (l), (s), (m_l) and (m_s) to label quantum states, but now we have to change our label for quantum states to the coupled representation, using (L), (S), (m_L) and (m_S) instead. How to get to coupled representation from independent representation is a typical/fundamental quantum mechanics problem, for which we can refer to Shankar‚Äôs book Principles of quantum mechanics (2nd edition, chapter-15). Back to the 1st Hund‚Äôs rule mentioned above (focusing on the coupling between electron spins for the moment), it can give us a non-degenerate (unique) ground state, with spins of all the five electrons aligned in a parallel manner, occupying each of the (m_l = -2, -1, 0, 1, 2) level. Why? Because Hund‚Äôs rules says we should have the coupled (S) as large as possible, and we know that the largest (S) should be equal to the largest possible value of (S_z). Furthermore, we know for sure that the largest possible value of (S_z) should be (5/2) with all spins lined up in the same direction. Here it may be a bit confusing that we said we go from independent representation to coupled representation, but it seems that the ground coupled state is just one of the original state in the independent representation. Actually, they are just seemingly identical and actually they are different stuff - in the coupled representation, the ground state we arrived at above is labeled with quantum number (S = 5/2) and (m_S = 5/2). However, for the independent representation, we have 5 independent labels for this single state (it‚Äôs just that all the five labels takes (m_s = 1/2))! Furthermore, if going beyond the ground state, we will immediately see the difference between these two representations - in most of the cases, the coupled state is a superposition of those states in the independent representation, where we have the so-called Clebsch-Gordan (CG) coefficients as the linear combination coefficients. For those excited states in the coupled representation, again we can refer to Shankar‚Äôs book mentioned above for details (chapter-15).  Here, though not directly relevant to current discussion, it‚Äôs still worth mentioning the other two general important issues in fundamental quantum mechanics (which most people just take for granted yet without knowing why): 1) given the principal quantum number (n), we all know the orbital angular momentum can take (0, 1, \dots, n-1). But why? We can find the answer to this question in Shankar‚Äôs book mentioned above (page 422-423, 2nd edition), where the quantum version of Runge-Lenz vector is introduced to act as a ladder operator with respect to orbital angular momentum. The values of orbital angular momentum is then obtained by observing that all (l&gt;n) terms will vanish. 2) Given the orbital angular momentum quantum number (l), we all know (m_l = -l, -(l-1), \dots, (l-1), l). But why? The answer to this question can be found in page 321-324 in Shankar‚Äôs book and again the ladder operator is acting an important role here. When the coupled spin (S) does not recognize a unique ground state, here comes the 2nd Hund‚Äôs rule, concerning coupling of orbital angular momentum. It says the ground state should be the one with largest coupled (L). Following the same recipe above, we should immediately know that we are actually looking for a state with largest possible (L_z). For the five electrons situation mentioned above, coupled (S) has already specified a unique ground state. To demonstrate the 2nd Hund‚Äôs rule, we go for six electrons situation. Following the 1st Hund‚Äôs rule, the first five electrons should line up in a parallel manner into the five available levels and the 6th electron can choose whichever of the first five electrons to pair with, and obviously after pairing we should have the 6th electron aligned in the opposite direction with the spins of the first five electrons. To determine the true ground state, we need the 2nd Hund‚Äôs rule here - we are trying to look for the largest possible (L_z), which obviously point to that the 6th electron should be put on the level indexed by (m_L = \pm 2) (here the sign does not really make any difference since it is just a matter of choosing the positive direction of (z)-axis).  The golden rule to keep in mind concerning the angular momentum coupling is that the value of the coupled angular momentum is equal to the largest possible sum of the corresponding magnetic quantum number of all the independent angular moment. Considering the interaction between electrons, the total number of non-degenerate states become ((2L+1)(2S+1)).  Understanding the physics behind the first two Hund‚Äôs rules. 1) Considering the first Hund‚Äôs rule, according to Pauli exclusion principle, electrons are not allowed to stay at exactly the same state. Therefore, by aligning in a parallel manner, electrons have to ‚Äòstay away from each other‚Äô (e. g. by taking up states indexed by different magnetic quantum number), which then help reducing the system energy (we can understand this as an effective Coulomb repulsion). 2) As for the second Hund‚Äôs rule, electrons tend to have the same orbital angular momentum, which means they rotate in the same direction and therefore they become further apart effectively because of the Coulomb repulsion - this also helps lowering the system energy.  Stage-3 Now we need to bring in the spin-orbital coupling, which is crucial for understanding both the magnetic property of free atoms or ions discussed here and that of solid materials where atoms are bonded together to form crystal field. Attached picture shows two key figures in shaping quantum mechanics - Paul Dirac and Wolfgang Pauli. Specially, the relativistic version of ({\rm{Shr}}\ddot o{\rm{dinger}}) equation given initially by Dirac not only embed spins in a natural way, but also it brings in the spin-orbital coupling term explicitly. Here we will just briefly mention the spin-orbital coupling in terms of (LS) mode coupling (another alternative coupling mode is the (jj) mode, for which the coupling between (l) and (s) of a single electron is considered first and the coupling between electrons are considered as perturbation. In contrast, for the (LS) mode coupling, since the coupling between electrons is stronger, all (l)‚Äôs and (s)‚Äôs are coupled first and (LS) coupling is considered afterwards). Within the (LS) coupling mode, (L) and (S) are coupled following the basic addition principle of angular momentum (see chapter-15 in Shankar‚Äôs book mentioned above), which gives (J = |L-S|, \dots, |L+S|). In this case, the degenerate states in stage-2 discussed above will be further split, with respect to the coupled quantum number (J) and here we have the 3rd Hund‚Äôs rule comes into play - the ground state takes minimum (J) if we have less than half filled levels (e. g. suppose the situation where we have 4 electrons filling the (3d) level); or the ground state takes maximum (J) if we have more than half filled levels (e. g. suppose the situation where we have 6 electrons filling the (3d) level); when we have half filled level, the 3rd Hund‚Äôs rule becomes trivial since we have (L = 0) (e. g. suppose the situation where we have 5 electrons filling the (3d) level) and thus we have (|L-S| = |L+S|).  Stage-4The hyperfine interaction which further splits energy levels is due to the interaction between nucleus spins and electron spins. Detailed formulation is a bit complicated and we won‚Äôt proceed with it here. We can refer to section-2. 6 in the lecture note Theory of Magnetism by Dr. C. Timm. "
    }, {
    "id": 64,
    "url": "http://localhost:4001/2020-03-08-coriolis_force/",
    "title": "About Coriolis force",
    "body": "2020/03/08 - First, a comprehensive GIF animation demonstrating the basic ideas of Coriolis force is presented.   Detailed explanation and derivation is presented in the following embedded document.  "
    }, {
    "id": 65,
    "url": "http://localhost:4001/2019-12-10-special_relativity/",
    "title": "Notes on special relativity",
    "body": "2019/12/10 -  The speed of light always is ‚Äòc‚Äô, no matter where we are (either on the moving body or on any rest ‚Äòground‚Äô). This is one of the two fundamental assumptions based on which Einstein‚Äôs special theory of relativity stands. This is, as a matter of fact, the result of experiment, not imagination or assumption of Einstein, Feynman, or anybody else. The famous experiment is called Michelson-Morley experiment, the details of which can be found in Wikipedia. The basic idea of this experiment is: assuming the speed of light ‚Äòc‚Äô is specifically relative to something (historically, the ‚Äòsomething‚Äô here was called aether, from what I remember), then we know our earth is rotating around the self-axis, thus the speed of light, of course, is NOT ‚Äòc‚Äô, if our previous assumption (‚Äòc‚Äô is specifically relative to aether) stands. Then using the facility designed by Michelson and Morley, we should observe some corresponding effect, which is the result of the changing of speed of light relative to our earth. I won‚Äôt bother with what the effect will be like (detailed information can be found in the link at the bottom), but I can tell the result: no expected effect was observed if our previous assumption stands! That‚Äôs it, it seems that we have to accept the experimental FACT that speed of light is always ‚Äòc‚Äô ‚Äì relative to the observer on spacecraft, or relative to our earth, or relative to anything moving on the earth, or, or, relative to ANYTHING in the universe. Actually, it was just the result of the famous Michelson-Morley experiment (and some other following experiments ‚Äì see the link below) that directly leads to the invention of the special theory of relativity. Moreover, the invariance of speed of light is one of the two basic principles of special theory of relativity. Furthermore, when we are talking about TIME, we actually mean the interval (along time axis) between two EVENTS. So imagine the process of a ball rising up from the ground and falling back to the ground. So the two events, in this case, are ‚Äòball leaves the surface ‚Äì starting to rise up‚Äô and ‚Äòball comes back to the surface ‚Äì finishing falling down‚Äô. Then two observers ‚Äì one moves together with the ball and the other one stands on the rest ‚Äòground‚Äô ‚Äì observe exactly the same two events, are the time (interval) measured by these two guys going to be different? The answer is: Yes. Why? Why? Why? Well, again, this is what we have to accept as the FACT. However, it‚Äôs worth a bit explanation, and now we need to go back to the experimental FACT ‚Äì the speed of light does not change from frame to frame (ignoring the influence of medium, e. g. from air to water, and all the other effects). It is based on this FACT that people (Lorentz should be one of them, I think) obtained the invariant quantity called space-time interval for ANY frames. The definition is, [{s^2} = - {c^2}{(\Delta t)^2} + {(\Delta x)^2} + {(\Delta y)^2} + {(\Delta z)^2}] To better express the idea, here I give an example as following, Time and length by different observer. In the figure, there are two observers in one-dimension frames ‚Äì one is standing on the ground, and the other is moving relative to the ground with the speed of v. Let‚Äôs call the axis x-axis, and the frame for observer-1 and observer-2 is named frame-1 (for which we use the notion x‚Äô and t‚Äô) and frame-2 (for which we use the notion of x‚Äô‚Äô and t‚Äô‚Äô), respectively. Moreover, both observer-1 and observer-2 stays at their own origins. Now, let‚Äôs imagine two bulb emitting light (as shown in the figure) one after another. Right at the beginning, bulb-1 emits light at the origin of frame-1, and just at that moment, observer-2 is also at the origin of frame-1 (which means the origins of frame-1 and frame-2 coincides with each other). Then we record the position and time for the event of bulb-1 emitting light, in two frames. For frame-1, it is: ({x_0} = 0), ({t_0} = 0), and for frame-2, it is: x‚Äô = 0, t‚Äô = 0. Then after some moments, observer-2 (remember? observer-2 is moving with speed of v, in frame-1, or as seen from observer-1) arrives at the position where bulb-2 is placed in frame-1, and JUST AT THAT EXACT MOMENT, bulb-2 emits light. Then we write down the position and time for the event of bulb-2 emitting light. For frame-1, it is: ({x_1} = x), ({t_1} = t), and for frame-2, it is: ({x‚Äô_1} = 0), ({t‚Äô_1} = t). You guess what? The two events happens at the same place as seen by observer-2 (or we say, in frame-2)!So now, we have two events - emission of the two bulbs. What we suspect is: is t (the time interval for these two events observed in frame-1, or by observer-1) and t‚Äô (the time interval for these two events observed in frame-2, or by observer-2), the same? Or different? Let‚Äôs have a look. As is already given above, we have the invariant quantity s from frame to frame, thus we have, [- {c^2}{t^2} + {x^2} = - {c^2}t{‚Äò^2} + 0] What else do we have? Remember observer-2 arrives at bulb-2 at the exact moment when bulb-2 emits light? So definitely we should have, [vt = x] By replacing (x) into the previous equation, we have, [- {c^2}{t^2} + {v^2}{t^2} = - {c^2}t{‚Äò^2}] Rearranging the above equation, it is easy to get, [t = \frac{1}{\sqrt{1 - \frac{v^2}{c^2}}}t‚Äô = \gamma t‚Äô] So, so, so, finally, without assuming anything except accepting the FACT that speed of light doesn‚Äôt change from frame to frame (based on which we then have the invariant quantity space-time interval), we obtain the result that for the two events that we cannot visually ‚Äòfeel‚Äô any difference when changing the observing frame, the time interval observed in two different frames (one is moving relative to another), is indeed different! ‚Äì They are linked up by the so called Œ≥ factor, as you can see from the above formula. What else can we say? Well, I should say, the difference of time interval observed in different frames (moving relative to each other) between two events, is some kind of PROPERTY of our space, and time. I am afraid, we have to accept it, maybe, no other choice.  N. B. The original post is from my answer to people‚Äôs question concerning the special theory of relativity on Stack Exchange. Click me to go to Stack Exchange Q &amp; A.  References [1] https://www. livescience. com/making-stable-wormholes. html "
    }, {
    "id": 66,
    "url": "http://localhost:4001/2019-12-08-einstein_fridge/",
    "title": "A silent refrigerator",
    "body": "2019/12/08 - All refrigerators running with gas relies on the principle that the evaporation of liquid to its corresponding gas form will take heat from surroundings. After evaporation, the gas should be liquefied back to liquid form to finish the cycle, and of course, the process of liquefaction will emit heat. That‚Äôs why need a fan (that‚Äôs just where the noise come from, which is also we want to diminish or even remove) for the commonly used gas-compression-based refrigerator to bring that part of emitted heat to the surrounding environment to keep it cool inside the refrigerator. The so-called absorption refrigerator, as one kind of gas-based refrigerator, also work on the evaporation and liquefaction of gas as mentioned above. But the difference here is that it does not bring the evaporated gas to its liquid form through compression. Instead, the evaporated gas will be solved (i. e. absorbed, thus comes the name ‚Äòabsorption refrigerator‚Äô) in some solvent, which then finish the cooling-and-heating cycle. [1, 2]General introduction to all kinds of refrigerators including the absorption refrigerator can be found everywhere on Internet, and a simple Googling will produce a lot of results [1-5]. Here in this post, I will focus on introducing a typical absorption refrigerator designed by Albert Einstein and his former student Le√≥ Szil√°rd in 1926 and patented in US in November 11, 1930 [4]. This summary is created based on the following references: Ref [6, 7]. First of all, the picture demonstrating the basic design of Einstein‚Äôs frig from Wikipedia is presented here as following, Figure. 1. The annotated patent drawing for Einstein‚Äôs fridge. Image reproduced from Ref. [4]. The working gas in Einstein‚Äôs frig is ammonia and butane ,and the absorption media is water which both ammonia and butane can be resolved in. As shown in Fig. 1, first of all, the ammonia gas is generated in the Generator (Fig. 1, No. 29), which is actually just a heater that heats the ammonia up to accelerate the evaporation of ammonia. Through Conduit D (Fig. 1, No. 30), ammonia gas will reach the Evaporator (Fig. 1, No. 1), which is the heart of Einstein‚Äôs frig and also where the cooling actually happens. Before going on, there are several key aspects to keep in mind, the first one is that unlike the electric frig, Einstein‚Äôs frig has the same pressure in all parts of the cycle. The second aspect is that the boiling point of certain matter (in this case specifically we mean butane contained in the Evaporator) decreases as the reduction of the corresponding partial pressure of that matter. In the first step of the cycle described above, we mentioned that the evaporated ammonia gas reaches the Evaporator, which naturally leads to the increasing of the partial pressure of ammonia. Also we already know that the pressure in all parts of the cycle keeps nearly as constant, and the total pressure is roughly the sum of the partial pressure of all component gas, [{P_{total}} = {P_1} + {P_2} + \cdots + {P_i} + \cdots] where ({P_1}), ({P_2}), etc. refers to the partial pressure corresponding to each single component in the system. As a result, with the introduction of ammonia into the Evaporator, the increasing of the ammonia partial pressure will lead to the reduction of the butane partial pressure. Then the boiling point of butane will decrease accordingly, which will lead to the evaporation of butane to cool itself and the environment. Here the ‚Äòenvironment‚Äô basically means part No. 5 in Fig. 1, where the food is kept. The mixture of ammonia and butane will then flow to the Condenser/Absorber (Fig. 1, No. 6), where water is sprinkled (since the water Container ‚Äì Fig. 1, No. 33 ‚Äì is located higher in position than the sprinkle head ‚Äì Fig. 1, No. 35, water can sprinkle automatically without problem) to absorb/resolve ammonia. Now the partial pressure of butane should increase accordingly when then lead to the condensation of butane (that‚Äôs why part No. 6 is also called the Condenser). The released heat accompanying the condensation then can be removed by the environment, e. g. by the flowing cooling water surrounding the Condenser, Fig. 1 ‚Äì the blue-colored part surrounding the Condenser. In the Condenser, the ammonia-water solution and ammonia-butane liquid forms two layers because of the difference in density. Here the ammonia-water solution in the Condenser is higher in position as compared to that in the Generator, which therefore promises the back-flowing of ammonia-water solution to the Generator automatically. In the way of flowing back to the Generator, the ammonia-water solution goes through the Heat Exchanger Jacket (Fig. 1, No. 28), where part of the heat carried by the ammonia-water solution is passed to the water in Conduit No. 37. Also, the water is heated in No. 36 Conduit, and I believe (although I am not sure and don‚Äôt have any supporting documents by hand) such heating may be beneficial for the circulating (this sprinkling) of water. Although the environment contaminating gas feron used in the conventional compression-based frig has already been replaced by the environment friendly tetrafluoroethane (CH2FCF3) [5], the potability and miniaturisation are still big issues. For example, in some poor regions around the world where there is not much or even no electricity, portable frig is indeed necessary especially to keep vaccine cool before being used to save lives. In September 8, 2016, it was reported [8] the revamping of Einstein‚Äôs frig won researcher William Broadway the 2016 UK James Dyson Award. Also considering the noise-free property of Einstein‚Äôs frig, there are indeed reasons that we should believe the old invention still shines nearly a century later since its first coming-out.  References [1] http://www. lafn. org/~dave/gas-frig. txt [2] https://en. wikipedia. org/wiki/Refrigerator [3] https://en. wikipedia. org/wiki/Absorption_refrigerator [4] https://en. wikipedia. org/wiki/Einstein_refrigerator [5] https://www. quora. com/Which-gas-is-used-in-refrigerators-nowadays [6] http://blog. lib. uiowa. edu/eng/how-cool-is-this/ [7] https://grouptms2. wordpress. com/2012/03/16/working-principle-of-a-einsteins-refrigerator/ [8] http://physicsworld. com/cws/article/news/2016/sep/08/flash-physics-dyson-award-for-einstein-s-fridge-australian-centres-of-excellence-mapping-our-galaxy-s-age "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}
</script>
<style>
    #lunrsearchresults {padding-top: 0.2rem;}
    .lunrsearchresult {padding-bottom: 1rem;}
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <p><input type="text" class="form-control" id="lunrsearch" name="q" maxlength="255" value="" placeholder="üîç" /></p>
</form>
<div id="lunrsearchresults">
    <ul></ul>
</div>



  
</div>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row column_top">
        <div class="col-xl-10 offset-xl-1 col-lg-10 offset-lg-1">
        <h3>External Links</h3>
        </div>
    </div>
    <div class="row" style="margin-bottom:10px">
        <div class="col-xl-10 offset-xl-1 col-lg-10 offset-lg-1">
      <div class="column" style="background-color:#EAEAEA;">
        <h4>Monte Carlo</h4>
				<a target="_blank" href="https://tproffen.github.io/DiffuseCode/">DISCUS</a>
				</br>
				<a target="_blank" href="https://www.szfki.hu/~nphys/rmc++/opening.html">RMC++</a>
				</br>
				<a target="_blank" href="https://research.csiro.au/mmm/hrmc/">HRMC</a>
				</br>
				<a target="_blank" href="https://bachiraoun.github.io/fullrmc/">fullrmc</a>
				</br>
        <a target="_blank" href="http://www.dragon.lv/exafs/rmc.htm">RMC for EXAFS</a>
        </br>
        <a target="_blank" href="https://www.isis.stfc.ac.uk/Pages/Empirical-Potential-Structure-Refinement.aspx">EPSR</a>
				</br>
				<a target="_blank" href="http://wwwisis2.isis.rl.ac.uk/rmc/">RMC at ISIS facility</a>
				</br>
				<a target="_blank" href="http://www.rmcprofile.org/Main_Page">RMCProfile website - legacy</a>
				</br>
				<a target="_blank" href="https://en.wikipedia.org/wiki/Reverse_Monte_Carlo">Wikipedia for RMC</a>
      </div>
      <div class="column" style="background-color:#EAEAEA;">
        <h4>Rietveld-like</h4>
        <a target="_blank" href="https://www.diffpy.org/products/pdfgui.html">PDFgui</a>
        </br>
        <a target="_blank" href="https://www.diffpy.org/products/diffpycmi/index.html">DIFFPy-CMI</a>
        </br>
        <a target="_blank" href="https://www.diffpy.org/products/mPDF.html">magnetic PDF</a>
        </br>
        <a target="_blank" href="https://community.dur.ac.uk/john.evans/topas_workshop/tutorial_pdf_sno2.htm">Topas for PDF</a>
      </div>
      <div class="column" style="background-color:#EAEAEA;">
        <h4>Tools</h4>
        <a target="_blank" href="http://addie.ornl.gov/">ADDIE (ORNL internal)</a>
        </br>
				<a target="_blank"
						href="http://li.mit.edu/Archive/Graphics/A/">Atomeye</a>
				</br>
				<a target="_blank"
						href="https://sourceforge.net/projects/xming/">Xming</a>
				</br>
				<a target="_blank"
						href="https://www.mantidproject.org/Main_Page">Mantid</a>
				</br>
				<a target="_blank" href="https://www.facebook.com/disord.matt">GUDRUN</a>
				</br>
				<a target="_blank"
						href="https://www.diffpy.org/products/pdfgetx.html">PDFGet..
						</a>
				</br>
				<a target="_blank" href="https://www.ncnr.nist.gov/resources/n-lengths/">Neutron scattering length</a>
				</br>
				<a target="_blank" href="http://wwwisis2.isis.rl.ac.uk/reference/Xray_scatfac.htm">X-ray form factor</a>
				</br>
				<a target="_blank" href="https://www.webelements.com/">Web elements</a>
				</br>
				<a target="_blank" href="https://ptable.com/#Properties">Dynamic
						periodic table</a>
				</br>
				<a target="_blank" href="http://wwwisis2.isis.rl.ac.uk/disordered/Manuals/ATLAS/atlas_values.htm">ISIS values</a>
				</br>
      </div>
      <div class="column" style="background-color:#EAEAEA;">
        <h4>Facilities</h4>
				<a target="_blank" href="https://neutrons.ornl.gov/nomad">US - ORNL - NOMAD</a>
        </br>
				<a target="_blank" href="https://neutrons.ornl.gov/powgen">US - ORNL -
						POWGEN</a>
				</br>
				<a target="_blank" href="https://www.aps.anl.gov/Beamlines/Directory/Details?beamline_id=16">US - APS - 11-ID-B</a>
				</br>
				<a target="_blank" href="https://www.bnl.gov/ps/beamlines/beamline.php?r=28-ID-1">US - BNL - 28-ID-1</a>
				</br>
				<a target="_blank"
						href="https://www.isis.stfc.ac.uk/Pages/Gem.aspx">UK - ISIS - GEM</a>
				</br>
				<a target="_blank" href="https://www.isis.stfc.ac.uk/Pages/polaris.aspx">UK - ISIS - Polaris</a>
				</br>
				<a target="_blank" href="https://www.diamond.ac.uk/Instruments/Crystallography/I15-1.html">UK - Diamond - I15-1</a>
				</br>
				<a target="_blank" href=""https://mlfinfo.jp/en/bl21/>Japan - J-PARC - NOVA</a>
				</br>
				<a target="_blank" href="http://www.spring8.or.jp/wkg/BL14B1/instrument/lang-en/INS-0000000309/instrument_summary_view">Japan - SPRING8 - BL14B1</a>
				</br>
				<a target="_blank" href="http://www.spring8.or.jp/wkg/BL22XU/instrument/lang-en/INS-0000000327/instrument_summary_view">Japan - SPRING8 - BL22XU</a>
				</br>
				<a target="_blank" href="https://europeanspallationsource.se/instruments/heimdal">Europe - ESS - HEIMDAL</a>
				</br>
				<a target="_blank" href="http://e-ssrf.sinap.cas.cn/beamlines/bl13w1/201401/t20140112_152430.html">China - SSRF - BL13W1</a>
      </div>
      </div>
    </div>
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 footer_bottom">
      <ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a target="_blank" href="/feed.xml" title="RSS">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">RSS</span>
    </a>
  </li><li class="list-inline-item">
    <a target="_blank" href="mailto:zhangy3@ornl.gov" title="Email me">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Email me</span>
   </a>
  </li><li class="list-inline-item">
    <a target="_blank" href="https://github.com/kvieta1990" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li></ul>

      
      <p class="copyright text-muted">

      
      </p>
      <p class="theme-by text-muted">
        Copyright 2020 ¬©
        <a>Yuanpeng Zhang</a>
      </p>
      </div>
    </div>
	<div class="row" id="vistor_map" style="position:absolute; left:-10px; bottom:20px;">
	  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=000000&w=300&t=tt&d=mXrA2cjTFPms32CLvpbXJeN7mGr8Pp6J7WRX3Im-ZOw&co=eaeaea&ct=000000'></script>
	</div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
